{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Este codigo prepara los datos para usarlos con pytorch (generando un archivo CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "cats = [\"MEL\",\"NV\",\"BCC\",\"AK\",\"BKL\",\"DF\",\"VASC\",\"SCC\",\"UNK\"]\n",
    "\n",
    "train_percent = .7\n",
    "val_percent = .2\n",
    "test_percent = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sacamos los datos del CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de elementos 25331\n",
      "> Head de los datos del csv\n",
      "          image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK\n",
      "0  ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "1  ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "2  ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "3  ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "4  ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "csv = pd.read_csv(\"./dataset/ISIC_2019_Training_GroundTruth.csv\")\n",
    "\n",
    "print(\"> Cantidad de elementos\", csv.count(axis=1).size )\n",
    "print(\"> Head de los datos del csv\")\n",
    "print(csv.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sacamos las categorias (esto no es necesario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Categorias\n",
      "['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']\n"
     ]
    }
   ],
   "source": [
    "header = list(csv.columns)\n",
    "header.remove(\"image\")\n",
    "\n",
    "print(\"> Categorias\")\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos un Dataframe en el formato que requiere pytorch (imagen<string>, categoria<int>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de filas 25331\n",
      "> Head de los datos en el formato que usa pytorch\n",
      "            img  cat\n",
      "0  ISIC_0000000    1\n",
      "1  ISIC_0000001    1\n",
      "2  ISIC_0000002    0\n",
      "3  ISIC_0000003    1\n",
      "4  ISIC_0000004    0\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({\"img\":[], \"cat\": []}, dtype=int)\n",
    "\n",
    "for entry in csv.values:\n",
    "    data = data.append({\"img\":entry[0] , \"cat\":np.where(entry==1.0)[0][0]-1}, ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"> Cantidad de filas\", csv.count(axis=1).size)\n",
    "print(\"> Head de los datos en el formato que usa pytorch\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contamos cuantas imagenes hay de cada categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de imagenes de cada tipo:\n",
      "[ 4522 12875  3323   867  2624   239   253   628     0]\n"
     ]
    }
   ],
   "source": [
    "counter = np.zeros(len(cats), dtype=int)\n",
    "\n",
    "for elm in data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> Cantidad de imagenes de cada tipo:\")\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averiguamos cual es el tamaño del grupo de imagenes mas pequeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad mínima de imagenes de un tipo:\n",
      "239\n"
     ]
    }
   ],
   "source": [
    "# counter = list(filter(lambda elm: elm > 0, counter))\n",
    "# min_cat_size = min(counter)\n",
    "\n",
    "min_cat_size = data.cat.value_counts().min()\n",
    "\n",
    "print(\"> Cantidad mínima de imagenes de un tipo:\")\n",
    "print(min_cat_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacemos que todos los grupos tengan el mismo tamaño, eligiendolos de forma aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de elemntos: 1912\n",
      "> Datos equilibrados\n",
      "                        img  cat\n",
      "0  ISIC_0014372_downsampled    0\n",
      "1              ISIC_0058177    0\n",
      "2              ISIC_0073237    0\n",
      "3  ISIC_0014072_downsampled    0\n",
      "4              ISIC_0055405    0\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(data.groupby(\"cat\").apply(lambda cat: cat.sample(min_cat_size)).reset_index(drop=True))\n",
    "\n",
    "print(\"> Cantidad de elemntos:\", data.count(axis=1).size )\n",
    "print(\"> Datos equilibrados\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barajamos todas las filas del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> cantidad de elementos 1912\n",
      "> datos barajados\n",
      "               img  cat\n",
      "842   ISIC_0028370    3\n",
      "1777  ISIC_0064287    7\n",
      "1881  ISIC_0058934    7\n",
      "1260  ISIC_0031799    5\n",
      "195   ISIC_0056389    0\n"
     ]
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "\n",
    "print(\"> cantidad de elementos\", data.count(axis=1).size)\n",
    "print(\"> datos barajados\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobamos cuantas imagenes hay de cada categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de imagenes de cada tipo:\n",
      "[239 239 239 239 239 239 239 239   0]\n"
     ]
    }
   ],
   "source": [
    "counter = np.zeros(len(cats), dtype=int)\n",
    "\n",
    "for elm in data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> Cantidad de imagenes de cada tipo:\")\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos el resultado en un archivo CSV\n",
    "> Esto para mas eficiencia a la hora de usarlo, mantener siempre el mismo dataset y evitar la sobrerrepresentación de las categorias con mas elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./dataset/balanced_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora vamos a separar los datos en 3 grupos (train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train 1338\n",
      "                           img  cat\n",
      "465               ISIC_0031744    1\n",
      "1288              ISIC_0034169    5\n",
      "1615              ISIC_0030722    6\n",
      "782               ISIC_0066391    3\n",
      "444   ISIC_0015161_downsampled    1\n",
      "\n",
      "> val 382\n",
      "              img  cat\n",
      "471  ISIC_0066017    1\n",
      "382  ISIC_0064461    1\n",
      "660  ISIC_0062225    2\n",
      "704  ISIC_0034095    2\n",
      "433  ISIC_0054256    1\n",
      "\n",
      "> test 192\n",
      "                           img  cat\n",
      "465               ISIC_0031744    1\n",
      "1288              ISIC_0034169    5\n",
      "1615              ISIC_0030722    6\n",
      "782               ISIC_0066391    3\n",
      "444   ISIC_0015161_downsampled    1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, tmp = train_test_split(data, train_size=train_percent, stratify=data['cat'], shuffle=True)\n",
    "val_data, test_data = train_test_split(tmp, test_size=test_percent/(test_percent+val_percent), stratify=tmp['cat'], shuffle=True)\n",
    "\n",
    "\n",
    "print(\"> train\", train_data.count(axis=1).size)\n",
    "print(test_data.head())\n",
    "print()\n",
    "\n",
    "print(\"> val\", val_data.count(axis=1).size)\n",
    "print(val_data.head())\n",
    "print()\n",
    "\n",
    "print(\"> test\", test_data.count(axis=1).size)\n",
    "print(test_data.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobamos cuantas imagenes hay de cada categoria para cada grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train 1338 0.6997907949790795\n",
      "[168 167 168 167 167 167 167 167   0] (0.12556053811659193)\n",
      "\n",
      "> val 382 0.1997907949790795\n",
      "[47 48 47 48 48 48 48 48  0] (0.12303664921465969)\n",
      "\n",
      "> test 192 0.100418410041841\n",
      "[24 24 24 24 24 24 24 24  0] (0.125)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = np.zeros(len(cats), dtype=int)\n",
    "for elm in train_data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> train\", train_data.count(axis=1).size, train_data.count(axis=1).size/data.count(axis=1).size)\n",
    "print(counter, f\"({counter[0]/train_data.count(axis=1).size})\")\n",
    "print()\n",
    "\n",
    "counter = np.zeros(len(cats), dtype=int)\n",
    "for elm in val_data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> val\", val_data.count(axis=1).size, val_data.count(axis=1).size/data.count(axis=1).size)\n",
    "print(counter, f\"({counter[0]/val_data.count(axis=1).size})\")\n",
    "print()\n",
    "\n",
    "counter = np.zeros(len(cats), dtype=int)\n",
    "for elm in test_data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> test\", test_data.count(axis=1).size, test_data.count(axis=1).size/data.count(axis=1).size)\n",
    "print(counter, f\"({counter[0]/test_data.count(axis=1).size})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barajamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train 1338\n",
      "                           img  cat\n",
      "1705              ISIC_0069086    7\n",
      "1265              ISIC_0028651    5\n",
      "1312              ISIC_0025668    5\n",
      "1172  ISIC_0012364_downsampled    4\n",
      "1302              ISIC_0030579    5\n",
      "\n",
      "> val 382\n",
      "               img  cat\n",
      "1886  ISIC_0064016    7\n",
      "1000  ISIC_0057348    4\n",
      "1176  ISIC_0032694    4\n",
      "70    ISIC_0065421    0\n",
      "1283  ISIC_0026313    5\n",
      "\n",
      "> test 192\n",
      "                           img  cat\n",
      "233   ISIC_0012395_downsampled    0\n",
      "1161              ISIC_0059118    4\n",
      "1506              ISIC_0069242    6\n",
      "186               ISIC_0068011    0\n",
      "260               ISIC_0028922    1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.sample(frac=1)\n",
    "val_data = val_data.sample(frac=1)\n",
    "test_data = test_data.sample(frac=1)\n",
    "\n",
    "print(\"> train\", train_data.count(axis=1).size)\n",
    "print(train_data.head(), end=\"\\n\\n\")\n",
    "\n",
    "print(\"> val\", val_data.count(axis=1).size)\n",
    "print(val_data.head(), end=\"\\n\\n\")\n",
    "\n",
    "print(\"> test\", test_data.count(axis=1).size)\n",
    "print(test_data.head(), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos cada uno de los dataframes en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"dataset/train_data.csv\", index=False)\n",
    "val_data.to_csv(\"dataset/val_data.csv\", index=False)\n",
    "test_data.to_csv(\"dataset/test_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
