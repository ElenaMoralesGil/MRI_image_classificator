{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Este codigo prepara los datos para usarlos con pytorch (generando un archivo CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:28:45.721219400Z",
     "start_time": "2023-12-29T13:28:45.011042600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:28:45.735394800Z",
     "start_time": "2023-12-29T13:28:45.722220700Z"
    }
   },
   "outputs": [],
   "source": [
    "# consts\n",
    "cats = [\"MEL\",\"NV\",\"BCC\",\"AK\",\"BKL\",\"DF\",\"VASC\",\"SCC\",\"UNK\"]\n",
    "\n",
    "train_percent = .7\n",
    "val_percent = .2\n",
    "test_percent = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sacamos los datos del CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:28:45.864587500Z",
     "start_time": "2023-12-29T13:28:45.736396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de elementos 25331\n",
      "> Head de los datos del csv\n",
      "          image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK\n",
      "0  ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "1  ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "2  ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "3  ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "4  ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "csv = pd.read_csv(\"./dataset/ISIC_2019_Training_GroundTruth.csv\")\n",
    "\n",
    "print(\"> Cantidad de elementos\", csv.count(axis=1).size )\n",
    "print(\"> Head de los datos del csv\")\n",
    "print(csv.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sacamos las categorias (esto no es necesario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:28:46.101198Z",
     "start_time": "2023-12-29T13:28:45.862587500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Categorias\n",
      "['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']\n"
     ]
    }
   ],
   "source": [
    "header = list(csv.columns)\n",
    "header.remove(\"image\")\n",
    "\n",
    "print(\"> Categorias\")\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos un Dataframe en el formato que requiere pytorch (imagen<string>, categoria<int>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:28:46.483375100Z",
     "start_time": "2023-12-29T13:28:46.103198400Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_17836\\83122925.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m\"img\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"cat\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mentry\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcsv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m     \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m\"img\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mentry\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m,\u001B[0m \u001B[1;34m\"cat\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mentry\u001B[0m\u001B[1;33m==\u001B[0m\u001B[1;36m1.0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mignore_index\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"> Cantidad de filas\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcsv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcount\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\universidad\\3º año\\FSI\\pythorch\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   6200\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_accessors\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6201\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6202\u001B[0m         ):\n\u001B[0;32m   6203\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 6204\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({\"img\":[], \"cat\": []}, dtype=int)\n",
    "\n",
    "for entry in csv.values:\n",
    "    data = data.append({\"img\":entry[0] , \"cat\":np.where(entry==1.0)[0][0]-1}, ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"> Cantidad de filas\", csv.count(axis=1).size)\n",
    "print(\"> Head de los datos en el formato que usa pytorch\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contamos cuantas imagenes hay de cada categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-29T13:28:46.484375600Z"
    }
   },
   "outputs": [],
   "source": [
    "counter = np.zeros(len(cats), dtype=int)\n",
    "\n",
    "for elm in data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> Cantidad de imagenes de cada tipo:\")\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averiguamos cual es el tamaño del grupo de imagenes mas pequeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-29T13:28:46.486375500Z"
    }
   },
   "outputs": [],
   "source": [
    "# counter = list(filter(lambda elm: elm > 0, counter))\n",
    "# min_cat_size = min(counter)\n",
    "\n",
    "min_cat_size = data.cat.value_counts().min()\n",
    "\n",
    "print(\"> Cantidad mínima de imagenes de un tipo:\")\n",
    "print(min_cat_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacemos que todos los grupos tengan el mismo tamaño, eligiendolos de forma aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-29T13:28:46.488376100Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data.groupby(\"cat\").apply(lambda cat: cat.sample(min_cat_size)).reset_index(drop=True))\n",
    "\n",
    "print(\"> Cantidad de elemntos:\", data.count(axis=1).size )\n",
    "print(\"> Datos equilibrados\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barajamos todas las filas del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-29T13:28:46.489376400Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.sample(frac=1)\n",
    "\n",
    "print(\"> cantidad de elementos\", data.count(axis=1).size)\n",
    "print(\"> datos barajados\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobamos cuantas imagenes hay de cada categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-29T13:28:46.491376400Z"
    }
   },
   "outputs": [],
   "source": [
    "counter = np.zeros(len(cats), dtype=int)\n",
    "\n",
    "for elm in data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> Cantidad de imagenes de cada tipo:\")\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos el resultado en un archivo CSV\n",
    "> Esto para mas eficiencia a la hora de usarlo, mantener siempre el mismo dataset y evitar la sobrerrepresentación de las categorias con mas elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:28:46.494377500Z",
     "start_time": "2023-12-29T13:28:46.492377100Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"./dataset/balanced_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora vamos a separar los datos en 3 grupos (train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-29T13:28:46.493377100Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, tmp = train_test_split(data, train_size=train_percent, stratify=data['cat'], shuffle=True)\n",
    "val_data, test_data = train_test_split(tmp, test_size=test_percent/(test_percent+val_percent), stratify=tmp['cat'], shuffle=True)\n",
    "\n",
    "\n",
    "print(\"> train\", train_data.count(axis=1).size)\n",
    "print(test_data.head())\n",
    "print()\n",
    "\n",
    "print(\"> val\", val_data.count(axis=1).size)\n",
    "print(val_data.head())\n",
    "print()\n",
    "\n",
    "print(\"> test\", test_data.count(axis=1).size)\n",
    "print(test_data.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobamos cuantas imagenes hay de cada categoria para cada grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-29T13:28:46.494377500Z"
    }
   },
   "outputs": [],
   "source": [
    "counter = np.zeros(len(cats), dtype=int)\n",
    "for elm in train_data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> train\", train_data.count(axis=1).size, train_data.count(axis=1).size/data.count(axis=1).size)\n",
    "print(counter, f\"({counter[0]/train_data.count(axis=1).size})\")\n",
    "print()\n",
    "\n",
    "counter = np.zeros(len(cats), dtype=int)\n",
    "for elm in val_data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> val\", val_data.count(axis=1).size, val_data.count(axis=1).size/data.count(axis=1).size)\n",
    "print(counter, f\"({counter[0]/val_data.count(axis=1).size})\")\n",
    "print()\n",
    "\n",
    "counter = np.zeros(len(cats), dtype=int)\n",
    "for elm in test_data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> test\", test_data.count(axis=1).size, test_data.count(axis=1).size/data.count(axis=1).size)\n",
    "print(counter, f\"({counter[0]/test_data.count(axis=1).size})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barajamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T13:28:46.495377600Z",
     "start_time": "2023-12-29T13:28:46.495377600Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data.sample(frac=1)\n",
    "val_data = val_data.sample(frac=1)\n",
    "test_data = test_data.sample(frac=1)\n",
    "\n",
    "print(\"> train\", train_data.count(axis=1).size)\n",
    "print(train_data.head(), end=\"\\n\\n\")\n",
    "\n",
    "print(\"> val\", val_data.count(axis=1).size)\n",
    "print(val_data.head(), end=\"\\n\\n\")\n",
    "\n",
    "print(\"> test\", test_data.count(axis=1).size)\n",
    "print(test_data.head(), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos cada uno de los dataframes en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-29T13:28:46.496377600Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(\"dataset/train_data.csv\", index=False)\n",
    "val_data.to_csv(\"dataset/val_data.csv\", index=False)\n",
    "test_data.to_csv(\"dataset/test_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
