{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# const\n",
    "\n",
    "dir_path = \"../dataset/brain-tumor-mri\"\n",
    "#dir_path = \"/kaggle/input/brain-tumor-mri-dataset\"\n",
    "\n",
    "labels = [\"notumor\", \"glioma\", \"meningioma\", \"pituitary\"]\n",
    "\n",
    "train_percent = .7\n",
    "val_percent = .2\n",
    "test_percent = .1\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "random_state = 1\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epoch = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num elementos: 7023\n",
      "                                                path cat\n",
      "0  ../dataset/brain-tumor-mri/Training/pituitary/...   3\n",
      "1  ../dataset/brain-tumor-mri/Training/pituitary/...   3\n",
      "2  ../dataset/brain-tumor-mri/Training/pituitary/...   3\n",
      "3  ../dataset/brain-tumor-mri/Training/pituitary/...   3\n",
      "4  ../dataset/brain-tumor-mri/Training/pituitary/...   3\n"
     ]
    }
   ],
   "source": [
    "# creamos un dataset de la forma (path, class)\n",
    "dataset = pd.DataFrame(columns = [\"path\", \"label\"])\n",
    "\n",
    "\n",
    "for dir in os.listdir(dir_path):\n",
    "    for label in os.listdir(os.path.join(dir_path, dir)):\n",
    "        for img in os.listdir(os.path.join(dir_path, dir, label)):\n",
    "            dataset.loc[len(dataset)] = {\"path\": os.path.join(dir_path, dir, label, img),\n",
    "                                   \"label\": labels.index(label) }\n",
    "\n",
    "\n",
    "print(\"num elementos:\", dataset.count(axis=1).size)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de imagenes de la categoria que menos tiene: 1621\n"
     ]
    }
   ],
   "source": [
    "min_cat_size = dataset.label.value_counts().min()\n",
    "\n",
    "print(\"> Cantidad de imagenes de la categoria que menos tiene:\", min_cat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de elementos:  6484\n",
      "0    1621\n",
      "1    1621\n",
      "2    1621\n",
      "3    1621\n",
      "Name: cat, dtype: int64\n",
      "                                                path cat\n",
      "0  ../dataset/brain-tumor-mri/Training/notumor/Tr...   0\n",
      "1  ../dataset/brain-tumor-mri/Testing/notumor/Te-...   0\n",
      "2  ../dataset/brain-tumor-mri/Training/notumor/Tr...   0\n",
      "3  ../dataset/brain-tumor-mri/Training/notumor/Tr...   0\n",
      "4  ../dataset/brain-tumor-mri/Training/notumor/Tr...   0\n"
     ]
    }
   ],
   "source": [
    "# Hacemos que todos tengan los mismos elementos\n",
    "dataset = pd.DataFrame(dataset.groupby(\"label\").apply(lambda label: label.sample(min_cat_size, random_state=random_state)).reset_index(drop=True))\n",
    "\n",
    "print(\"> Cantidad de elementos: \", dataset.count(axis=1).size)\n",
    "print(dataset.label.value_counts())\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train 4538 0.6998766193707588\n",
      "2    1135\n",
      "3    1135\n",
      "0    1134\n",
      "1    1134\n",
      "Name: cat, dtype: int64\n",
      "\n",
      "> val 1297 0.2000308451573103\n",
      "0    325\n",
      "2    324\n",
      "1    324\n",
      "3    324\n",
      "Name: cat, dtype: int64\n",
      "\n",
      "> test 649 0.10009253547193091\n",
      "1    163\n",
      "3    162\n",
      "0    162\n",
      "2    162\n",
      "Name: cat, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# separamos en los cjtos de entrenamiento\n",
    "train_dataset, tmp = train_test_split(dataset, train_size=train_percent, stratify=dataset[\"label\"], shuffle=True, random_state=random_state)\n",
    "val_dataset, test_dataset = train_test_split(tmp, test_size=test_percent/(test_percent+val_percent), stratify=tmp[\"label\"], shuffle=True, random_state=random_state)\n",
    "\n",
    "print(\"> train\", train_dataset.count(axis=1).size, train_dataset.count(axis=1).size/dataset.count(axis=1).size)\n",
    "print(train_dataset.label.value_counts())\n",
    "print()\n",
    "\n",
    "print(\"> val\", val_dataset.count(axis=1).size, val_dataset.count(axis=1).size/dataset.count(axis=1).size)\n",
    "print(val_dataset.label.value_counts())\n",
    "print()\n",
    "\n",
    "print(\"> test\", test_dataset.count(axis=1).size, test_dataset.count(axis=1).size/dataset.count(axis=1).size)\n",
    "print(test_dataset.label.value_counts())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx) -> (str, int):\n",
    "\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img, label = row.path, row.label\n",
    "\n",
    "        img = Image.open(img)\n",
    "        if self.transform: img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "\n",
    "        self.early_stop = False\n",
    "        self.counter = 1\n",
    "\n",
    "        self.best_model = None\n",
    "        self.best_loss = float(\"inf\")\n",
    "\n",
    "def __call__(self, val_loss, model):\n",
    "\n",
    "    if val_loss < (self.best_loss - self.min_delta):\n",
    "        self.best_loss = val_loss\n",
    "        self.counter = 0\n",
    "\n",
    "        self.best_model = model.state_dict()\n",
    "        return True\n",
    "\n",
    "\n",
    "    self.counter += 1\n",
    "    if self.counter >= self.patience: return True\n",
    "\n",
    "def reset(self):\n",
    "    self.early_stop = False\n",
    "    self.counter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Capas convolucionales\n",
    "        self.convin = nn.Conv2d( 3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1 = nn.Conv2d( 64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.convout = nn.Conv2d( 64, 128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Capas Fully connected \n",
    "        # ajustado para 128\n",
    "        self.fcin = nn.Linear(in_features=128 * 16 * 16, out_features=128)\n",
    "        self.fcout = nn.Linear(in_features=len(labels), out_features=4)\n",
    "\n",
    "        # BatchNorm2d\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bnout = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Max pooling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # Capa Dropout \n",
    "        self.dropout25 = nn.Dropout(0.25)\n",
    "        \n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # conv in\n",
    "        x = self.convin(x)\n",
    "        in_copy = x.clone()\n",
    "        x = self.pool(F.relu(x))\n",
    "\n",
    "        # conv 1\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = x.dropout25(x)\n",
    "\n",
    "        # conv out\n",
    "        x = self.pool(F.relu(self.bnout(self.convout(x + in_copy)))) \n",
    "        x = self.dropout25(x)\n",
    "    \n",
    "        # flatten\n",
    "        x = x.view(-1, 128*16*16)\n",
    "\n",
    "        # fully in\n",
    "        x = F.relu(self.fcin(x))\n",
    "        x = self.dropout25(x)\n",
    "\n",
    "        # fully out\n",
    "        x = F.relu(self.fc2out(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loader, *, device = None, criterion = None):\n",
    "    \"\"\"returns pred, real, accuracy, val_loss\"\"\"\n",
    "    if not (device and criterion): raise Exception(\"Params needed\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    corrects = 0\n",
    "\n",
    "    pred = []\n",
    "    real = []\n",
    "    loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outs = model(imgs)\n",
    "            _, predicted = torch.max(outs, 1)\n",
    "\n",
    "            loss += criterion(outs, labels).item()\n",
    "\n",
    "            pred.extend(predicted.tolist())\n",
    "            real.extend(labels.tolist())\n",
    "\n",
    "            corrects = (predicted == labels).sum().item()\n",
    "    \n",
    "    return  pred, real, loss/len(loader), corrects/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loader, *, optimizer, criterion, num_epoch=100, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), train_loss_h=[], train_acc_h=[], val_loss_h=[] ,val_acc_h=[], early_stopping, callback=lambda **_: None, early_callback=lambda **_: None):\n",
    "    if not (optimizer and criterion and early_stopping): raise Exception(\"Params needed\")\n",
    "\n",
    "    message_controler = len(loader)/5\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        corrects = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, (imgs, labels) in enumerate(loader, 1):\n",
    "            model.train()\n",
    "\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outs = model(imgs)\n",
    "            loss = criterion(outs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # extra for analytics\n",
    "            _, predicted = torch.max(outs, 1)\n",
    "            total += labels.size()\n",
    "            corrects += (predicted == labels).sum().item()\n",
    "            # ==================\n",
    "\n",
    "            if not i % message_controler:\n",
    "                print(f\"Epoch {epoch+1}, Batch {i}, Loss, {running_loss/message_controler:.4f}\")\n",
    "            \n",
    "        preds, labels, val_loss, val_acc  = eval(model, val_dataset, device=device, criterion=criterion)\n",
    "\n",
    "        # extra for analytics\n",
    "        train_loss = running_loss /len(loader)\n",
    "        train_loss_h.append(train_loss)\n",
    "        train_acc = 100*corrects/total\n",
    "        train_acc_h.append(train_acc)\n",
    "\n",
    "        val_loss_h.append(val_loss)\n",
    "        val_acc_h.append(val_acc)\n",
    "        # ===================\n",
    "\n",
    "        callback(val_acc=val_acc, val_loss=val_loss, train_loss=train_loss, train_acc=train_acc)\n",
    "\n",
    "        if(early_stopping(val_loss, model)): early_callback(model=model, early_stopping=early_stopping)\n",
    "\n",
    "    return train_acc_h, val_acc_h, train_loss_h, val_loss_h, preds, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path, complete=False):\n",
    "    try:\n",
    "        torch.save(model if complete else model.state_dict(), path)\n",
    "    except Exception as e:\n",
    "        print(\"Error al guardar el model:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img, label):\n",
    "    print('Label: ', dataset.cat[label], \"(\" + str(label) + \")\")\n",
    "    plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormalized_transforms = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "unnormalized_dataset = CustomDataset(dataset, transform=unnormalized_transforms)\n",
    "loader = DataLoader(unnormalized_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "mean_sum = torch.zeros(3)\n",
    "std_sum = torch.zeros(3)\n",
    "n_samples = 0\n",
    "\n",
    "for imgs, _ in loader:\n",
    "    imgs = imgs/255.0 if imgs.max() > 1 else imgs\n",
    "\n",
    "    batch_samples = imgs.size(0)\n",
    "    imgs = imgs.view(batch_samples, imgs.size(1), -1)\n",
    "    \n",
    "    mean_sum += imgs.mean(dim=[0, 2]) * batch_samples\n",
    "    std_sum += imgs.std(dim=[0, 2]) * batch_samples\n",
    "    n_samples += batch_samples\n",
    "\n",
    "mean = mean_sum / n_samples\n",
    "std = std_sum / n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),             \n",
    "    transforms.RandomRotation(180),            \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "test_valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_dataset, transform=train_transform)\n",
    "val_dataset = CustomDataset(val_dataset, transform=test_valid_transforms)\n",
    "test_dataset = CustomDataset(test_dataset, transform=test_valid_transforms)\n",
    "\n",
    "# Acceder e imprimir las primeras 5 muestras del dataset\n",
    "for i in range(5):\n",
    "    image, label = train_dataset[i]\n",
    "    print(f\"Muestra {i}: Imagen - {type(image)}, Dimensiones - {image.size()}, Etiqueta - {label}\")\n",
    "\n",
    "# Imprimir los valores de la media y la desviación estándar\n",
    "print(f\"Media: {mean}, Desviación Estándar: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# Verificar DataLoader\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Batch de imágenes: {images.shape}, Batch de etiquetas: {labels.shape}\")\n",
    "    break\n",
    "\n",
    "# Carga una imagen de prueba\n",
    "img, label = test_dataset[45]\n",
    "show_img(img, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobaciones previas de la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo configurado para usar: {device}\")\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=10, min_delta=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "def callback(val_loss, val_acc):\n",
    "    print(f\"val_loss: {val_loss}, val_acc: {val_acc}\")\n",
    "\n",
    "def early_callback(): print(\"> Early stopping <\")\n",
    "\n",
    "train_loop(model, train_loader,\n",
    "           optimizer=optimizer,\n",
    "           criterion=criterion,\n",
    "           num_epoch=num_epoch,\n",
    "           device=device,\n",
    "           early_stopping=early_stopping,\n",
    "           early_callback=early_callback,\n",
    "           callback=callback\n",
    "           )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
