{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# const\n",
    "\n",
    "dir_path = \"../dataset/brain-tumor-mri\"\n",
    "\n",
    "labels = [\"notumor\", \"glioma\", \"meningioma\", \"pituitary\"]\n",
    "\n",
    "train_percent = .7\n",
    "val_percent = .2\n",
    "test_percent = .1\n",
    "\n",
    "random_state = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num elementos: 7023\n",
      "                                                path cat\n",
      "0  ../dataset/brain-tumor-mri/Training/pituitary/...   3\n",
      "1  ../dataset/brain-tumor-mri/Training/pituitary/...   3\n",
      "2  ../dataset/brain-tumor-mri/Training/pituitary/...   3\n",
      "3  ../dataset/brain-tumor-mri/Training/pituitary/...   3\n",
      "4  ../dataset/brain-tumor-mri/Training/pituitary/...   3\n"
     ]
    }
   ],
   "source": [
    "# creamos un dataset de la forma (path, class)\n",
    "dataset = pd.DataFrame(columns = [\"path\", \"label\"])\n",
    "\n",
    "\n",
    "for dir in os.listdir(dir_path):\n",
    "    for label in os.listdir(os.path.join(dir_path, dir)):\n",
    "        for img in os.listdir(os.path.join(dir_path, dir, label)):\n",
    "            dataset.loc[len(dataset)] = {\"path\": os.path.join(dir_path, dir, label, img),\n",
    "                                   \"label\": labels.index(label) }\n",
    "\n",
    "\n",
    "print(\"num elementos:\", dataset.count(axis=1).size)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de imagenes de la categoria que menos tiene: 1621\n"
     ]
    }
   ],
   "source": [
    "min_cat_size = dataset.label.value_counts().min()\n",
    "\n",
    "print(\"> Cantidad de imagenes de la categoria que menos tiene:\", min_cat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de elementos:  6484\n",
      "0    1621\n",
      "1    1621\n",
      "2    1621\n",
      "3    1621\n",
      "Name: cat, dtype: int64\n",
      "                                                path cat\n",
      "0  ../dataset/brain-tumor-mri/Training/notumor/Tr...   0\n",
      "1  ../dataset/brain-tumor-mri/Testing/notumor/Te-...   0\n",
      "2  ../dataset/brain-tumor-mri/Training/notumor/Tr...   0\n",
      "3  ../dataset/brain-tumor-mri/Training/notumor/Tr...   0\n",
      "4  ../dataset/brain-tumor-mri/Training/notumor/Tr...   0\n"
     ]
    }
   ],
   "source": [
    "# Hacemos que todos tengan los mismos elementos\n",
    "dataset = pd.DataFrame(dataset.groupby(\"label\").apply(lambda label: label.sample(min_cat_size, random_state=random_state)).reset_index(drop=True))\n",
    "\n",
    "print(\"> Cantidad de elementos: \", dataset.count(axis=1).size)\n",
    "print(dataset.label.value_counts())\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train 4538 0.6998766193707588\n",
      "2    1135\n",
      "3    1135\n",
      "0    1134\n",
      "1    1134\n",
      "Name: cat, dtype: int64\n",
      "\n",
      "> val 1297 0.2000308451573103\n",
      "0    325\n",
      "2    324\n",
      "1    324\n",
      "3    324\n",
      "Name: cat, dtype: int64\n",
      "\n",
      "> test 649 0.10009253547193091\n",
      "1    163\n",
      "3    162\n",
      "0    162\n",
      "2    162\n",
      "Name: cat, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# separamos en los cjtos de entrenamiento\n",
    "train_dataset, tmp = train_test_split(dataset, train_size=train_percent, stratify=dataset[\"label\"], shuffle=True, random_state=random_state)\n",
    "val_dataset, test_dataset = train_test_split(tmp, test_size=test_percent/(test_percent+val_percent), stratify=tmp[\"label\"], shuffle=True, random_state=random_state)\n",
    "\n",
    "print(\"> train\", train_dataset.count(axis=1).size, train_dataset.count(axis=1).size/dataset.count(axis=1).size)\n",
    "print(train_dataset.label.value_counts())\n",
    "print()\n",
    "\n",
    "print(\"> val\", val_dataset.count(axis=1).size, val_dataset.count(axis=1).size/dataset.count(axis=1).size)\n",
    "print(val_dataset.label.value_counts())\n",
    "print()\n",
    "\n",
    "print(\"> test\", test_dataset.count(axis=1).size, test_dataset.count(axis=1).size/dataset.count(axis=1).size)\n",
    "print(test_dataset.label.value_counts())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx) -> (str, int):\n",
    "\n",
    "        img, label = self.dataframe[idx]\n",
    "\n",
    "        img = Image.open(img)\n",
    "        if self.transform: img = img.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "\n",
    "        self.early_stop = False\n",
    "        self.counter = 1\n",
    "\n",
    "        self.best_model = None\n",
    "        self.best_loss = float(\"inf\")\n",
    "\n",
    "def __call__(self, val_loss, model):\n",
    "\n",
    "    if val_loss < (self.best_loss - self.min_delta):\n",
    "        self.best_loss = val_loss\n",
    "        self.counter = 0\n",
    "\n",
    "        self.best_model = model.state_dict()\n",
    "        return True\n",
    "\n",
    "\n",
    "    self.counter += 1\n",
    "    if self.counter >= self.patience: return True\n",
    "\n",
    "def reset(self):\n",
    "    self.early_stop = False\n",
    "    self.counter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Capas convolucionales\n",
    "        self.convin = nn.Conv2d( 3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1 = nn.Conv2d( 64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.convout = nn.Conv2d( 64, 128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Capas Fully connected \n",
    "        # ajustado para 128\n",
    "        self.fcin = nn.Linear(in_features=128 * 16 * 16, out_features=128)\n",
    "        self.fcout = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "        # BatchNorm2d\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bnout = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Max pooling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # Capa Dropout \n",
    "        self.dropout25 = nn.Dropout(0.25)\n",
    "        \n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # conv in\n",
    "        x = self.convin(x)\n",
    "        in_copy = x.clone()\n",
    "        x = self.pool(F.relu(x))\n",
    "\n",
    "        # conv 1\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = x.dropout25(x)\n",
    "\n",
    "        # conv out\n",
    "        x = self.pool(F.relu(self.bnout(self.convout(x + in_copy)))) \n",
    "        x = self.dropout25(x)\n",
    "    \n",
    "        # flatten\n",
    "        x = x.view(-1, 128*16*16)\n",
    "\n",
    "        # fully in\n",
    "        x = F.relu(self.fcin(x))\n",
    "        x = self.dropout25(x)\n",
    "\n",
    "        # fully out\n",
    "        x = F.relu(self.fc2out(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loader, *, device = None, criterion = None):\n",
    "    \"\"\"returns pred, real, accuracy, val_loss\"\"\"\n",
    "    if not (device and criterion): raise Exception(\"Params needed\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    corrects = 0\n",
    "\n",
    "    pred = []\n",
    "    real = []\n",
    "    loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outs = model(imgs)\n",
    "            _, predicted = torch.max(outs, 1)\n",
    "\n",
    "            loss += criterion(outs, labels).item()\n",
    "\n",
    "            pred.extend(predicted.tolist())\n",
    "            real.extend(labels.tolist())\n",
    "\n",
    "            corrects = (predicted == labels).sum().item()\n",
    "    \n",
    "    return  pred, real, corrects/len(loader), loss/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loader, *, optimizer, criterion, num_epoch=100, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), history=[], early_stopping, callback=lambda **_: None, early_callback=lambda **_: None):\n",
    "    if not (optimizer and criterion and early_stopping): raise Exception(\"Params needed\")\n",
    "\n",
    "    message_controler = len(loader)/5\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        for i, (imgs, labels) in enumerate(loader, 1):\n",
    "            model.train()\n",
    "\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outs = model(imgs)\n",
    "            loss = criterion(outs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if not i % message_controler:\n",
    "                print(f\"Epoch {epoch+1}, Batch {i}, Loss, {running_loss/message_controler:.4f}\")\n",
    "                history.append(running_loss/10)\n",
    "                running_loss = 0\n",
    "            \n",
    "            _, _, val_acc, val_loss  = eval(model, val_dataset, device=device, criterion=criterion)\n",
    "            \n",
    "            callback(val_acc=val_acc, val_loss=val_loss, loss=loss, outs=outs, labels=labels)\n",
    "\n",
    "            if(early_stopping(val_loss, model)): early_callback(model=model, early_stopping=early_stopping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
