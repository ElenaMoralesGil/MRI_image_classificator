{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a592dab344556c81",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "884dfa2c9f2720f2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Introducción\n",
    "Este cuaderno se centra en el procesamiento y análisis de un conjunto de datos de melanoma. Incluye pasos para la carga de datos, preprocesamiento, entrenamiento del modelo y evaluación.\n",
    "\n",
    "### Indice\n",
    "* [Model](##red-neuronal-simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ee142f79e26fe88f"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e297458e66d698c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:54.819203700Z",
     "start_time": "2023-12-31T16:38:54.723519200Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "17429aaa5c21af8d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:54.919151200Z",
     "start_time": "2023-12-31T16:38:54.739721900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu121\n",
      "Dispositivo configurado para usar: cuda\n",
      "True\n",
      "NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Configuración del dispositivo CUDA\n",
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo configurado para usar: {device}\")\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6e9d634414fcb0a8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:55.160440400Z",
     "start_time": "2023-12-31T16:38:54.910067200Z"
    }
   },
   "outputs": [],
   "source": [
    "# consts\n",
    "cats = [\"MEL\",\"NV\",\"BCC\",\"AK\",\"BKL\",\"DF\",\"VASC\",\"SCC\",\"UNK\"]\n",
    "\n",
    "base_path_csv = \"./dataset\"\n",
    "base_path_img = \"./dataset\"\n",
    "\n",
    "random_state=1\n",
    "\n",
    "train_percent = .7\n",
    "val_percent = .2\n",
    "test_percent = .1\n",
    "\n",
    "batch_size=64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f446c2ab7e62e5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Configuración\n",
    "Las siguientes celdas importan las librerías necesarias y definen constantes utilizadas a lo largo del cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "51724f93a2becdfb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:55.346772800Z",
     "start_time": "2023-12-31T16:38:55.161440800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de elementos 25331\n",
      "> Head de los datos del csv\n",
      "          image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK\n",
      "0  ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "1  ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "2  ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "3  ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "4  ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "csv = pd.read_csv(f\"{base_path_csv}/ISIC_2019_Training_GroundTruth.csv\")\n",
    "\n",
    "print(\"> Cantidad de elementos\", csv.count(axis=1).size )\n",
    "print(\"> Head de los datos del csv\")\n",
    "print(csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f2c2d80efad22ce3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:55.489116400Z",
     "start_time": "2023-12-31T16:38:55.348773500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Categorias\n",
      "['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']\n"
     ]
    }
   ],
   "source": [
    "header = list(csv.columns)\n",
    "header.remove(\"image\")\n",
    "\n",
    "print(\"> Categorias\")\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dd487ad7b0d9ea0d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:55.933981300Z",
     "start_time": "2023-12-31T16:38:55.488116500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de filas 25331\n",
      "> Head de los datos en el formato que usa pytorch\n",
      "            img  cat\n",
      "0  ISIC_0000000    1\n",
      "1  ISIC_0000001    1\n",
      "2  ISIC_0000002    0\n",
      "3  ISIC_0000003    1\n",
      "4  ISIC_0000004    0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.DataFrame({\"img\":[], \"cat\": []}, dtype=int)\n",
    "rows_list = []\n",
    "for entry in csv.values:\n",
    "    new_row = {\"img\": entry[0], \"cat\": np.where(entry==1.0)[0][0]-1}\n",
    "    rows_list.append(new_row)\n",
    "\n",
    "data = pd.DataFrame(rows_list)\n",
    "\n",
    "\n",
    "print(\"> Cantidad de filas\", csv.count(axis=1).size)\n",
    "print(\"> Head de los datos en el formato que usa pytorch\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc258a4506fca26f",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1f642ef672dfe1d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Carga de Datos y Exploración Inicial\n",
    "El conjunto de datos se carga desde un archivo CSV, y se realiza una exploración inicial para entender su estructura y contenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6b70f51bf4912f76",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:55.987554300Z",
     "start_time": "2023-12-31T16:38:55.936084200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de imagenes de cada tipo:\n",
      "[ 4522 12875  3323   867  2624   239   253   628     0]\n"
     ]
    }
   ],
   "source": [
    "counter = np.zeros(len(cats), dtype=int)\n",
    "\n",
    "for elm in data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> Cantidad de imagenes de cada tipo:\")\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "baac2604b9be6feb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:56.140681800Z",
     "start_time": "2023-12-31T16:38:55.966356500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad mínima de imagenes de un tipo:\n",
      "239\n"
     ]
    }
   ],
   "source": [
    "# counter = list(filter(lambda elm: elm > 0, counter))\n",
    "# min_cat_size = min(counter)\n",
    "\n",
    "min_cat_size = data.cat.value_counts().min()\n",
    "\n",
    "print(\"> Cantidad mínima de imagenes de un tipo:\")\n",
    "print(min_cat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b75e85454418a3d4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:56.310356400Z",
     "start_time": "2023-12-31T16:38:56.139681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de elemntos: 1912\n",
      "> Datos equilibrados\n",
      "            img  cat\n",
      "0  ISIC_0032408    0\n",
      "1  ISIC_0056876    0\n",
      "2  ISIC_0033947    0\n",
      "3  ISIC_0072989    0\n",
      "4  ISIC_0054312    0\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(data.groupby(\"cat\").apply(lambda cat: cat.sample(min_cat_size, random_state=random_state)).reset_index(drop=True))\n",
    "\n",
    "print(\"> Cantidad de elemntos:\", data.count(axis=1).size )\n",
    "print(\"> Datos equilibrados\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4a3d5f2b4ec3448b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:56.545026200Z",
     "start_time": "2023-12-31T16:38:56.312357200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> cantidad de elementos 1912\n",
      "> datos barajados\n",
      "               img  cat\n",
      "301   ISIC_0031379    1\n",
      "137   ISIC_0069254    0\n",
      "1799  ISIC_0058515    7\n",
      "267   ISIC_0029388    1\n",
      "186   ISIC_0070731    0\n"
     ]
    }
   ],
   "source": [
    "data = data.sample(frac=1, random_state=random_state)\n",
    "\n",
    "print(\"> cantidad de elementos\", data.count(axis=1).size)\n",
    "print(\"> datos barajados\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f69d52d9c9d54a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preprocesamiento y Análisis de Datos\n",
    "Estas celdas manejan el preprocesamiento de datos, incluyendo la limpieza, equilibrio y preparación para el aprendizaje automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "52bd2a6b437772a9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:56.686454300Z",
     "start_time": "2023-12-31T16:38:56.545026200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de imagenes de cada tipo:\n",
      "[239 239 239 239 239 239 239 239   0]\n"
     ]
    }
   ],
   "source": [
    "counter = np.zeros(len(cats), dtype=int)\n",
    "\n",
    "for elm in data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> Cantidad de imagenes de cada tipo:\")\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d41e8af072468566",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:56.794575Z",
     "start_time": "2023-12-31T16:38:56.687455400Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.to_csv(f\"{base_path_csv}/balanced_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "675c45665252c0d8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:56.967389Z",
     "start_time": "2023-12-31T16:38:56.797654500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train 1338\n",
      "               img  cat\n",
      "1073  ISIC_0072864    4\n",
      "104   ISIC_0068581    0\n",
      "450   ISIC_0059722    1\n",
      "505   ISIC_0068758    2\n",
      "1169  ISIC_0070967    4\n",
      "\n",
      "> val 382\n",
      "               img  cat\n",
      "1251  ISIC_0025668    5\n",
      "1498  ISIC_0027563    6\n",
      "1838  ISIC_0025539    7\n",
      "1790  ISIC_0071795    7\n",
      "1551  ISIC_0033254    6\n",
      "\n",
      "> test 192\n",
      "               img  cat\n",
      "1073  ISIC_0072864    4\n",
      "104   ISIC_0068581    0\n",
      "450   ISIC_0059722    1\n",
      "505   ISIC_0068758    2\n",
      "1169  ISIC_0070967    4\n"
     ]
    }
   ],
   "source": [
    "train_data, tmp = train_test_split(data, train_size=train_percent, stratify=data['cat'], shuffle=True, random_state=random_state)\n",
    "val_data, test_data = train_test_split(tmp, test_size=test_percent/(test_percent+val_percent), stratify=tmp['cat'], shuffle=True, random_state=random_state)\n",
    "\n",
    "\n",
    "print(\"> train\", train_data.count(axis=1).size)\n",
    "print(test_data.head())\n",
    "print()\n",
    "\n",
    "print(\"> val\", val_data.count(axis=1).size)\n",
    "print(val_data.head())\n",
    "print()\n",
    "\n",
    "print(\"> test\", test_data.count(axis=1).size)\n",
    "print(test_data.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "65875d972288c8e5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:57.091785700Z",
     "start_time": "2023-12-31T16:38:56.971390100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train 1338 0.6997907949790795\n",
      "[167 167 168 167 167 167 167 168   0] (0.12481315396113603)\n",
      "\n",
      "> val 382 0.1997907949790795\n",
      "[48 48 47 48 48 48 48 47  0] (0.1256544502617801)\n",
      "\n",
      "> test 192 0.100418410041841\n",
      "[24 24 24 24 24 24 24 24  0] (0.125)\n"
     ]
    }
   ],
   "source": [
    "counter = np.zeros(len(cats), dtype=int)\n",
    "for elm in train_data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> train\", train_data.count(axis=1).size, train_data.count(axis=1).size/data.count(axis=1).size)\n",
    "print(counter, f\"({counter[0]/train_data.count(axis=1).size})\")\n",
    "print()\n",
    "\n",
    "counter = np.zeros(len(cats), dtype=int)\n",
    "for elm in val_data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> val\", val_data.count(axis=1).size, val_data.count(axis=1).size/data.count(axis=1).size)\n",
    "print(counter, f\"({counter[0]/val_data.count(axis=1).size})\")\n",
    "print()\n",
    "\n",
    "counter = np.zeros(len(cats), dtype=int)\n",
    "for elm in test_data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> test\", test_data.count(axis=1).size, test_data.count(axis=1).size/data.count(axis=1).size)\n",
    "print(counter, f\"({counter[0]/test_data.count(axis=1).size})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b055c548040e747d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## División de Datos para el Entrenamiento del Modelo\n",
    "El conjunto de datos se divide en conjuntos de entrenamiento, validación y prueba para prepararse para el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4571fa141d88aa2f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:57.370162600Z",
     "start_time": "2023-12-31T16:38:57.090784700Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_data.to_csv(f\"{base_path_csv}/train_data.csv\", index=False)\n",
    "# val_data.to_csv(f\"{base_path_csv}/val_data.csv\", index=False)\n",
    "# test_data.to_csv(f\"{base_path_csv}/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed53491ef059f8be",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# creacion de un dataset personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "74b025b08473b620",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:38:57.523585600Z",
     "start_time": "2023-12-31T16:38:57.372163100Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import  Dataset\n",
    "image_dir = f\"{base_path_img}/ISIC_2019_Training_Input/ISIC_2019_Training_Input\"\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.dataframe.iloc[idx]['img'] + \".jpg\")\n",
    "        image = Image.open(img_name)\n",
    "        label = self.dataframe.iloc[idx]['cat']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c54cfda2a9fbf1f1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:39:15.622947200Z",
     "start_time": "2023-12-31T16:38:57.524585800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestra 0: Imagen - <class 'torch.Tensor'>, Dimensiones - torch.Size([3, 150, 150]), Etiqueta - 2\n",
      "Muestra 1: Imagen - <class 'torch.Tensor'>, Dimensiones - torch.Size([3, 150, 150]), Etiqueta - 5\n",
      "Muestra 2: Imagen - <class 'torch.Tensor'>, Dimensiones - torch.Size([3, 150, 150]), Etiqueta - 7\n",
      "Muestra 3: Imagen - <class 'torch.Tensor'>, Dimensiones - torch.Size([3, 150, 150]), Etiqueta - 2\n",
      "Muestra 4: Imagen - <class 'torch.Tensor'>, Dimensiones - torch.Size([3, 150, 150]), Etiqueta - 7\n",
      "Media: tensor([0.6479, 0.5226, 0.5249]), Desviación Estándar: tensor([0.2328, 0.2073, 0.2172])\n",
      "Batch de imágenes: torch.Size([64, 3, 150, 150]), Batch de etiquetas: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Carga el conjunto de datos de entrenamiento sin ninguna normalización para calcular la media y la desviación estándar\n",
    "unnormalized_transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "unnormalized_dataset = CustomDataset(data, image_dir, transform=unnormalized_transform)\n",
    "loader = DataLoader(unnormalized_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Calcular la media y la desviación estándar\n",
    "mean_sum = torch.zeros(3)\n",
    "std_sum = torch.zeros(3)\n",
    "n_samples = 0\n",
    "\n",
    "for images, _ in loader:\n",
    "    # Asegúrate de que las imágenes están en el rango 0-1\n",
    "    images = images / 255.0 if images.max() > 1 else images\n",
    "\n",
    "    batch_samples = images.size(0)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean = images.mean(dim=[0, 2])\n",
    "    std = images.std(dim=[0, 2])\n",
    "\n",
    "    mean_sum += mean * batch_samples\n",
    "    std_sum += std * batch_samples\n",
    "    n_samples += batch_samples\n",
    "\n",
    "mean = mean_sum / n_samples\n",
    "std = std_sum / n_samples\n",
    "\n",
    "# Transformaciones para el conjunto de entrenamiento\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),             \n",
    "    transforms.RandomRotation(180),            \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# Transformaciones para el conjunto de validación y test (sin data augmentation)\n",
    "test_valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_data,image_dir, transform=train_transform)\n",
    "val_dataset = CustomDataset(val_data,image_dir, transform=test_valid_transforms)\n",
    "test_dataset = CustomDataset(test_data, image_dir,transform=test_valid_transforms)\n",
    "\n",
    "# comprobaciones\n",
    "sample_dataset = CustomDataset(train_data, image_dir, transform=train_transform)\n",
    "\n",
    "# Acceder e imprimir las primeras 5 muestras del dataset\n",
    "for i in range(5):\n",
    "    image, label = sample_dataset[i]\n",
    "    print(f\"Muestra {i}: Imagen - {type(image)}, Dimensiones - {image.size()}, Etiqueta - {label}\")\n",
    "\n",
    "# Imprimir los valores de la media y la desviación estándar\n",
    "print(f\"Media: {mean}, Desviación Estándar: {std}\")\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,pin_memory=True)\n",
    "\n",
    "# Verificar DataLoader\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Batch de imágenes: {images.shape}, Batch de etiquetas: {labels.shape}\")\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "86e00ff04666ab8d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:39:15.650953400Z",
     "start_time": "2023-12-31T16:39:15.623947600Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8fcd7b97d85613",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Red Neuronal simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3195808d0e522f69",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:39:15.753976900Z",
     "start_time": "2023-12-31T16:39:15.638950300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout25): Dropout(p=0.25, inplace=False)\n",
      "  (dropout50): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=41472, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Capas convolucionales\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Max pooling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # Capa Dropout \n",
    "        self.dropout25 = nn.Dropout(0.25)\n",
    "        self.dropout50 = nn.Dropout(0.5)\n",
    "\n",
    "        # Capas Fully connected \n",
    "        # ajustado para 150x150\n",
    "        self.fc1 = nn.Linear(in_features=128 * 18 * 18, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=8)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "\n",
    "\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout25(x)\n",
    "\n",
    "   \n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.dropout25(x)\n",
    "\n",
    "       \n",
    "        x = x.view(-1, 128 *18 * 18)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout50(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "if torch.cuda.device_count() > 1:  model = nn.DataParallel(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9344ab85d911",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preparación del Modelo\n",
    "Esta sección prepara el modelo de red neuronal usando PyTorch, incluyendo la definición de la arquitectura del modelo y los cargadores de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d3d3e819c89a605c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:39:15.830623300Z",
     "start_time": "2023-12-31T16:39:15.750976400Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history)\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e3884d1e16d38",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Funciones de Entrenamiento y Evaluación\n",
    "Aquí se definen las funciones para entrenar el modelo y evaluar su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "99dac6e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T16:39:15.939659400Z",
     "start_time": "2023-12-31T16:39:15.832623800Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def eval(model, test_loader, device, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    pred = []\n",
    "    real = []\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, cats in test_loader:\n",
    "    \n",
    "            imgs, cats = imgs.to(device), cats.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            \n",
    "            val_loss += criterion(outputs, cats).item()\n",
    "\n",
    "            pred.extend(predicted.tolist())\n",
    "            real.extend(cats.tolist())\n",
    "\n",
    "            total += cats.size(0)\n",
    "            correct += (predicted == cats).sum().item()\n",
    "\n",
    "    print(f'Accuracy on images: {100 * correct / total:.2f}%')\n",
    "    print(metrics.classification_report(pred, real, zero_division=0))\n",
    "    \n",
    "    return torch.FloatTensor(pred).to(device), torch.FloatTensor(real).to(device), val_loss/(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8a2f8ca530edeff5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:39:16.051307900Z",
     "start_time": "2023-12-31T16:39:15.942660300Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(model, train_loader, optimizer, criterion, num_epoch, device, history = []):\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        running_loss = 0\n",
    "        for i, (imgs, cats) in enumerate(train_loader, 1):\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "            imgs, cats = imgs.to(device), cats.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, cats)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if not i % 10:\n",
    "                print(f\"Epoch {epoch+1}, Batch {i}, Loss: {running_loss/10:.4f}\")\n",
    "                history.append(running_loss/10)\n",
    "                running_loss = 0.0\n",
    "                \n",
    "        _, _, val_loss = eval(model, train_loader, device, criterion=criterion)\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "        early_stopping(val_loss)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf22adcee1bee40",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Utilidades Adicionales\n",
    "Funciones de utilidad adicionales, como la detención temprana, se definen en esta sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "97a17b8124f01e9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:39:16.145311100Z",
     "start_time": "2023-12-31T16:39:16.051307900Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "early_stopping = EarlyStopping(patience=20, min_delta=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "95cccb2ef10a97fd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T18:16:28.924414100Z",
     "start_time": "2023-12-31T16:39:16.146312200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss: 2.1458\n",
      "Epoch 1, Batch 20, Loss: 2.0464\n",
      "Accuracy on images: 22.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.26      0.26       174\n",
      "           1       0.66      0.21      0.31       535\n",
      "           2       0.11      0.16      0.13       110\n",
      "           3       0.04      0.55      0.07        11\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.26      0.26      0.26       164\n",
      "           6       0.27      0.25      0.26       182\n",
      "           7       0.20      0.21      0.21       162\n",
      "\n",
      "    accuracy                           0.22      1338\n",
      "   macro avg       0.23      0.24      0.19      1338\n",
      "weighted avg       0.40      0.22      0.26      1338\n",
      "\n",
      "Validation Loss: 2.0054\n",
      "Epoch 2, Batch 10, Loss: 2.0380\n",
      "Epoch 2, Batch 20, Loss: 2.0112\n",
      "Accuracy on images: 25.41%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.29      0.34       238\n",
      "           1       0.64      0.23      0.34       459\n",
      "           2       0.18      0.17      0.17       180\n",
      "           3       0.34      0.32      0.33       174\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.13      0.31      0.19        70\n",
      "           6       0.03      0.50      0.06        10\n",
      "           7       0.31      0.25      0.28       206\n",
      "\n",
      "    accuracy                           0.25      1338\n",
      "   macro avg       0.25      0.26      0.21      1338\n",
      "weighted avg       0.41      0.25      0.30      1338\n",
      "\n",
      "Validation Loss: 1.9641\n",
      "Epoch 3, Batch 10, Loss: 1.9881\n",
      "Epoch 3, Batch 20, Loss: 1.9463\n",
      "Accuracy on images: 31.54%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.36      0.41       220\n",
      "           1       0.49      0.34      0.40       236\n",
      "           2       0.07      0.14      0.10        84\n",
      "           3       0.40      0.29      0.34       226\n",
      "           4       0.06      0.18      0.09        56\n",
      "           5       0.28      0.27      0.27       168\n",
      "           6       0.48      0.67      0.56       119\n",
      "           7       0.29      0.21      0.24       229\n",
      "\n",
      "    accuracy                           0.32      1338\n",
      "   macro avg       0.32      0.31      0.30      1338\n",
      "weighted avg       0.36      0.32      0.33      1338\n",
      "\n",
      "Validation Loss: 1.9028\n",
      "Epoch 4, Batch 10, Loss: 1.8810\n",
      "Epoch 4, Batch 20, Loss: 1.8564\n",
      "Accuracy on images: 32.88%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.55      0.25        49\n",
      "           1       0.75      0.29      0.42       430\n",
      "           2       0.25      0.20      0.22       206\n",
      "           3       0.09      0.41      0.15        37\n",
      "           4       0.10      0.26      0.14        61\n",
      "           5       0.34      0.29      0.31       190\n",
      "           6       0.66      0.68      0.67       163\n",
      "           7       0.28      0.23      0.25       202\n",
      "\n",
      "    accuracy                           0.33      1338\n",
      "   macro avg       0.33      0.37      0.30      1338\n",
      "weighted avg       0.46      0.33      0.35      1338\n",
      "\n",
      "Validation Loss: 1.8281\n",
      "Epoch 5, Batch 10, Loss: 1.8466\n",
      "Epoch 5, Batch 20, Loss: 1.8155\n",
      "Accuracy on images: 33.78%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.37      0.40       199\n",
      "           1       0.31      0.53      0.39        97\n",
      "           2       0.12      0.21      0.16       101\n",
      "           3       0.53      0.25      0.34       351\n",
      "           4       0.19      0.21      0.19       151\n",
      "           5       0.13      0.37      0.19        60\n",
      "           6       0.75      0.59      0.66       214\n",
      "           7       0.23      0.23      0.23       165\n",
      "\n",
      "    accuracy                           0.34      1338\n",
      "   macro avg       0.34      0.34      0.32      1338\n",
      "weighted avg       0.41      0.34      0.35      1338\n",
      "\n",
      "Validation Loss: 1.7563\n",
      "Epoch 6, Batch 10, Loss: 1.8094\n",
      "Epoch 6, Batch 20, Loss: 1.7097\n",
      "Accuracy on images: 36.32%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.34      0.42       285\n",
      "           1       0.56      0.41      0.47       229\n",
      "           2       0.11      0.23      0.15        82\n",
      "           3       0.47      0.31      0.37       255\n",
      "           4       0.09      0.21      0.13        71\n",
      "           5       0.24      0.29      0.26       139\n",
      "           6       0.68      0.69      0.68       163\n",
      "           7       0.18      0.27      0.22       114\n",
      "\n",
      "    accuracy                           0.36      1338\n",
      "   macro avg       0.36      0.34      0.34      1338\n",
      "weighted avg       0.44      0.36      0.39      1338\n",
      "\n",
      "Validation Loss: 1.6838\n",
      "Epoch 7, Batch 10, Loss: 1.7837\n",
      "Epoch 7, Batch 20, Loss: 1.8068\n",
      "Accuracy on images: 34.38%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.34      0.40       232\n",
      "           1       0.47      0.45      0.46       176\n",
      "           2       0.10      0.18      0.13        96\n",
      "           3       0.39      0.30      0.34       215\n",
      "           4       0.11      0.21      0.14        87\n",
      "           5       0.27      0.34      0.30       131\n",
      "           6       0.55      0.80      0.65       115\n",
      "           7       0.39      0.23      0.29       286\n",
      "\n",
      "    accuracy                           0.34      1338\n",
      "   macro avg       0.34      0.36      0.34      1338\n",
      "weighted avg       0.38      0.34      0.35      1338\n",
      "\n",
      "Validation Loss: 1.7147\n",
      "Epoch 8, Batch 10, Loss: 1.7516\n",
      "Epoch 8, Batch 20, Loss: 1.7329\n",
      "Accuracy on images: 39.31%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.34      0.42       269\n",
      "           1       0.53      0.51      0.52       176\n",
      "           2       0.17      0.29      0.21        96\n",
      "           3       0.44      0.34      0.39       215\n",
      "           4       0.19      0.22      0.20       144\n",
      "           5       0.38      0.34      0.36       190\n",
      "           6       0.77      0.70      0.74       184\n",
      "           7       0.11      0.30      0.16        64\n",
      "\n",
      "    accuracy                           0.39      1338\n",
      "   macro avg       0.39      0.38      0.37      1338\n",
      "weighted avg       0.45      0.39      0.41      1338\n",
      "\n",
      "Validation Loss: 1.6549\n",
      "Epoch 9, Batch 10, Loss: 1.7136\n",
      "Epoch 9, Batch 20, Loss: 1.7366\n",
      "Accuracy on images: 39.24%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.46      0.39       124\n",
      "           1       0.68      0.41      0.51       277\n",
      "           2       0.19      0.23      0.21       140\n",
      "           3       0.39      0.35      0.37       184\n",
      "           4       0.17      0.25      0.20       111\n",
      "           5       0.48      0.31      0.38       256\n",
      "           6       0.74      0.71      0.72       174\n",
      "           7       0.15      0.36      0.22        72\n",
      "\n",
      "    accuracy                           0.39      1338\n",
      "   macro avg       0.39      0.39      0.38      1338\n",
      "weighted avg       0.46      0.39      0.41      1338\n",
      "\n",
      "Validation Loss: 1.6498\n",
      "Epoch 10, Batch 10, Loss: 1.6996\n",
      "Epoch 10, Batch 20, Loss: 1.7048\n",
      "Accuracy on images: 39.24%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.38      0.44       242\n",
      "           1       0.50      0.51      0.51       164\n",
      "           2       0.10      0.23      0.13        71\n",
      "           3       0.52      0.32      0.40       273\n",
      "           4       0.13      0.24      0.17        92\n",
      "           5       0.38      0.37      0.38       174\n",
      "           6       0.71      0.75      0.73       158\n",
      "           7       0.26      0.26      0.26       164\n",
      "\n",
      "    accuracy                           0.39      1338\n",
      "   macro avg       0.39      0.38      0.38      1338\n",
      "weighted avg       0.45      0.39      0.41      1338\n",
      "\n",
      "Validation Loss: 1.6178\n",
      "Epoch 11, Batch 10, Loss: 1.6600\n",
      "Epoch 11, Batch 20, Loss: 1.6654\n",
      "Accuracy on images: 39.84%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.50      0.44       131\n",
      "           1       0.63      0.50      0.56       209\n",
      "           2       0.33      0.25      0.28       222\n",
      "           3       0.40      0.36      0.38       184\n",
      "           4       0.16      0.22      0.18       125\n",
      "           5       0.32      0.33      0.33       159\n",
      "           6       0.76      0.70      0.73       181\n",
      "           7       0.20      0.27      0.23       127\n",
      "\n",
      "    accuracy                           0.40      1338\n",
      "   macro avg       0.40      0.39      0.39      1338\n",
      "weighted avg       0.42      0.40      0.41      1338\n",
      "\n",
      "Validation Loss: 1.5982\n",
      "Epoch 12, Batch 10, Loss: 1.6504\n",
      "Epoch 12, Batch 20, Loss: 1.6890\n",
      "Accuracy on images: 40.28%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.53      0.44       118\n",
      "           1       0.68      0.48      0.56       236\n",
      "           2       0.14      0.25      0.18        93\n",
      "           3       0.41      0.29      0.34       232\n",
      "           4       0.08      0.37      0.13        35\n",
      "           5       0.59      0.29      0.39       341\n",
      "           6       0.74      0.75      0.75       165\n",
      "           7       0.22      0.31      0.26       118\n",
      "\n",
      "    accuracy                           0.40      1338\n",
      "   macro avg       0.40      0.41      0.38      1338\n",
      "weighted avg       0.50      0.40      0.43      1338\n",
      "\n",
      "Validation Loss: 1.6036\n",
      "Epoch 13, Batch 10, Loss: 1.6571\n",
      "Epoch 13, Batch 20, Loss: 1.6834\n",
      "Accuracy on images: 39.46%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.46      0.45       160\n",
      "           1       0.77      0.38      0.51       338\n",
      "           2       0.07      0.21      0.10        53\n",
      "           3       0.34      0.38      0.36       149\n",
      "           4       0.13      0.26      0.17        80\n",
      "           5       0.32      0.34      0.33       154\n",
      "           6       0.68      0.79      0.73       145\n",
      "           7       0.41      0.27      0.32       259\n",
      "\n",
      "    accuracy                           0.39      1338\n",
      "   macro avg       0.39      0.39      0.37      1338\n",
      "weighted avg       0.49      0.39      0.42      1338\n",
      "\n",
      "Validation Loss: 1.6066\n",
      "Epoch 14, Batch 10, Loss: 1.6652\n",
      "Epoch 14, Batch 20, Loss: 1.6642\n",
      "Accuracy on images: 40.66%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.46      0.48       177\n",
      "           1       0.53      0.62      0.57       141\n",
      "           2       0.14      0.29      0.19        84\n",
      "           3       0.39      0.34      0.36       193\n",
      "           4       0.43      0.23      0.30       316\n",
      "           5       0.24      0.40      0.30       101\n",
      "           6       0.72      0.83      0.77       144\n",
      "           7       0.32      0.29      0.30       182\n",
      "\n",
      "    accuracy                           0.41      1338\n",
      "   macro avg       0.41      0.43      0.41      1338\n",
      "weighted avg       0.43      0.41      0.40      1338\n",
      "\n",
      "Validation Loss: 1.6079\n",
      "Epoch 15, Batch 10, Loss: 1.6089\n",
      "Epoch 15, Batch 20, Loss: 1.6293\n",
      "Accuracy on images: 40.88%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.37      0.46       259\n",
      "           1       0.50      0.63      0.56       132\n",
      "           2       0.13      0.23      0.17        94\n",
      "           3       0.49      0.35      0.41       231\n",
      "           4       0.27      0.23      0.25       193\n",
      "           5       0.32      0.46      0.38       115\n",
      "           6       0.70      0.82      0.75       143\n",
      "           7       0.29      0.29      0.29       171\n",
      "\n",
      "    accuracy                           0.41      1338\n",
      "   macro avg       0.41      0.42      0.41      1338\n",
      "weighted avg       0.43      0.41      0.41      1338\n",
      "\n",
      "Validation Loss: 1.5595\n",
      "Epoch 16, Batch 10, Loss: 1.5901\n",
      "Epoch 16, Batch 20, Loss: 1.6477\n",
      "Accuracy on images: 41.55%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.47      0.46       158\n",
      "           1       0.65      0.47      0.54       231\n",
      "           2       0.07      0.20      0.11        59\n",
      "           3       0.34      0.40      0.37       143\n",
      "           4       0.19      0.24      0.21       130\n",
      "           5       0.64      0.35      0.45       308\n",
      "           6       0.77      0.77      0.77       166\n",
      "           7       0.23      0.27      0.25       143\n",
      "\n",
      "    accuracy                           0.42      1338\n",
      "   macro avg       0.42      0.40      0.39      1338\n",
      "weighted avg       0.49      0.42      0.44      1338\n",
      "\n",
      "Validation Loss: 1.5262\n",
      "Epoch 17, Batch 10, Loss: 1.5893\n",
      "Epoch 17, Batch 20, Loss: 1.6210\n",
      "Accuracy on images: 42.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.59      0.47       111\n",
      "           1       0.63      0.53      0.58       199\n",
      "           2       0.12      0.31      0.17        64\n",
      "           3       0.57      0.33      0.42       287\n",
      "           4       0.19      0.32      0.24       100\n",
      "           5       0.38      0.43      0.40       148\n",
      "           6       0.78      0.74      0.76       178\n",
      "           7       0.36      0.24      0.29       251\n",
      "\n",
      "    accuracy                           0.43      1338\n",
      "   macro avg       0.43      0.44      0.42      1338\n",
      "weighted avg       0.48      0.43      0.44      1338\n",
      "\n",
      "Validation Loss: 1.5389\n",
      "Epoch 18, Batch 10, Loss: 1.5848\n",
      "Epoch 18, Batch 20, Loss: 1.6288\n",
      "Accuracy on images: 44.47%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.47      0.47       165\n",
      "           1       0.63      0.58      0.60       184\n",
      "           2       0.12      0.28      0.17        75\n",
      "           3       0.52      0.37      0.43       233\n",
      "           4       0.23      0.32      0.27       121\n",
      "           5       0.31      0.45      0.36       114\n",
      "           6       0.81      0.74      0.77       185\n",
      "           7       0.46      0.30      0.36       261\n",
      "\n",
      "    accuracy                           0.44      1338\n",
      "   macro avg       0.44      0.44      0.43      1338\n",
      "weighted avg       0.49      0.44      0.46      1338\n",
      "\n",
      "Validation Loss: 1.5074\n",
      "Epoch 19, Batch 10, Loss: 1.5591\n",
      "Epoch 19, Batch 20, Loss: 1.5887\n",
      "Accuracy on images: 43.42%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.53      0.45       125\n",
      "           1       0.75      0.44      0.56       281\n",
      "           2       0.29      0.28      0.28       173\n",
      "           3       0.41      0.39      0.40       176\n",
      "           4       0.14      0.32      0.19        73\n",
      "           5       0.49      0.39      0.44       209\n",
      "           6       0.80      0.71      0.75       188\n",
      "           7       0.21      0.31      0.25       113\n",
      "\n",
      "    accuracy                           0.43      1338\n",
      "   macro avg       0.43      0.42      0.41      1338\n",
      "weighted avg       0.50      0.43      0.45      1338\n",
      "\n",
      "Validation Loss: 1.4923\n",
      "Epoch 20, Batch 10, Loss: 1.6172\n",
      "Epoch 20, Batch 20, Loss: 1.5169\n",
      "Accuracy on images: 45.52%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.53      0.49       142\n",
      "           1       0.69      0.49      0.57       237\n",
      "           2       0.15      0.32      0.21        82\n",
      "           3       0.40      0.45      0.42       147\n",
      "           4       0.25      0.33      0.28       128\n",
      "           5       0.43      0.43      0.43       166\n",
      "           6       0.83      0.74      0.78       187\n",
      "           7       0.44      0.30      0.35       249\n",
      "\n",
      "    accuracy                           0.46      1338\n",
      "   macro avg       0.46      0.45      0.44      1338\n",
      "weighted avg       0.50      0.46      0.47      1338\n",
      "\n",
      "Validation Loss: 1.4678\n",
      "Epoch 21, Batch 10, Loss: 1.5477\n",
      "Epoch 21, Batch 20, Loss: 1.5953\n",
      "Accuracy on images: 44.32%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.53      0.46       131\n",
      "           1       0.61      0.55      0.58       184\n",
      "           2       0.13      0.28      0.18        79\n",
      "           3       0.52      0.38      0.44       229\n",
      "           4       0.44      0.28      0.34       266\n",
      "           5       0.28      0.52      0.36        91\n",
      "           6       0.72      0.85      0.78       142\n",
      "           7       0.42      0.33      0.37       216\n",
      "\n",
      "    accuracy                           0.44      1338\n",
      "   macro avg       0.44      0.46      0.44      1338\n",
      "weighted avg       0.47      0.44      0.45      1338\n",
      "\n",
      "Validation Loss: 1.5311\n",
      "Epoch 22, Batch 10, Loss: 1.5535\n",
      "Epoch 22, Batch 20, Loss: 1.5621\n",
      "Accuracy on images: 47.09%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.58      0.48       118\n",
      "           1       0.63      0.62      0.62       170\n",
      "           2       0.14      0.39      0.20        59\n",
      "           3       0.56      0.39      0.46       241\n",
      "           4       0.42      0.32      0.36       218\n",
      "           5       0.52      0.40      0.45       219\n",
      "           6       0.78      0.85      0.81       155\n",
      "           7       0.30      0.32      0.31       158\n",
      "\n",
      "    accuracy                           0.47      1338\n",
      "   macro avg       0.47      0.48      0.46      1338\n",
      "weighted avg       0.50      0.47      0.48      1338\n",
      "\n",
      "Validation Loss: 1.4568\n",
      "Epoch 23, Batch 10, Loss: 1.5480\n",
      "Epoch 23, Batch 20, Loss: 1.5174\n",
      "Accuracy on images: 46.41%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.55      0.49       135\n",
      "           1       0.71      0.51      0.59       230\n",
      "           2       0.13      0.29      0.18        77\n",
      "           3       0.37      0.44      0.40       140\n",
      "           4       0.31      0.34      0.32       155\n",
      "           5       0.54      0.43      0.48       211\n",
      "           6       0.78      0.81      0.80       160\n",
      "           7       0.43      0.32      0.37       230\n",
      "\n",
      "    accuracy                           0.46      1338\n",
      "   macro avg       0.46      0.46      0.45      1338\n",
      "weighted avg       0.50      0.46      0.48      1338\n",
      "\n",
      "Validation Loss: 1.4507\n",
      "Epoch 24, Batch 10, Loss: 1.4881\n",
      "Epoch 24, Batch 20, Loss: 1.5185\n",
      "Accuracy on images: 45.59%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.53      0.51       160\n",
      "           1       0.63      0.51      0.56       206\n",
      "           2       0.17      0.30      0.22        96\n",
      "           3       0.54      0.38      0.45       240\n",
      "           4       0.27      0.30      0.28       152\n",
      "           5       0.31      0.56      0.40        91\n",
      "           6       0.80      0.82      0.81       162\n",
      "           7       0.43      0.31      0.36       231\n",
      "\n",
      "    accuracy                           0.46      1338\n",
      "   macro avg       0.46      0.46      0.45      1338\n",
      "weighted avg       0.49      0.46      0.46      1338\n",
      "\n",
      "Validation Loss: 1.4499\n",
      "Epoch 25, Batch 10, Loss: 1.4825\n",
      "Epoch 25, Batch 20, Loss: 1.4965\n",
      "Accuracy on images: 47.98%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.51      0.48       149\n",
      "           1       0.70      0.52      0.60       225\n",
      "           2       0.20      0.31      0.24       105\n",
      "           3       0.43      0.46      0.44       158\n",
      "           4       0.40      0.33      0.36       200\n",
      "           5       0.49      0.51      0.50       162\n",
      "           6       0.81      0.82      0.82       164\n",
      "           7       0.36      0.35      0.36       175\n",
      "\n",
      "    accuracy                           0.48      1338\n",
      "   macro avg       0.48      0.48      0.47      1338\n",
      "weighted avg       0.50      0.48      0.49      1338\n",
      "\n",
      "Validation Loss: 1.4081\n",
      "Epoch 26, Batch 10, Loss: 1.4443\n",
      "Epoch 26, Batch 20, Loss: 1.5364\n",
      "Accuracy on images: 47.68%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.46      0.48       182\n",
      "           1       0.73      0.51      0.60       240\n",
      "           2       0.21      0.33      0.25       107\n",
      "           3       0.44      0.43      0.43       174\n",
      "           4       0.17      0.44      0.24        63\n",
      "           5       0.59      0.42      0.49       236\n",
      "           6       0.83      0.81      0.82       170\n",
      "           7       0.35      0.36      0.35       166\n",
      "\n",
      "    accuracy                           0.48      1338\n",
      "   macro avg       0.48      0.47      0.46      1338\n",
      "weighted avg       0.53      0.48      0.50      1338\n",
      "\n",
      "Validation Loss: 1.3887\n",
      "Epoch 27, Batch 10, Loss: 1.4218\n",
      "Epoch 27, Batch 20, Loss: 1.5115\n",
      "Accuracy on images: 46.19%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.65      0.44        84\n",
      "           1       0.60      0.62      0.61       162\n",
      "           2       0.12      0.24      0.17        86\n",
      "           3       0.56      0.35      0.43       262\n",
      "           4       0.41      0.38      0.40       177\n",
      "           5       0.56      0.42      0.48       226\n",
      "           6       0.77      0.91      0.83       141\n",
      "           7       0.35      0.29      0.32       200\n",
      "\n",
      "    accuracy                           0.46      1338\n",
      "   macro avg       0.46      0.48      0.46      1338\n",
      "weighted avg       0.49      0.46      0.47      1338\n",
      "\n",
      "Validation Loss: 1.4211\n",
      "Epoch 28, Batch 10, Loss: 1.5248\n",
      "Epoch 28, Batch 20, Loss: 1.4633\n",
      "Accuracy on images: 48.88%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.54       171\n",
      "           1       0.67      0.52      0.58       216\n",
      "           2       0.30      0.32      0.31       154\n",
      "           3       0.44      0.44      0.44       167\n",
      "           4       0.26      0.39      0.31       110\n",
      "           5       0.43      0.53      0.48       135\n",
      "           6       0.82      0.72      0.77       189\n",
      "           7       0.45      0.38      0.41       196\n",
      "\n",
      "    accuracy                           0.49      1338\n",
      "   macro avg       0.49      0.48      0.48      1338\n",
      "weighted avg       0.51      0.49      0.50      1338\n",
      "\n",
      "Validation Loss: 1.3907\n",
      "Epoch 29, Batch 10, Loss: 1.4303\n",
      "Epoch 29, Batch 20, Loss: 1.4961\n",
      "Accuracy on images: 48.36%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.51      0.53       179\n",
      "           1       0.71      0.52      0.60       230\n",
      "           2       0.29      0.31      0.30       160\n",
      "           3       0.46      0.41      0.43       189\n",
      "           4       0.25      0.41      0.31       101\n",
      "           5       0.40      0.56      0.46       117\n",
      "           6       0.83      0.74      0.79       187\n",
      "           7       0.39      0.37      0.38       175\n",
      "\n",
      "    accuracy                           0.48      1338\n",
      "   macro avg       0.48      0.48      0.47      1338\n",
      "weighted avg       0.52      0.48      0.49      1338\n",
      "\n",
      "Validation Loss: 1.3574\n",
      "Epoch 30, Batch 10, Loss: 1.4462\n",
      "Epoch 30, Batch 20, Loss: 1.4860\n",
      "Accuracy on images: 49.70%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.55      0.53       156\n",
      "           1       0.63      0.52      0.57       201\n",
      "           2       0.16      0.39      0.23        70\n",
      "           3       0.50      0.40      0.44       212\n",
      "           4       0.37      0.38      0.38       162\n",
      "           5       0.50      0.52      0.51       162\n",
      "           6       0.83      0.85      0.84       163\n",
      "           7       0.46      0.37      0.41       212\n",
      "\n",
      "    accuracy                           0.50      1338\n",
      "   macro avg       0.50      0.50      0.49      1338\n",
      "weighted avg       0.52      0.50      0.51      1338\n",
      "\n",
      "Validation Loss: 1.3560\n",
      "Epoch 31, Batch 10, Loss: 1.4158\n",
      "Epoch 31, Batch 20, Loss: 1.4880\n",
      "Accuracy on images: 50.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.60      0.53       134\n",
      "           1       0.74      0.56      0.63       221\n",
      "           2       0.33      0.35      0.34       156\n",
      "           3       0.58      0.41      0.48       237\n",
      "           4       0.20      0.41      0.27        81\n",
      "           5       0.51      0.51      0.51       167\n",
      "           6       0.81      0.85      0.83       159\n",
      "           7       0.41      0.38      0.39       183\n",
      "\n",
      "    accuracy                           0.51      1338\n",
      "   macro avg       0.51      0.51      0.50      1338\n",
      "weighted avg       0.54      0.51      0.52      1338\n",
      "\n",
      "Validation Loss: 1.3271\n",
      "Epoch 32, Batch 10, Loss: 1.4187\n",
      "Epoch 32, Batch 20, Loss: 1.4458\n",
      "Accuracy on images: 51.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.66      0.52       108\n",
      "           1       0.71      0.61      0.66       193\n",
      "           2       0.30      0.35      0.32       143\n",
      "           3       0.45      0.45      0.45       167\n",
      "           4       0.38      0.45      0.41       139\n",
      "           5       0.70      0.40      0.51       295\n",
      "           6       0.81      0.87      0.84       156\n",
      "           7       0.33      0.40      0.36       137\n",
      "\n",
      "    accuracy                           0.51      1338\n",
      "   macro avg       0.51      0.52      0.51      1338\n",
      "weighted avg       0.55      0.51      0.52      1338\n",
      "\n",
      "Validation Loss: 1.3280\n",
      "Epoch 33, Batch 10, Loss: 1.3484\n",
      "Epoch 33, Batch 20, Loss: 1.4737\n",
      "Accuracy on images: 51.94%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.56      0.54       154\n",
      "           1       0.66      0.59      0.62       187\n",
      "           2       0.38      0.37      0.37       169\n",
      "           3       0.38      0.49      0.43       129\n",
      "           4       0.44      0.39      0.41       185\n",
      "           5       0.50      0.53      0.51       160\n",
      "           6       0.84      0.83      0.83       169\n",
      "           7       0.45      0.41      0.42       185\n",
      "\n",
      "    accuracy                           0.52      1338\n",
      "   macro avg       0.52      0.52      0.52      1338\n",
      "weighted avg       0.52      0.52      0.52      1338\n",
      "\n",
      "Validation Loss: 1.3004\n",
      "Epoch 34, Batch 10, Loss: 1.3952\n",
      "Epoch 34, Batch 20, Loss: 1.4624\n",
      "Accuracy on images: 51.64%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.58      0.54       144\n",
      "           1       0.71      0.57      0.64       207\n",
      "           2       0.25      0.36      0.29       117\n",
      "           3       0.54      0.41      0.47       223\n",
      "           4       0.39      0.38      0.38       171\n",
      "           5       0.51      0.57      0.54       149\n",
      "           6       0.80      0.88      0.83       152\n",
      "           7       0.43      0.41      0.42       175\n",
      "\n",
      "    accuracy                           0.52      1338\n",
      "   macro avg       0.52      0.52      0.51      1338\n",
      "weighted avg       0.53      0.52      0.52      1338\n",
      "\n",
      "Validation Loss: 1.3477\n",
      "Epoch 35, Batch 10, Loss: 1.4204\n",
      "Epoch 35, Batch 20, Loss: 1.4101\n",
      "Accuracy on images: 53.51%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.62      0.54       128\n",
      "           1       0.68      0.61      0.64       187\n",
      "           2       0.23      0.36      0.28       105\n",
      "           3       0.46      0.50      0.48       152\n",
      "           4       0.50      0.38      0.43       220\n",
      "           5       0.62      0.51      0.56       204\n",
      "           6       0.80      0.91      0.85       147\n",
      "           7       0.52      0.45      0.48       195\n",
      "\n",
      "    accuracy                           0.54      1338\n",
      "   macro avg       0.54      0.54      0.53      1338\n",
      "weighted avg       0.55      0.54      0.54      1338\n",
      "\n",
      "Validation Loss: 1.2871\n",
      "Epoch 36, Batch 10, Loss: 1.4055\n",
      "Epoch 36, Batch 20, Loss: 1.4080\n",
      "Accuracy on images: 51.12%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.65      0.50       105\n",
      "           1       0.66      0.65      0.66       168\n",
      "           2       0.21      0.34      0.26       105\n",
      "           3       0.54      0.44      0.49       205\n",
      "           4       0.34      0.38      0.36       152\n",
      "           5       0.57      0.52      0.55       185\n",
      "           6       0.89      0.68      0.77       219\n",
      "           7       0.46      0.39      0.43       199\n",
      "\n",
      "    accuracy                           0.51      1338\n",
      "   macro avg       0.51      0.51      0.50      1338\n",
      "weighted avg       0.55      0.51      0.52      1338\n",
      "\n",
      "Validation Loss: 1.3075\n",
      "Epoch 37, Batch 10, Loss: 1.3772\n",
      "Epoch 37, Batch 20, Loss: 1.4327\n",
      "Accuracy on images: 54.63%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57       174\n",
      "           1       0.69      0.63      0.66       185\n",
      "           2       0.25      0.39      0.31       107\n",
      "           3       0.56      0.47      0.51       199\n",
      "           4       0.38      0.42      0.40       151\n",
      "           5       0.54      0.56      0.55       163\n",
      "           6       0.83      0.86      0.84       162\n",
      "           7       0.54      0.46      0.49       197\n",
      "\n",
      "    accuracy                           0.55      1338\n",
      "   macro avg       0.55      0.54      0.54      1338\n",
      "weighted avg       0.56      0.55      0.55      1338\n",
      "\n",
      "Validation Loss: 1.2490\n",
      "Epoch 38, Batch 10, Loss: 1.3844\n",
      "Epoch 38, Batch 20, Loss: 1.3637\n",
      "Accuracy on images: 50.82%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.57      0.49       129\n",
      "           1       0.49      0.73      0.59       113\n",
      "           2       0.30      0.39      0.34       129\n",
      "           3       0.56      0.40      0.47       235\n",
      "           4       0.51      0.36      0.42       236\n",
      "           5       0.57      0.49      0.53       192\n",
      "           6       0.81      0.87      0.84       157\n",
      "           7       0.39      0.44      0.41       147\n",
      "\n",
      "    accuracy                           0.51      1338\n",
      "   macro avg       0.51      0.53      0.51      1338\n",
      "weighted avg       0.52      0.51      0.51      1338\n",
      "\n",
      "Validation Loss: 1.2932\n",
      "Epoch 39, Batch 10, Loss: 1.3051\n",
      "Epoch 39, Batch 20, Loss: 1.4617\n",
      "Accuracy on images: 55.16%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.57      0.56       159\n",
      "           1       0.71      0.65      0.68       182\n",
      "           2       0.24      0.49      0.33        84\n",
      "           3       0.47      0.48      0.47       164\n",
      "           4       0.37      0.38      0.37       165\n",
      "           5       0.66      0.53      0.59       209\n",
      "           6       0.89      0.85      0.87       176\n",
      "           7       0.52      0.44      0.47       199\n",
      "\n",
      "    accuracy                           0.55      1338\n",
      "   macro avg       0.55      0.55      0.54      1338\n",
      "weighted avg       0.58      0.55      0.56      1338\n",
      "\n",
      "Validation Loss: 1.2330\n",
      "Epoch 40, Batch 10, Loss: 1.3576\n",
      "Epoch 40, Batch 20, Loss: 1.3790\n",
      "Accuracy on images: 52.99%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.62      0.52       119\n",
      "           1       0.78      0.59      0.67       222\n",
      "           2       0.30      0.40      0.34       125\n",
      "           3       0.45      0.49      0.47       154\n",
      "           4       0.35      0.46      0.40       128\n",
      "           5       0.63      0.49      0.55       217\n",
      "           6       0.75      0.93      0.83       136\n",
      "           7       0.52      0.37      0.43       237\n",
      "\n",
      "    accuracy                           0.53      1338\n",
      "   macro avg       0.53      0.54      0.53      1338\n",
      "weighted avg       0.56      0.53      0.53      1338\n",
      "\n",
      "Validation Loss: 1.2782\n",
      "Epoch 41, Batch 10, Loss: 1.4000\n",
      "Epoch 41, Batch 20, Loss: 1.3778\n",
      "Accuracy on images: 55.46%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.63      0.55       130\n",
      "           1       0.71      0.66      0.69       179\n",
      "           2       0.33      0.43      0.37       129\n",
      "           3       0.52      0.49      0.50       178\n",
      "           4       0.50      0.40      0.45       208\n",
      "           5       0.62      0.52      0.57       197\n",
      "           6       0.83      0.86      0.84       160\n",
      "           7       0.44      0.47      0.46       157\n",
      "\n",
      "    accuracy                           0.55      1338\n",
      "   macro avg       0.55      0.56      0.55      1338\n",
      "weighted avg       0.56      0.55      0.56      1338\n",
      "\n",
      "Validation Loss: 1.2137\n",
      "Epoch 42, Batch 10, Loss: 1.3272\n",
      "Epoch 42, Batch 20, Loss: 1.3953\n",
      "Accuracy on images: 54.78%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.65      0.54       119\n",
      "           1       0.67      0.72      0.70       155\n",
      "           2       0.34      0.40      0.37       141\n",
      "           3       0.44      0.47      0.46       158\n",
      "           4       0.39      0.51      0.44       128\n",
      "           5       0.68      0.47      0.56       238\n",
      "           6       0.85      0.83      0.84       171\n",
      "           7       0.55      0.41      0.47       228\n",
      "\n",
      "    accuracy                           0.55      1338\n",
      "   macro avg       0.55      0.56      0.55      1338\n",
      "weighted avg       0.57      0.55      0.55      1338\n",
      "\n",
      "Validation Loss: 1.2386\n",
      "Epoch 43, Batch 10, Loss: 1.3624\n",
      "Epoch 43, Batch 20, Loss: 1.2524\n",
      "Accuracy on images: 56.73%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.69      0.59       124\n",
      "           1       0.79      0.59      0.68       223\n",
      "           2       0.38      0.40      0.39       157\n",
      "           3       0.54      0.48      0.51       188\n",
      "           4       0.34      0.54      0.41       103\n",
      "           5       0.62      0.52      0.56       200\n",
      "           6       0.84      0.90      0.87       157\n",
      "           7       0.52      0.47      0.50       186\n",
      "\n",
      "    accuracy                           0.57      1338\n",
      "   macro avg       0.57      0.57      0.56      1338\n",
      "weighted avg       0.59      0.57      0.57      1338\n",
      "\n",
      "Validation Loss: 1.1745\n",
      "Epoch 44, Batch 10, Loss: 1.3135\n",
      "Epoch 44, Batch 20, Loss: 1.3140\n",
      "Accuracy on images: 55.53%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58       148\n",
      "           1       0.61      0.69      0.65       148\n",
      "           2       0.38      0.42      0.40       150\n",
      "           3       0.60      0.42      0.49       240\n",
      "           4       0.40      0.40      0.40       165\n",
      "           5       0.55      0.63      0.59       146\n",
      "           6       0.87      0.90      0.88       162\n",
      "           7       0.49      0.46      0.48       179\n",
      "\n",
      "    accuracy                           0.56      1338\n",
      "   macro avg       0.56      0.57      0.56      1338\n",
      "weighted avg       0.56      0.56      0.55      1338\n",
      "\n",
      "Validation Loss: 1.1907\n",
      "Epoch 45, Batch 10, Loss: 1.3307\n",
      "Epoch 45, Batch 20, Loss: 1.3214\n",
      "Accuracy on images: 57.62%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       169\n",
      "           1       0.70      0.66      0.68       176\n",
      "           2       0.32      0.46      0.37       115\n",
      "           3       0.59      0.48      0.53       206\n",
      "           4       0.38      0.46      0.42       138\n",
      "           5       0.65      0.56      0.60       192\n",
      "           6       0.84      0.89      0.87       158\n",
      "           7       0.53      0.48      0.51       184\n",
      "\n",
      "    accuracy                           0.58      1338\n",
      "   macro avg       0.58      0.58      0.57      1338\n",
      "weighted avg       0.59      0.58      0.58      1338\n",
      "\n",
      "Validation Loss: 1.1669\n",
      "Epoch 46, Batch 10, Loss: 1.3128\n",
      "Epoch 46, Batch 20, Loss: 1.2981\n",
      "Accuracy on images: 54.93%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.56       207\n",
      "           1       0.77      0.58      0.66       222\n",
      "           2       0.33      0.38      0.35       146\n",
      "           3       0.43      0.54      0.48       134\n",
      "           4       0.22      0.54      0.31        69\n",
      "           5       0.63      0.54      0.58       196\n",
      "           6       0.86      0.86      0.86       168\n",
      "           7       0.53      0.45      0.49       196\n",
      "\n",
      "    accuracy                           0.55      1338\n",
      "   macro avg       0.55      0.55      0.54      1338\n",
      "weighted avg       0.59      0.55      0.56      1338\n",
      "\n",
      "Validation Loss: 1.1730\n",
      "Epoch 47, Batch 10, Loss: 1.2975\n",
      "Epoch 47, Batch 20, Loss: 1.3069\n",
      "Accuracy on images: 57.03%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.54      0.57       186\n",
      "           1       0.67      0.68      0.68       164\n",
      "           2       0.28      0.57      0.38        82\n",
      "           3       0.56      0.46      0.51       204\n",
      "           4       0.40      0.47      0.43       140\n",
      "           5       0.69      0.54      0.61       216\n",
      "           6       0.84      0.92      0.88       152\n",
      "           7       0.52      0.45      0.48       194\n",
      "\n",
      "    accuracy                           0.57      1338\n",
      "   macro avg       0.57      0.58      0.57      1338\n",
      "weighted avg       0.59      0.57      0.57      1338\n",
      "\n",
      "Validation Loss: 1.1266\n",
      "Epoch 48, Batch 10, Loss: 1.2799\n",
      "Epoch 48, Batch 20, Loss: 1.2658\n",
      "Accuracy on images: 58.22%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.59      0.57       158\n",
      "           1       0.74      0.64      0.68       193\n",
      "           2       0.54      0.39      0.45       230\n",
      "           3       0.38      0.65      0.48        99\n",
      "           4       0.40      0.52      0.45       128\n",
      "           5       0.59      0.63      0.61       156\n",
      "           6       0.92      0.83      0.88       185\n",
      "           7       0.54      0.48      0.51       189\n",
      "\n",
      "    accuracy                           0.58      1338\n",
      "   macro avg       0.58      0.59      0.58      1338\n",
      "weighted avg       0.60      0.58      0.59      1338\n",
      "\n",
      "Validation Loss: 1.1739\n",
      "Epoch 49, Batch 10, Loss: 1.2601\n",
      "Epoch 49, Batch 20, Loss: 1.3243\n",
      "Accuracy on images: 58.15%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.74      0.58       110\n",
      "           1       0.69      0.66      0.67       177\n",
      "           2       0.39      0.47      0.42       138\n",
      "           3       0.65      0.43      0.51       253\n",
      "           4       0.41      0.45      0.43       155\n",
      "           5       0.66      0.64      0.65       173\n",
      "           6       0.89      0.85      0.87       175\n",
      "           7       0.48      0.51      0.49       157\n",
      "\n",
      "    accuracy                           0.58      1338\n",
      "   macro avg       0.58      0.59      0.58      1338\n",
      "weighted avg       0.60      0.58      0.58      1338\n",
      "\n",
      "Validation Loss: 1.1839\n",
      "Epoch 50, Batch 10, Loss: 1.3177\n",
      "Epoch 50, Batch 20, Loss: 1.2940\n",
      "Accuracy on images: 58.82%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.67      0.59       133\n",
      "           1       0.67      0.68      0.68       164\n",
      "           2       0.36      0.47      0.41       128\n",
      "           3       0.50      0.54      0.52       155\n",
      "           4       0.51      0.44      0.48       194\n",
      "           5       0.61      0.68      0.64       151\n",
      "           6       0.88      0.90      0.89       164\n",
      "           7       0.64      0.43      0.51       249\n",
      "\n",
      "    accuracy                           0.59      1338\n",
      "   macro avg       0.59      0.60      0.59      1338\n",
      "weighted avg       0.60      0.59      0.59      1338\n",
      "\n",
      "Validation Loss: 1.1202\n",
      "Epoch 51, Batch 10, Loss: 1.2970\n",
      "Epoch 51, Batch 20, Loss: 1.2949\n",
      "Accuracy on images: 58.45%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.65      0.60       141\n",
      "           1       0.74      0.62      0.67       198\n",
      "           2       0.44      0.43      0.43       173\n",
      "           3       0.59      0.50      0.54       197\n",
      "           4       0.47      0.44      0.46       179\n",
      "           5       0.57      0.67      0.62       143\n",
      "           6       0.89      0.86      0.87       174\n",
      "           7       0.42      0.53      0.47       133\n",
      "\n",
      "    accuracy                           0.58      1338\n",
      "   macro avg       0.58      0.59      0.58      1338\n",
      "weighted avg       0.59      0.58      0.59      1338\n",
      "\n",
      "Validation Loss: 1.1356\n",
      "Epoch 52, Batch 10, Loss: 1.2359\n",
      "Epoch 52, Batch 20, Loss: 1.3300\n",
      "Accuracy on images: 56.88%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.66      0.58       131\n",
      "           1       0.63      0.72      0.67       145\n",
      "           2       0.46      0.41      0.43       189\n",
      "           3       0.56      0.46      0.50       203\n",
      "           4       0.46      0.39      0.42       193\n",
      "           5       0.62      0.61      0.61       169\n",
      "           6       0.90      0.83      0.86       181\n",
      "           7       0.42      0.56      0.48       127\n",
      "\n",
      "    accuracy                           0.57      1338\n",
      "   macro avg       0.57      0.58      0.57      1338\n",
      "weighted avg       0.57      0.57      0.57      1338\n",
      "\n",
      "Validation Loss: 1.1328\n",
      "Epoch 53, Batch 10, Loss: 1.2813\n",
      "Epoch 53, Batch 20, Loss: 1.2636\n",
      "Accuracy on images: 59.04%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.54      0.60       209\n",
      "           1       0.75      0.68      0.71       183\n",
      "           2       0.39      0.49      0.44       134\n",
      "           3       0.49      0.50      0.49       162\n",
      "           4       0.35      0.55      0.42       106\n",
      "           5       0.66      0.65      0.65       169\n",
      "           6       0.90      0.83      0.86       180\n",
      "           7       0.52      0.45      0.48       195\n",
      "\n",
      "    accuracy                           0.59      1338\n",
      "   macro avg       0.59      0.59      0.58      1338\n",
      "weighted avg       0.61      0.59      0.60      1338\n",
      "\n",
      "Validation Loss: 1.1100\n",
      "Epoch 54, Batch 10, Loss: 1.2472\n",
      "Epoch 54, Batch 20, Loss: 1.2727\n",
      "Accuracy on images: 60.24%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.69      0.57       119\n",
      "           1       0.66      0.76      0.71       147\n",
      "           2       0.36      0.52      0.43       118\n",
      "           3       0.64      0.49      0.55       219\n",
      "           4       0.56      0.42      0.48       222\n",
      "           5       0.66      0.65      0.66       170\n",
      "           6       0.86      0.94      0.90       152\n",
      "           7       0.58      0.51      0.54       191\n",
      "\n",
      "    accuracy                           0.60      1338\n",
      "   macro avg       0.60      0.62      0.61      1338\n",
      "weighted avg       0.61      0.60      0.60      1338\n",
      "\n",
      "Validation Loss: 1.0933\n",
      "Epoch 55, Batch 10, Loss: 1.2268\n",
      "Epoch 55, Batch 20, Loss: 1.3321\n",
      "Accuracy on images: 60.76%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.67      0.63       147\n",
      "           1       0.80      0.64      0.71       209\n",
      "           2       0.43      0.45      0.44       160\n",
      "           3       0.60      0.52      0.56       195\n",
      "           4       0.37      0.56      0.44       109\n",
      "           5       0.69      0.57      0.62       202\n",
      "           6       0.89      0.91      0.90       164\n",
      "           7       0.49      0.55      0.52       152\n",
      "\n",
      "    accuracy                           0.61      1338\n",
      "   macro avg       0.61      0.61      0.60      1338\n",
      "weighted avg       0.63      0.61      0.61      1338\n",
      "\n",
      "Validation Loss: 1.1106\n",
      "Epoch 56, Batch 10, Loss: 1.2583\n",
      "Epoch 56, Batch 20, Loss: 1.2916\n",
      "Accuracy on images: 60.24%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57       126\n",
      "           1       0.74      0.69      0.71       180\n",
      "           2       0.48      0.43      0.45       184\n",
      "           3       0.55      0.55      0.55       166\n",
      "           4       0.45      0.56      0.50       134\n",
      "           5       0.63      0.60      0.62       174\n",
      "           6       0.87      0.86      0.87       170\n",
      "           7       0.60      0.49      0.54       204\n",
      "\n",
      "    accuracy                           0.60      1338\n",
      "   macro avg       0.60      0.61      0.60      1338\n",
      "weighted avg       0.61      0.60      0.60      1338\n",
      "\n",
      "Validation Loss: 1.0787\n",
      "Epoch 57, Batch 10, Loss: 1.1942\n",
      "Epoch 57, Batch 20, Loss: 1.2929\n",
      "Accuracy on images: 62.56%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65       151\n",
      "           1       0.73      0.69      0.71       177\n",
      "           2       0.46      0.44      0.45       174\n",
      "           3       0.54      0.59      0.57       154\n",
      "           4       0.51      0.50      0.50       171\n",
      "           5       0.68      0.71      0.69       159\n",
      "           6       0.92      0.84      0.88       183\n",
      "           7       0.55      0.54      0.55       169\n",
      "\n",
      "    accuracy                           0.63      1338\n",
      "   macro avg       0.63      0.62      0.62      1338\n",
      "weighted avg       0.63      0.63      0.63      1338\n",
      "\n",
      "Validation Loss: 1.0361\n",
      "Epoch 58, Batch 10, Loss: 1.1877\n",
      "Epoch 58, Batch 20, Loss: 1.2462\n",
      "Accuracy on images: 64.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.64       140\n",
      "           1       0.75      0.74      0.75       170\n",
      "           2       0.39      0.53      0.45       125\n",
      "           3       0.66      0.52      0.58       211\n",
      "           4       0.48      0.61      0.54       131\n",
      "           5       0.69      0.70      0.70       166\n",
      "           6       0.87      0.94      0.90       156\n",
      "           7       0.68      0.48      0.57       239\n",
      "\n",
      "    accuracy                           0.64      1338\n",
      "   macro avg       0.64      0.65      0.64      1338\n",
      "weighted avg       0.66      0.64      0.64      1338\n",
      "\n",
      "Validation Loss: 1.0505\n",
      "Epoch 59, Batch 10, Loss: 1.2879\n",
      "Epoch 59, Batch 20, Loss: 1.1595\n",
      "Accuracy on images: 63.23%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62       157\n",
      "           1       0.67      0.75      0.71       149\n",
      "           2       0.44      0.55      0.49       134\n",
      "           3       0.61      0.56      0.59       181\n",
      "           4       0.51      0.49      0.50       172\n",
      "           5       0.66      0.69      0.68       161\n",
      "           6       0.92      0.90      0.91       172\n",
      "           7       0.64      0.50      0.56       212\n",
      "\n",
      "    accuracy                           0.63      1338\n",
      "   macro avg       0.63      0.64      0.63      1338\n",
      "weighted avg       0.64      0.63      0.63      1338\n",
      "\n",
      "Validation Loss: 1.0278\n",
      "Epoch 60, Batch 10, Loss: 1.1622\n",
      "Epoch 60, Batch 20, Loss: 1.2105\n",
      "Accuracy on images: 63.23%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.76      0.63       117\n",
      "           1       0.71      0.76      0.73       155\n",
      "           2       0.48      0.53      0.50       153\n",
      "           3       0.70      0.53      0.60       221\n",
      "           4       0.59      0.44      0.51       225\n",
      "           5       0.66      0.65      0.66       170\n",
      "           6       0.86      0.95      0.90       151\n",
      "           7       0.52      0.60      0.56       146\n",
      "\n",
      "    accuracy                           0.63      1338\n",
      "   macro avg       0.63      0.65      0.64      1338\n",
      "weighted avg       0.64      0.63      0.63      1338\n",
      "\n",
      "Validation Loss: 1.0570\n",
      "Epoch 61, Batch 10, Loss: 1.2256\n",
      "Epoch 61, Batch 20, Loss: 1.2258\n",
      "Accuracy on images: 62.41%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.70      0.61       129\n",
      "           1       0.69      0.73      0.71       159\n",
      "           2       0.36      0.50      0.42       121\n",
      "           3       0.67      0.54      0.60       206\n",
      "           4       0.53      0.44      0.48       204\n",
      "           5       0.68      0.68      0.68       167\n",
      "           6       0.89      0.89      0.89       166\n",
      "           7       0.62      0.56      0.59       186\n",
      "\n",
      "    accuracy                           0.62      1338\n",
      "   macro avg       0.62      0.63      0.62      1338\n",
      "weighted avg       0.63      0.62      0.62      1338\n",
      "\n",
      "Validation Loss: 1.0287\n",
      "Epoch 62, Batch 10, Loss: 1.2014\n",
      "Epoch 62, Batch 20, Loss: 1.2170\n",
      "Accuracy on images: 63.45%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.70      0.64       138\n",
      "           1       0.81      0.69      0.75       197\n",
      "           2       0.39      0.55      0.46       119\n",
      "           3       0.62      0.57      0.59       184\n",
      "           4       0.47      0.48      0.47       164\n",
      "           5       0.69      0.69      0.69       169\n",
      "           6       0.90      0.89      0.90       168\n",
      "           7       0.61      0.51      0.56       199\n",
      "\n",
      "    accuracy                           0.63      1338\n",
      "   macro avg       0.63      0.64      0.63      1338\n",
      "weighted avg       0.65      0.63      0.64      1338\n",
      "\n",
      "Validation Loss: 1.0348\n",
      "Epoch 63, Batch 10, Loss: 1.1375\n",
      "Epoch 63, Batch 20, Loss: 1.1708\n",
      "Accuracy on images: 63.08%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64       163\n",
      "           1       0.66      0.78      0.72       143\n",
      "           2       0.46      0.50      0.48       155\n",
      "           3       0.62      0.52      0.56       200\n",
      "           4       0.46      0.63      0.53       120\n",
      "           5       0.66      0.63      0.65       174\n",
      "           6       0.91      0.91      0.91       167\n",
      "           7       0.65      0.51      0.57       216\n",
      "\n",
      "    accuracy                           0.63      1338\n",
      "   macro avg       0.63      0.64      0.63      1338\n",
      "weighted avg       0.64      0.63      0.63      1338\n",
      "\n",
      "Validation Loss: 1.0052\n",
      "Epoch 64, Batch 10, Loss: 1.1403\n",
      "Epoch 64, Batch 20, Loss: 1.2303\n",
      "Accuracy on images: 61.88%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.65      0.61       147\n",
      "           1       0.72      0.69      0.71       175\n",
      "           2       0.48      0.49      0.48       167\n",
      "           3       0.59      0.59      0.59       169\n",
      "           4       0.42      0.47      0.44       150\n",
      "           5       0.69      0.63      0.66       183\n",
      "           6       0.93      0.86      0.89       181\n",
      "           7       0.55      0.55      0.55       166\n",
      "\n",
      "    accuracy                           0.62      1338\n",
      "   macro avg       0.62      0.61      0.62      1338\n",
      "weighted avg       0.63      0.62      0.62      1338\n",
      "\n",
      "Validation Loss: 1.0128\n",
      "Epoch 65, Batch 10, Loss: 1.1802\n",
      "Epoch 65, Batch 20, Loss: 1.2106\n",
      "Accuracy on images: 62.11%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.72      0.64       137\n",
      "           1       0.65      0.80      0.72       137\n",
      "           2       0.34      0.61      0.44        93\n",
      "           3       0.73      0.45      0.55       273\n",
      "           4       0.52      0.49      0.50       178\n",
      "           5       0.72      0.68      0.70       178\n",
      "           6       0.92      0.89      0.90       172\n",
      "           7       0.50      0.49      0.50       170\n",
      "\n",
      "    accuracy                           0.62      1338\n",
      "   macro avg       0.62      0.64      0.62      1338\n",
      "weighted avg       0.65      0.62      0.62      1338\n",
      "\n",
      "Validation Loss: 1.0196\n",
      "Epoch 66, Batch 10, Loss: 1.1913\n",
      "Epoch 66, Batch 20, Loss: 1.1233\n",
      "Accuracy on images: 64.80%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       169\n",
      "           1       0.77      0.68      0.72       189\n",
      "           2       0.42      0.50      0.45       140\n",
      "           3       0.65      0.62      0.63       174\n",
      "           4       0.50      0.52      0.51       162\n",
      "           5       0.68      0.68      0.68       165\n",
      "           6       0.92      0.92      0.92       167\n",
      "           7       0.59      0.58      0.58       172\n",
      "\n",
      "    accuracy                           0.65      1338\n",
      "   macro avg       0.65      0.64      0.65      1338\n",
      "weighted avg       0.66      0.65      0.65      1338\n",
      "\n",
      "Validation Loss: 0.9751\n",
      "Epoch 67, Batch 10, Loss: 1.1172\n",
      "Epoch 67, Batch 20, Loss: 1.1891\n",
      "Accuracy on images: 65.77%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.76      0.67       132\n",
      "           1       0.77      0.75      0.76       170\n",
      "           2       0.57      0.55      0.56       172\n",
      "           3       0.63      0.53      0.58       197\n",
      "           4       0.44      0.63      0.52       115\n",
      "           5       0.79      0.63      0.70       210\n",
      "           6       0.93      0.86      0.89       180\n",
      "           7       0.55      0.57      0.56       162\n",
      "\n",
      "    accuracy                           0.66      1338\n",
      "   macro avg       0.66      0.66      0.65      1338\n",
      "weighted avg       0.67      0.66      0.66      1338\n",
      "\n",
      "Validation Loss: 0.9710\n",
      "Epoch 68, Batch 10, Loss: 1.1516\n",
      "Epoch 68, Batch 20, Loss: 1.0904\n",
      "Accuracy on images: 64.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64       163\n",
      "           1       0.81      0.67      0.73       204\n",
      "           2       0.48      0.52      0.50       155\n",
      "           3       0.54      0.63      0.58       143\n",
      "           4       0.44      0.53      0.48       137\n",
      "           5       0.66      0.70      0.68       158\n",
      "           6       0.92      0.94      0.93       163\n",
      "           7       0.67      0.52      0.58       215\n",
      "\n",
      "    accuracy                           0.64      1338\n",
      "   macro avg       0.64      0.64      0.64      1338\n",
      "weighted avg       0.65      0.64      0.64      1338\n",
      "\n",
      "Validation Loss: 0.9433\n",
      "Epoch 69, Batch 10, Loss: 1.1609\n",
      "Epoch 69, Batch 20, Loss: 1.1891\n",
      "Accuracy on images: 65.32%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61       169\n",
      "           1       0.76      0.68      0.72       186\n",
      "           2       0.57      0.59      0.58       161\n",
      "           3       0.59      0.57      0.58       173\n",
      "           4       0.50      0.61      0.55       135\n",
      "           5       0.72      0.69      0.70       174\n",
      "           6       0.91      0.92      0.91       166\n",
      "           7       0.57      0.55      0.56       174\n",
      "\n",
      "    accuracy                           0.65      1338\n",
      "   macro avg       0.65      0.65      0.65      1338\n",
      "weighted avg       0.66      0.65      0.65      1338\n",
      "\n",
      "Validation Loss: 0.9840\n",
      "Epoch 70, Batch 10, Loss: 1.2089\n",
      "Epoch 70, Batch 20, Loss: 1.1695\n",
      "Accuracy on images: 66.44%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.80      0.68       123\n",
      "           1       0.74      0.79      0.77       156\n",
      "           2       0.64      0.48      0.55       221\n",
      "           3       0.57      0.60      0.58       159\n",
      "           4       0.54      0.59      0.56       152\n",
      "           5       0.74      0.69      0.71       178\n",
      "           6       0.93      0.86      0.89       182\n",
      "           7       0.57      0.57      0.57       167\n",
      "\n",
      "    accuracy                           0.66      1338\n",
      "   macro avg       0.66      0.67      0.67      1338\n",
      "weighted avg       0.67      0.66      0.66      1338\n",
      "\n",
      "Validation Loss: 0.9666\n",
      "Epoch 71, Batch 10, Loss: 1.1546\n",
      "Epoch 71, Batch 20, Loss: 1.1594\n",
      "Accuracy on images: 66.89%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66       157\n",
      "           1       0.77      0.74      0.76       174\n",
      "           2       0.57      0.56      0.56       172\n",
      "           3       0.62      0.61      0.61       168\n",
      "           4       0.43      0.58      0.49       124\n",
      "           5       0.73      0.70      0.71       175\n",
      "           6       0.93      0.85      0.89       184\n",
      "           7       0.65      0.60      0.62       184\n",
      "\n",
      "    accuracy                           0.67      1338\n",
      "   macro avg       0.67      0.66      0.66      1338\n",
      "weighted avg       0.68      0.67      0.67      1338\n",
      "\n",
      "Validation Loss: 0.9507\n",
      "Epoch 72, Batch 10, Loss: 1.1277\n",
      "Epoch 72, Batch 20, Loss: 1.1843\n",
      "Accuracy on images: 68.98%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.72      0.66       141\n",
      "           1       0.82      0.72      0.77       190\n",
      "           2       0.49      0.62      0.55       134\n",
      "           3       0.66      0.65      0.66       168\n",
      "           4       0.56      0.58      0.57       159\n",
      "           5       0.78      0.73      0.76       177\n",
      "           6       0.93      0.92      0.93       168\n",
      "           7       0.67      0.56      0.61       201\n",
      "\n",
      "    accuracy                           0.69      1338\n",
      "   macro avg       0.69      0.69      0.69      1338\n",
      "weighted avg       0.70      0.69      0.69      1338\n",
      "\n",
      "Validation Loss: 0.9140\n",
      "Epoch 73, Batch 10, Loss: 1.1397\n",
      "Epoch 73, Batch 20, Loss: 1.0769\n",
      "Accuracy on images: 67.49%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66       158\n",
      "           1       0.71      0.80      0.75       149\n",
      "           2       0.44      0.62      0.52       119\n",
      "           3       0.68      0.61      0.65       186\n",
      "           4       0.58      0.54      0.56       178\n",
      "           5       0.78      0.67      0.72       195\n",
      "           6       0.89      0.96      0.92       154\n",
      "           7       0.68      0.57      0.62       199\n",
      "\n",
      "    accuracy                           0.67      1338\n",
      "   macro avg       0.68      0.68      0.67      1338\n",
      "weighted avg       0.68      0.67      0.68      1338\n",
      "\n",
      "Validation Loss: 0.9169\n",
      "Epoch 74, Batch 10, Loss: 1.1531\n",
      "Epoch 74, Batch 20, Loss: 1.0721\n",
      "Accuracy on images: 66.89%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65       156\n",
      "           1       0.86      0.72      0.78       201\n",
      "           2       0.55      0.56      0.56       167\n",
      "           3       0.62      0.56      0.59       186\n",
      "           4       0.36      0.57      0.44       106\n",
      "           5       0.80      0.70      0.74       191\n",
      "           6       0.92      0.95      0.93       161\n",
      "           7       0.61      0.61      0.61       170\n",
      "\n",
      "    accuracy                           0.67      1338\n",
      "   macro avg       0.67      0.67      0.66      1338\n",
      "weighted avg       0.69      0.67      0.68      1338\n",
      "\n",
      "Validation Loss: 0.8975\n",
      "Epoch 75, Batch 10, Loss: 1.0733\n",
      "Epoch 75, Batch 20, Loss: 1.0922\n",
      "Accuracy on images: 67.86%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69       173\n",
      "           1       0.79      0.77      0.78       172\n",
      "           2       0.42      0.60      0.49       116\n",
      "           3       0.72      0.56      0.63       214\n",
      "           4       0.50      0.58      0.54       145\n",
      "           5       0.70      0.74      0.72       159\n",
      "           6       0.90      0.96      0.93       157\n",
      "           7       0.70      0.58      0.63       202\n",
      "\n",
      "    accuracy                           0.68      1338\n",
      "   macro avg       0.68      0.68      0.68      1338\n",
      "weighted avg       0.69      0.68      0.68      1338\n",
      "\n",
      "Validation Loss: 0.8701\n",
      "Epoch 76, Batch 10, Loss: 1.0746\n",
      "Epoch 76, Batch 20, Loss: 1.1025\n",
      "Accuracy on images: 66.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68       148\n",
      "           1       0.80      0.66      0.73       202\n",
      "           2       0.48      0.58      0.52       137\n",
      "           3       0.70      0.56      0.62       208\n",
      "           4       0.44      0.66      0.53       112\n",
      "           5       0.68      0.75      0.71       152\n",
      "           6       0.95      0.89      0.92       179\n",
      "           7       0.64      0.54      0.58       200\n",
      "\n",
      "    accuracy                           0.67      1338\n",
      "   macro avg       0.67      0.67      0.66      1338\n",
      "weighted avg       0.69      0.67      0.67      1338\n",
      "\n",
      "Validation Loss: 0.9150\n",
      "Epoch 77, Batch 10, Loss: 1.1191\n",
      "Epoch 77, Batch 20, Loss: 1.0956\n",
      "Accuracy on images: 69.73%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.70       154\n",
      "           1       0.80      0.78      0.79       170\n",
      "           2       0.60      0.54      0.56       186\n",
      "           3       0.65      0.67      0.66       161\n",
      "           4       0.56      0.63      0.59       148\n",
      "           5       0.75      0.70      0.73       179\n",
      "           6       0.93      0.93      0.93       167\n",
      "           7       0.62      0.61      0.62       173\n",
      "\n",
      "    accuracy                           0.70      1338\n",
      "   macro avg       0.70      0.70      0.70      1338\n",
      "weighted avg       0.70      0.70      0.70      1338\n",
      "\n",
      "Validation Loss: 0.8764\n",
      "Epoch 78, Batch 10, Loss: 1.0762\n",
      "Epoch 78, Batch 20, Loss: 1.0748\n",
      "Accuracy on images: 68.46%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.67       165\n",
      "           1       0.84      0.70      0.77       199\n",
      "           2       0.52      0.58      0.55       152\n",
      "           3       0.74      0.58      0.65       213\n",
      "           4       0.40      0.65      0.49       101\n",
      "           5       0.76      0.76      0.76       168\n",
      "           6       0.91      0.93      0.92       164\n",
      "           7       0.65      0.62      0.63       176\n",
      "\n",
      "    accuracy                           0.68      1338\n",
      "   macro avg       0.68      0.69      0.68      1338\n",
      "weighted avg       0.71      0.68      0.69      1338\n",
      "\n",
      "Validation Loss: 0.8728\n",
      "Epoch 79, Batch 10, Loss: 1.0834\n",
      "Epoch 79, Batch 20, Loss: 1.0601\n",
      "Accuracy on images: 69.36%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.74      0.70       149\n",
      "           1       0.74      0.81      0.78       153\n",
      "           2       0.58      0.54      0.56       182\n",
      "           3       0.71      0.61      0.66       195\n",
      "           4       0.54      0.62      0.58       146\n",
      "           5       0.74      0.75      0.75       165\n",
      "           6       0.92      0.90      0.91       172\n",
      "           7       0.64      0.61      0.63       176\n",
      "\n",
      "    accuracy                           0.69      1338\n",
      "   macro avg       0.69      0.70      0.69      1338\n",
      "weighted avg       0.70      0.69      0.69      1338\n",
      "\n",
      "Validation Loss: 0.8843\n",
      "Epoch 80, Batch 10, Loss: 1.0332\n",
      "Epoch 80, Batch 20, Loss: 1.1441\n",
      "Accuracy on images: 69.51%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70       158\n",
      "           1       0.78      0.77      0.77       169\n",
      "           2       0.58      0.58      0.58       170\n",
      "           3       0.72      0.65      0.68       185\n",
      "           4       0.46      0.61      0.52       125\n",
      "           5       0.79      0.68      0.73       193\n",
      "           6       0.94      0.91      0.92       173\n",
      "           7       0.61      0.62      0.62       165\n",
      "\n",
      "    accuracy                           0.70      1338\n",
      "   macro avg       0.70      0.69      0.69      1338\n",
      "weighted avg       0.71      0.70      0.70      1338\n",
      "\n",
      "Validation Loss: 0.8645\n",
      "Epoch 81, Batch 10, Loss: 1.0699\n",
      "Epoch 81, Batch 20, Loss: 1.1590\n",
      "Accuracy on images: 69.21%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       175\n",
      "           1       0.76      0.74      0.75       171\n",
      "           2       0.60      0.58      0.59       172\n",
      "           3       0.60      0.66      0.63       152\n",
      "           4       0.51      0.61      0.56       141\n",
      "           5       0.71      0.79      0.75       150\n",
      "           6       0.96      0.90      0.93       178\n",
      "           7       0.69      0.58      0.63       199\n",
      "\n",
      "    accuracy                           0.69      1338\n",
      "   macro avg       0.69      0.69      0.69      1338\n",
      "weighted avg       0.70      0.69      0.69      1338\n",
      "\n",
      "Validation Loss: 0.8924\n",
      "Epoch 82, Batch 10, Loss: 1.0796\n",
      "Epoch 82, Batch 20, Loss: 1.0821\n",
      "Accuracy on images: 70.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.78      0.69       133\n",
      "           1       0.75      0.78      0.77       161\n",
      "           2       0.67      0.60      0.63       189\n",
      "           3       0.69      0.67      0.68       171\n",
      "           4       0.68      0.52      0.59       217\n",
      "           5       0.71      0.79      0.74       150\n",
      "           6       0.93      0.96      0.94       162\n",
      "           7       0.58      0.63      0.61       155\n",
      "\n",
      "    accuracy                           0.70      1338\n",
      "   macro avg       0.70      0.72      0.71      1338\n",
      "weighted avg       0.70      0.70      0.70      1338\n",
      "\n",
      "Validation Loss: 0.8707\n",
      "Epoch 83, Batch 10, Loss: 1.1022\n",
      "Epoch 83, Batch 20, Loss: 1.0992\n",
      "Accuracy on images: 68.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71       155\n",
      "           1       0.79      0.78      0.78       170\n",
      "           2       0.58      0.61      0.60       158\n",
      "           3       0.65      0.61      0.63       177\n",
      "           4       0.56      0.60      0.58       155\n",
      "           5       0.69      0.72      0.71       159\n",
      "           6       0.92      0.94      0.93       163\n",
      "           7       0.65      0.54      0.59       201\n",
      "\n",
      "    accuracy                           0.69      1338\n",
      "   macro avg       0.69      0.69      0.69      1338\n",
      "weighted avg       0.69      0.69      0.69      1338\n",
      "\n",
      "Validation Loss: 0.8747\n",
      "Epoch 84, Batch 10, Loss: 1.0658\n",
      "Epoch 84, Batch 20, Loss: 1.0767\n",
      "Accuracy on images: 70.63%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.83      0.68       117\n",
      "           1       0.81      0.80      0.80       169\n",
      "           2       0.55      0.65      0.60       141\n",
      "           3       0.72      0.56      0.63       213\n",
      "           4       0.64      0.61      0.62       176\n",
      "           5       0.74      0.78      0.76       160\n",
      "           6       0.92      0.96      0.94       161\n",
      "           7       0.69      0.58      0.63       201\n",
      "\n",
      "    accuracy                           0.71      1338\n",
      "   macro avg       0.71      0.72      0.71      1338\n",
      "weighted avg       0.71      0.71      0.70      1338\n",
      "\n",
      "Validation Loss: 0.8388\n",
      "Epoch 85, Batch 10, Loss: 1.0365\n",
      "Epoch 85, Batch 20, Loss: 1.1027\n",
      "Accuracy on images: 69.51%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.70       138\n",
      "           1       0.78      0.80      0.79       163\n",
      "           2       0.51      0.63      0.57       136\n",
      "           3       0.62      0.65      0.63       161\n",
      "           4       0.59      0.53      0.56       188\n",
      "           5       0.80      0.66      0.72       201\n",
      "           6       0.92      0.91      0.92       169\n",
      "           7       0.69      0.64      0.66       182\n",
      "\n",
      "    accuracy                           0.70      1338\n",
      "   macro avg       0.70      0.70      0.69      1338\n",
      "weighted avg       0.70      0.70      0.70      1338\n",
      "\n",
      "Validation Loss: 0.8580\n",
      "Epoch 86, Batch 10, Loss: 0.9833\n",
      "Epoch 86, Batch 20, Loss: 1.0557\n",
      "Accuracy on images: 72.12%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.82      0.73       134\n",
      "           1       0.85      0.74      0.79       192\n",
      "           2       0.62      0.65      0.64       161\n",
      "           3       0.70      0.64      0.67       182\n",
      "           4       0.54      0.59      0.57       153\n",
      "           5       0.77      0.74      0.75       174\n",
      "           6       0.97      0.93      0.95       175\n",
      "           7       0.65      0.66      0.66       167\n",
      "\n",
      "    accuracy                           0.72      1338\n",
      "   macro avg       0.72      0.72      0.72      1338\n",
      "weighted avg       0.73      0.72      0.72      1338\n",
      "\n",
      "Validation Loss: 0.8044\n",
      "Epoch 87, Batch 10, Loss: 1.0147\n",
      "Epoch 87, Batch 20, Loss: 1.0434\n",
      "Accuracy on images: 71.23%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       168\n",
      "           1       0.83      0.76      0.79       182\n",
      "           2       0.57      0.63      0.60       150\n",
      "           3       0.74      0.59      0.66       211\n",
      "           4       0.47      0.75      0.58       106\n",
      "           5       0.79      0.75      0.77       175\n",
      "           6       0.92      0.96      0.94       160\n",
      "           7       0.67      0.61      0.64       186\n",
      "\n",
      "    accuracy                           0.71      1338\n",
      "   macro avg       0.71      0.72      0.71      1338\n",
      "weighted avg       0.73      0.71      0.71      1338\n",
      "\n",
      "Validation Loss: 0.8144\n",
      "Epoch 88, Batch 10, Loss: 1.0423\n",
      "Epoch 88, Batch 20, Loss: 1.0529\n",
      "Accuracy on images: 69.73%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       173\n",
      "           1       0.83      0.71      0.77       196\n",
      "           2       0.58      0.56      0.57       173\n",
      "           3       0.56      0.76      0.65       123\n",
      "           4       0.59      0.54      0.57       183\n",
      "           5       0.74      0.75      0.75       163\n",
      "           6       0.97      0.90      0.93       180\n",
      "           7       0.60      0.68      0.63       147\n",
      "\n",
      "    accuracy                           0.70      1338\n",
      "   macro avg       0.70      0.70      0.70      1338\n",
      "weighted avg       0.71      0.70      0.70      1338\n",
      "\n",
      "Validation Loss: 0.8314\n",
      "Epoch 89, Batch 10, Loss: 1.0412\n",
      "Epoch 89, Batch 20, Loss: 1.0450\n",
      "Accuracy on images: 71.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       123\n",
      "           1       0.84      0.80      0.82       176\n",
      "           2       0.57      0.64      0.60       148\n",
      "           3       0.69      0.62      0.66       186\n",
      "           4       0.62      0.57      0.60       182\n",
      "           5       0.78      0.69      0.73       190\n",
      "           6       0.95      0.96      0.95       165\n",
      "           7       0.67      0.67      0.67       168\n",
      "\n",
      "    accuracy                           0.72      1338\n",
      "   macro avg       0.72      0.72      0.72      1338\n",
      "weighted avg       0.72      0.72      0.72      1338\n",
      "\n",
      "Validation Loss: 0.8102\n",
      "Epoch 90, Batch 10, Loss: 1.0581\n",
      "Epoch 90, Batch 20, Loss: 1.0874\n",
      "Accuracy on images: 70.85%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70       129\n",
      "           1       0.82      0.73      0.77       188\n",
      "           2       0.53      0.66      0.59       135\n",
      "           3       0.67      0.66      0.66       170\n",
      "           4       0.54      0.62      0.58       146\n",
      "           5       0.80      0.71      0.75       187\n",
      "           6       0.92      0.97      0.94       157\n",
      "           7       0.78      0.58      0.66       226\n",
      "\n",
      "    accuracy                           0.71      1338\n",
      "   macro avg       0.71      0.72      0.71      1338\n",
      "weighted avg       0.72      0.71      0.71      1338\n",
      "\n",
      "Validation Loss: 0.8138\n",
      "Epoch 91, Batch 10, Loss: 1.0200\n",
      "Epoch 91, Batch 20, Loss: 1.0265\n",
      "Accuracy on images: 71.23%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69       150\n",
      "           1       0.75      0.84      0.79       149\n",
      "           2       0.61      0.61      0.61       167\n",
      "           3       0.78      0.63      0.70       207\n",
      "           4       0.54      0.64      0.58       141\n",
      "           5       0.78      0.72      0.75       180\n",
      "           6       0.95      0.91      0.93       174\n",
      "           7       0.64      0.63      0.63       170\n",
      "\n",
      "    accuracy                           0.71      1338\n",
      "   macro avg       0.71      0.71      0.71      1338\n",
      "weighted avg       0.72      0.71      0.71      1338\n",
      "\n",
      "Validation Loss: 0.8251\n",
      "Epoch 92, Batch 10, Loss: 1.0452\n",
      "Epoch 92, Batch 20, Loss: 1.0156\n",
      "Accuracy on images: 72.27%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74       140\n",
      "           1       0.78      0.79      0.79       164\n",
      "           2       0.69      0.59      0.64       197\n",
      "           3       0.65      0.67      0.66       161\n",
      "           4       0.57      0.63      0.60       150\n",
      "           5       0.76      0.77      0.77       164\n",
      "           6       0.93      0.95      0.94       165\n",
      "           7       0.73      0.62      0.67       197\n",
      "\n",
      "    accuracy                           0.72      1338\n",
      "   macro avg       0.72      0.73      0.72      1338\n",
      "weighted avg       0.72      0.72      0.72      1338\n",
      "\n",
      "Validation Loss: 0.7848\n",
      "Epoch 93, Batch 10, Loss: 0.9982\n",
      "Epoch 93, Batch 20, Loss: 1.0331\n",
      "Accuracy on images: 71.97%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.74      0.70       149\n",
      "           1       0.77      0.84      0.80       153\n",
      "           2       0.58      0.70      0.64       140\n",
      "           3       0.69      0.68      0.69       170\n",
      "           4       0.72      0.54      0.62       221\n",
      "           5       0.78      0.74      0.76       176\n",
      "           6       0.93      0.92      0.93       170\n",
      "           7       0.62      0.66      0.64       159\n",
      "\n",
      "    accuracy                           0.72      1338\n",
      "   macro avg       0.72      0.73      0.72      1338\n",
      "weighted avg       0.72      0.72      0.72      1338\n",
      "\n",
      "Validation Loss: 0.8046\n",
      "Epoch 94, Batch 10, Loss: 1.0074\n",
      "Epoch 94, Batch 20, Loss: 1.0040\n",
      "Accuracy on images: 70.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.67       169\n",
      "           1       0.79      0.70      0.74       188\n",
      "           2       0.57      0.59      0.58       162\n",
      "           3       0.60      0.77      0.68       132\n",
      "           4       0.55      0.58      0.57       158\n",
      "           5       0.77      0.81      0.79       159\n",
      "           6       0.91      0.96      0.94       158\n",
      "           7       0.76      0.60      0.67       212\n",
      "\n",
      "    accuracy                           0.70      1338\n",
      "   macro avg       0.70      0.71      0.70      1338\n",
      "weighted avg       0.71      0.70      0.70      1338\n",
      "\n",
      "Validation Loss: 0.8213\n",
      "Epoch 95, Batch 10, Loss: 1.0748\n",
      "Epoch 95, Batch 20, Loss: 1.0109\n",
      "Accuracy on images: 74.51%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73       157\n",
      "           1       0.83      0.82      0.82       170\n",
      "           2       0.68      0.58      0.63       198\n",
      "           3       0.74      0.75      0.74       164\n",
      "           4       0.63      0.68      0.65       157\n",
      "           5       0.80      0.78      0.79       171\n",
      "           6       0.97      0.91      0.94       178\n",
      "           7       0.60      0.71      0.65       143\n",
      "\n",
      "    accuracy                           0.75      1338\n",
      "   macro avg       0.75      0.75      0.74      1338\n",
      "weighted avg       0.75      0.75      0.75      1338\n",
      "\n",
      "Validation Loss: 0.7747\n",
      "Epoch 96, Batch 10, Loss: 0.9861\n",
      "Epoch 96, Batch 20, Loss: 1.0641\n",
      "Accuracy on images: 72.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.70       154\n",
      "           1       0.81      0.76      0.78       177\n",
      "           2       0.60      0.63      0.61       159\n",
      "           3       0.71      0.66      0.68       179\n",
      "           4       0.57      0.66      0.61       146\n",
      "           5       0.72      0.76      0.74       160\n",
      "           6       0.95      0.95      0.95       166\n",
      "           7       0.74      0.63      0.68       197\n",
      "\n",
      "    accuracy                           0.72      1338\n",
      "   macro avg       0.72      0.72      0.72      1338\n",
      "weighted avg       0.73      0.72      0.72      1338\n",
      "\n",
      "Validation Loss: 0.7734\n",
      "Epoch 97, Batch 10, Loss: 0.9743\n",
      "Epoch 97, Batch 20, Loss: 1.0319\n",
      "Accuracy on images: 74.22%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.75       139\n",
      "           1       0.83      0.80      0.81       173\n",
      "           2       0.60      0.70      0.64       143\n",
      "           3       0.78      0.66      0.72       198\n",
      "           4       0.63      0.67      0.65       159\n",
      "           5       0.75      0.77      0.76       162\n",
      "           6       0.93      0.93      0.93       167\n",
      "           7       0.73      0.62      0.67       197\n",
      "\n",
      "    accuracy                           0.74      1338\n",
      "   macro avg       0.74      0.75      0.74      1338\n",
      "weighted avg       0.75      0.74      0.74      1338\n",
      "\n",
      "Validation Loss: 0.7758\n",
      "Epoch 98, Batch 10, Loss: 0.9662\n",
      "Epoch 98, Batch 20, Loss: 1.0177\n",
      "Accuracy on images: 72.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71       150\n",
      "           1       0.86      0.75      0.80       192\n",
      "           2       0.70      0.58      0.63       204\n",
      "           3       0.66      0.73      0.69       151\n",
      "           4       0.52      0.70      0.60       124\n",
      "           5       0.73      0.74      0.73       165\n",
      "           6       0.96      0.91      0.94       177\n",
      "           7       0.67      0.64      0.65       175\n",
      "\n",
      "    accuracy                           0.72      1338\n",
      "   macro avg       0.72      0.72      0.72      1338\n",
      "weighted avg       0.73      0.72      0.72      1338\n",
      "\n",
      "Validation Loss: 0.7549\n",
      "Epoch 99, Batch 10, Loss: 0.9815\n",
      "Epoch 99, Batch 20, Loss: 0.9891\n",
      "Accuracy on images: 74.14%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.71       147\n",
      "           1       0.79      0.81      0.80       162\n",
      "           2       0.64      0.66      0.65       164\n",
      "           3       0.75      0.65      0.70       194\n",
      "           4       0.56      0.69      0.62       134\n",
      "           5       0.79      0.78      0.79       169\n",
      "           6       0.96      0.92      0.94       175\n",
      "           7       0.76      0.66      0.71       193\n",
      "\n",
      "    accuracy                           0.74      1338\n",
      "   macro avg       0.74      0.74      0.74      1338\n",
      "weighted avg       0.75      0.74      0.74      1338\n",
      "\n",
      "Validation Loss: 0.7512\n",
      "Epoch 100, Batch 10, Loss: 0.9737\n",
      "Epoch 100, Batch 20, Loss: 1.0336\n",
      "Accuracy on images: 71.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.69      0.73       185\n",
      "           1       0.67      0.83      0.74       135\n",
      "           2       0.65      0.66      0.66       167\n",
      "           3       0.74      0.62      0.68       199\n",
      "           4       0.56      0.65      0.60       145\n",
      "           5       0.69      0.83      0.76       139\n",
      "           6       0.94      0.92      0.93       170\n",
      "           7       0.71      0.60      0.65       198\n",
      "\n",
      "    accuracy                           0.72      1338\n",
      "   macro avg       0.72      0.73      0.72      1338\n",
      "weighted avg       0.72      0.72      0.72      1338\n",
      "\n",
      "Validation Loss: 0.7866\n",
      "Epoch 101, Batch 10, Loss: 0.9411\n",
      "Epoch 101, Batch 20, Loss: 1.0280\n",
      "Accuracy on images: 73.17%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.72       151\n",
      "           1       0.81      0.78      0.80       175\n",
      "           2       0.61      0.68      0.65       151\n",
      "           3       0.79      0.65      0.71       203\n",
      "           4       0.46      0.74      0.57       104\n",
      "           5       0.82      0.72      0.77       189\n",
      "           6       0.95      0.95      0.95       166\n",
      "           7       0.73      0.61      0.66       199\n",
      "\n",
      "    accuracy                           0.73      1338\n",
      "   macro avg       0.73      0.74      0.73      1338\n",
      "weighted avg       0.75      0.73      0.74      1338\n",
      "\n",
      "Validation Loss: 0.7487\n",
      "Epoch 102, Batch 10, Loss: 0.9508\n",
      "Epoch 102, Batch 20, Loss: 1.0527\n",
      "Accuracy on images: 74.29%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.80      0.72       137\n",
      "           1       0.82      0.73      0.77       187\n",
      "           2       0.66      0.63      0.65       176\n",
      "           3       0.77      0.69      0.73       186\n",
      "           4       0.57      0.68      0.62       142\n",
      "           5       0.77      0.81      0.79       158\n",
      "           6       0.95      0.95      0.95       168\n",
      "           7       0.74      0.67      0.70       184\n",
      "\n",
      "    accuracy                           0.74      1338\n",
      "   macro avg       0.74      0.75      0.74      1338\n",
      "weighted avg       0.75      0.74      0.74      1338\n",
      "\n",
      "Validation Loss: 0.7347\n",
      "Epoch 103, Batch 10, Loss: 0.9316\n",
      "Epoch 103, Batch 20, Loss: 1.0525\n",
      "Accuracy on images: 74.14%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.65      0.70       194\n",
      "           1       0.81      0.83      0.82       164\n",
      "           2       0.68      0.64      0.66       178\n",
      "           3       0.72      0.70      0.71       173\n",
      "           4       0.61      0.65      0.63       156\n",
      "           5       0.76      0.81      0.79       156\n",
      "           6       0.93      0.94      0.94       166\n",
      "           7       0.65      0.72      0.68       151\n",
      "\n",
      "    accuracy                           0.74      1338\n",
      "   macro avg       0.74      0.74      0.74      1338\n",
      "weighted avg       0.74      0.74      0.74      1338\n",
      "\n",
      "Validation Loss: 0.7321\n",
      "Epoch 104, Batch 10, Loss: 0.9892\n",
      "Epoch 104, Batch 20, Loss: 0.9928\n",
      "Accuracy on images: 74.22%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73       148\n",
      "           1       0.81      0.75      0.78       182\n",
      "           2       0.67      0.67      0.67       168\n",
      "           3       0.78      0.72      0.75       181\n",
      "           4       0.64      0.66      0.65       161\n",
      "           5       0.72      0.83      0.77       146\n",
      "           6       0.92      0.97      0.95       158\n",
      "           7       0.70      0.60      0.65       194\n",
      "\n",
      "    accuracy                           0.74      1338\n",
      "   macro avg       0.74      0.75      0.74      1338\n",
      "weighted avg       0.74      0.74      0.74      1338\n",
      "\n",
      "Validation Loss: 0.7604\n",
      "Epoch 105, Batch 10, Loss: 0.9338\n",
      "Epoch 105, Batch 20, Loss: 0.9665\n",
      "Accuracy on images: 76.38%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.77       149\n",
      "           1       0.83      0.80      0.81       172\n",
      "           2       0.75      0.65      0.70       194\n",
      "           3       0.78      0.69      0.73       189\n",
      "           4       0.55      0.71      0.62       130\n",
      "           5       0.79      0.86      0.83       153\n",
      "           6       0.95      0.96      0.95       164\n",
      "           7       0.74      0.67      0.70       187\n",
      "\n",
      "    accuracy                           0.76      1338\n",
      "   macro avg       0.76      0.77      0.76      1338\n",
      "weighted avg       0.77      0.76      0.76      1338\n",
      "\n",
      "Validation Loss: 0.7371\n",
      "Epoch 106, Batch 10, Loss: 0.9122\n",
      "Epoch 106, Batch 20, Loss: 0.9451\n",
      "Accuracy on images: 76.16%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.74       151\n",
      "           1       0.80      0.83      0.81       162\n",
      "           2       0.67      0.66      0.67       171\n",
      "           3       0.77      0.67      0.72       192\n",
      "           4       0.64      0.70      0.67       153\n",
      "           5       0.80      0.83      0.81       162\n",
      "           6       0.96      0.95      0.96       168\n",
      "           7       0.74      0.69      0.71       179\n",
      "\n",
      "    accuracy                           0.76      1338\n",
      "   macro avg       0.76      0.76      0.76      1338\n",
      "weighted avg       0.76      0.76      0.76      1338\n",
      "\n",
      "Validation Loss: 0.7137\n",
      "Epoch 107, Batch 10, Loss: 0.9402\n",
      "Epoch 107, Batch 20, Loss: 0.9344\n",
      "Accuracy on images: 74.14%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74       169\n",
      "           1       0.84      0.75      0.79       187\n",
      "           2       0.54      0.68      0.60       133\n",
      "           3       0.72      0.71      0.72       171\n",
      "           4       0.63      0.61      0.62       174\n",
      "           5       0.75      0.79      0.77       159\n",
      "           6       0.93      0.94      0.94       166\n",
      "           7       0.76      0.71      0.73       179\n",
      "\n",
      "    accuracy                           0.74      1338\n",
      "   macro avg       0.74      0.74      0.74      1338\n",
      "weighted avg       0.75      0.74      0.74      1338\n",
      "\n",
      "Validation Loss: 0.7260\n",
      "Epoch 108, Batch 10, Loss: 0.9786\n",
      "Epoch 108, Batch 20, Loss: 0.9340\n",
      "Accuracy on images: 75.78%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77       164\n",
      "           1       0.90      0.76      0.82       197\n",
      "           2       0.63      0.62      0.63       170\n",
      "           3       0.69      0.70      0.69       164\n",
      "           4       0.66      0.73      0.69       150\n",
      "           5       0.74      0.81      0.77       151\n",
      "           6       0.93      0.97      0.95       161\n",
      "           7       0.76      0.70      0.73       181\n",
      "\n",
      "    accuracy                           0.76      1338\n",
      "   macro avg       0.76      0.76      0.76      1338\n",
      "weighted avg       0.76      0.76      0.76      1338\n",
      "\n",
      "Validation Loss: 0.7186\n",
      "Epoch 109, Batch 10, Loss: 0.9113\n",
      "Epoch 109, Batch 20, Loss: 0.9900\n",
      "Accuracy on images: 74.29%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.81      0.72       134\n",
      "           1       0.77      0.88      0.82       145\n",
      "           2       0.63      0.64      0.64       165\n",
      "           3       0.71      0.66      0.68       178\n",
      "           4       0.70      0.61      0.65       192\n",
      "           5       0.77      0.80      0.79       161\n",
      "           6       0.97      0.94      0.96       172\n",
      "           7       0.74      0.65      0.70       191\n",
      "\n",
      "    accuracy                           0.74      1338\n",
      "   macro avg       0.74      0.75      0.74      1338\n",
      "weighted avg       0.74      0.74      0.74      1338\n",
      "\n",
      "Validation Loss: 0.7280\n",
      "Epoch 110, Batch 10, Loss: 0.8913\n",
      "Epoch 110, Batch 20, Loss: 1.0103\n",
      "Accuracy on images: 75.71%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76       175\n",
      "           1       0.81      0.81      0.81       166\n",
      "           2       0.63      0.66      0.65       160\n",
      "           3       0.69      0.71      0.70       164\n",
      "           4       0.63      0.74      0.68       141\n",
      "           5       0.75      0.84      0.79       149\n",
      "           6       0.96      0.96      0.96       167\n",
      "           7       0.81      0.63      0.71       216\n",
      "\n",
      "    accuracy                           0.76      1338\n",
      "   macro avg       0.76      0.76      0.76      1338\n",
      "weighted avg       0.76      0.76      0.76      1338\n",
      "\n",
      "Validation Loss: 0.6880\n",
      "Epoch 111, Batch 10, Loss: 0.9544\n",
      "Epoch 111, Batch 20, Loss: 1.0031\n",
      "Accuracy on images: 74.07%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.66      0.73       208\n",
      "           1       0.80      0.78      0.79       170\n",
      "           2       0.61      0.69      0.65       147\n",
      "           3       0.82      0.65      0.72       211\n",
      "           4       0.54      0.67      0.60       136\n",
      "           5       0.75      0.88      0.81       142\n",
      "           6       0.93      0.95      0.94       164\n",
      "           7       0.66      0.69      0.68       160\n",
      "\n",
      "    accuracy                           0.74      1338\n",
      "   macro avg       0.74      0.75      0.74      1338\n",
      "weighted avg       0.75      0.74      0.74      1338\n",
      "\n",
      "Validation Loss: 0.7403\n",
      "Epoch 112, Batch 10, Loss: 0.9428\n",
      "Epoch 112, Batch 20, Loss: 0.9550\n",
      "Accuracy on images: 75.19%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       176\n",
      "           1       0.76      0.82      0.79       154\n",
      "           2       0.64      0.72      0.68       150\n",
      "           3       0.69      0.71      0.70       162\n",
      "           4       0.66      0.68      0.67       164\n",
      "           5       0.81      0.80      0.81       168\n",
      "           6       0.93      0.93      0.93       167\n",
      "           7       0.76      0.64      0.70       197\n",
      "\n",
      "    accuracy                           0.75      1338\n",
      "   macro avg       0.75      0.75      0.75      1338\n",
      "weighted avg       0.75      0.75      0.75      1338\n",
      "\n",
      "Validation Loss: 0.6903\n",
      "Epoch 113, Batch 10, Loss: 0.9570\n",
      "Epoch 113, Batch 20, Loss: 0.9642\n",
      "Accuracy on images: 74.51%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72       142\n",
      "           1       0.75      0.81      0.78       154\n",
      "           2       0.72      0.64      0.68       190\n",
      "           3       0.73      0.69      0.71       177\n",
      "           4       0.62      0.67      0.64       153\n",
      "           5       0.84      0.74      0.79       188\n",
      "           6       0.96      0.93      0.95       173\n",
      "           7       0.67      0.70      0.69       161\n",
      "\n",
      "    accuracy                           0.75      1338\n",
      "   macro avg       0.75      0.75      0.74      1338\n",
      "weighted avg       0.75      0.75      0.75      1338\n",
      "\n",
      "Validation Loss: 0.7201\n",
      "Epoch 114, Batch 10, Loss: 0.9325\n",
      "Epoch 114, Batch 20, Loss: 0.9773\n",
      "Accuracy on images: 76.98%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76       160\n",
      "           1       0.80      0.91      0.85       148\n",
      "           2       0.74      0.69      0.71       182\n",
      "           3       0.75      0.69      0.72       182\n",
      "           4       0.69      0.67      0.68       173\n",
      "           5       0.84      0.77      0.80       182\n",
      "           6       0.93      0.96      0.94       162\n",
      "           7       0.65      0.73      0.69       149\n",
      "\n",
      "    accuracy                           0.77      1338\n",
      "   macro avg       0.77      0.77      0.77      1338\n",
      "weighted avg       0.77      0.77      0.77      1338\n",
      "\n",
      "Validation Loss: 0.6629\n",
      "Epoch 115, Batch 10, Loss: 0.9525\n",
      "Epoch 115, Batch 20, Loss: 1.0229\n",
      "Accuracy on images: 75.19%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.87      0.76       130\n",
      "           1       0.76      0.82      0.79       155\n",
      "           2       0.66      0.71      0.69       156\n",
      "           3       0.78      0.68      0.72       192\n",
      "           4       0.59      0.64      0.62       154\n",
      "           5       0.78      0.81      0.80       162\n",
      "           6       0.95      0.93      0.94       171\n",
      "           7       0.81      0.62      0.70       218\n",
      "\n",
      "    accuracy                           0.75      1338\n",
      "   macro avg       0.75      0.76      0.75      1338\n",
      "weighted avg       0.76      0.75      0.75      1338\n",
      "\n",
      "Validation Loss: 0.7239\n",
      "Epoch 116, Batch 10, Loss: 0.9189\n",
      "Epoch 116, Batch 20, Loss: 0.9538\n",
      "Accuracy on images: 75.64%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.74       151\n",
      "           1       0.81      0.80      0.81       169\n",
      "           2       0.64      0.65      0.64       165\n",
      "           3       0.72      0.67      0.70       181\n",
      "           4       0.68      0.71      0.69       160\n",
      "           5       0.81      0.83      0.82       163\n",
      "           6       0.92      0.97      0.95       158\n",
      "           7       0.76      0.66      0.71       191\n",
      "\n",
      "    accuracy                           0.76      1338\n",
      "   macro avg       0.76      0.76      0.76      1338\n",
      "weighted avg       0.76      0.76      0.76      1338\n",
      "\n",
      "Validation Loss: 0.7054\n",
      "Epoch 117, Batch 10, Loss: 0.9349\n",
      "Epoch 117, Batch 20, Loss: 0.9122\n",
      "Accuracy on images: 76.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73       158\n",
      "           1       0.81      0.80      0.81       168\n",
      "           2       0.65      0.73      0.69       151\n",
      "           3       0.72      0.76      0.74       159\n",
      "           4       0.66      0.68      0.67       161\n",
      "           5       0.85      0.79      0.82       179\n",
      "           6       0.99      0.87      0.93       189\n",
      "           7       0.76      0.73      0.74       173\n",
      "\n",
      "    accuracy                           0.77      1338\n",
      "   macro avg       0.77      0.77      0.77      1338\n",
      "weighted avg       0.78      0.77      0.77      1338\n",
      "\n",
      "Validation Loss: 0.6772\n",
      "Epoch 118, Batch 10, Loss: 0.8785\n",
      "Epoch 118, Batch 20, Loss: 0.9702\n",
      "Accuracy on images: 78.85%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       162\n",
      "           1       0.78      0.84      0.81       156\n",
      "           2       0.68      0.71      0.70       162\n",
      "           3       0.83      0.72      0.77       192\n",
      "           4       0.69      0.70      0.69       165\n",
      "           5       0.87      0.84      0.86       173\n",
      "           6       0.97      0.95      0.96       170\n",
      "           7       0.71      0.76      0.74       158\n",
      "\n",
      "    accuracy                           0.79      1338\n",
      "   macro avg       0.79      0.79      0.79      1338\n",
      "weighted avg       0.79      0.79      0.79      1338\n",
      "\n",
      "Validation Loss: 0.6433\n",
      "Epoch 119, Batch 10, Loss: 0.8727\n",
      "Epoch 119, Batch 20, Loss: 0.9538\n",
      "Accuracy on images: 78.18%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.75       162\n",
      "           1       0.85      0.80      0.83       177\n",
      "           2       0.71      0.68      0.70       177\n",
      "           3       0.74      0.75      0.75       163\n",
      "           4       0.64      0.78      0.70       138\n",
      "           5       0.83      0.82      0.82       169\n",
      "           6       0.98      0.96      0.97       170\n",
      "           7       0.77      0.71      0.74       182\n",
      "\n",
      "    accuracy                           0.78      1338\n",
      "   macro avg       0.78      0.78      0.78      1338\n",
      "weighted avg       0.79      0.78      0.78      1338\n",
      "\n",
      "Validation Loss: 0.6501\n",
      "Epoch 120, Batch 10, Loss: 0.9096\n",
      "Epoch 120, Batch 20, Loss: 0.9079\n",
      "Accuracy on images: 76.61%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76       148\n",
      "           1       0.78      0.79      0.79       165\n",
      "           2       0.68      0.70      0.69       164\n",
      "           3       0.76      0.76      0.76       167\n",
      "           4       0.73      0.66      0.69       185\n",
      "           5       0.77      0.79      0.78       163\n",
      "           6       0.95      0.99      0.97       160\n",
      "           7       0.73      0.66      0.69       186\n",
      "\n",
      "    accuracy                           0.77      1338\n",
      "   macro avg       0.77      0.77      0.77      1338\n",
      "weighted avg       0.77      0.77      0.76      1338\n",
      "\n",
      "Validation Loss: 0.6791\n",
      "Epoch 121, Batch 10, Loss: 0.8746\n",
      "Epoch 121, Batch 20, Loss: 1.0081\n",
      "Accuracy on images: 78.85%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.78       140\n",
      "           1       0.81      0.87      0.84       156\n",
      "           2       0.68      0.76      0.72       150\n",
      "           3       0.80      0.75      0.77       179\n",
      "           4       0.72      0.70      0.71       173\n",
      "           5       0.84      0.75      0.79       189\n",
      "           6       0.98      0.96      0.97       170\n",
      "           7       0.76      0.70      0.73       181\n",
      "\n",
      "    accuracy                           0.79      1338\n",
      "   macro avg       0.79      0.79      0.79      1338\n",
      "weighted avg       0.79      0.79      0.79      1338\n",
      "\n",
      "Validation Loss: 0.6526\n",
      "Epoch 122, Batch 10, Loss: 0.8740\n",
      "Epoch 122, Batch 20, Loss: 0.8744\n",
      "Accuracy on images: 76.68%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       165\n",
      "           1       0.81      0.81      0.81       166\n",
      "           2       0.70      0.72      0.71       164\n",
      "           3       0.75      0.71      0.73       177\n",
      "           4       0.60      0.72      0.66       141\n",
      "           5       0.78      0.81      0.80       161\n",
      "           6       0.97      0.96      0.96       169\n",
      "           7       0.77      0.66      0.71       195\n",
      "\n",
      "    accuracy                           0.77      1338\n",
      "   macro avg       0.77      0.77      0.77      1338\n",
      "weighted avg       0.77      0.77      0.77      1338\n",
      "\n",
      "Validation Loss: 0.6290\n",
      "Epoch 123, Batch 10, Loss: 0.8777\n",
      "Epoch 123, Batch 20, Loss: 0.9551\n",
      "Accuracy on images: 77.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77       155\n",
      "           1       0.77      0.85      0.81       150\n",
      "           2       0.73      0.67      0.70       183\n",
      "           3       0.81      0.69      0.75       198\n",
      "           4       0.64      0.70      0.67       152\n",
      "           5       0.84      0.77      0.80       183\n",
      "           6       0.94      0.98      0.96       161\n",
      "           7       0.70      0.76      0.73       156\n",
      "\n",
      "    accuracy                           0.77      1338\n",
      "   macro avg       0.77      0.78      0.77      1338\n",
      "weighted avg       0.77      0.77      0.77      1338\n",
      "\n",
      "Validation Loss: 0.6707\n",
      "Epoch 124, Batch 10, Loss: 0.9248\n",
      "Epoch 124, Batch 20, Loss: 0.8687\n",
      "Accuracy on images: 77.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76       146\n",
      "           1       0.75      0.85      0.80       148\n",
      "           2       0.65      0.71      0.68       154\n",
      "           3       0.77      0.67      0.72       190\n",
      "           4       0.73      0.69      0.71       177\n",
      "           5       0.81      0.80      0.80       169\n",
      "           6       0.95      0.99      0.97       161\n",
      "           7       0.79      0.69      0.74       193\n",
      "\n",
      "    accuracy                           0.77      1338\n",
      "   macro avg       0.77      0.78      0.77      1338\n",
      "weighted avg       0.77      0.77      0.77      1338\n",
      "\n",
      "Validation Loss: 0.6559\n",
      "Epoch 125, Batch 10, Loss: 0.9096\n",
      "Epoch 125, Batch 20, Loss: 0.9271\n",
      "Accuracy on images: 80.04%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77       156\n",
      "           1       0.83      0.83      0.83       167\n",
      "           2       0.74      0.74      0.74       170\n",
      "           3       0.78      0.75      0.77       174\n",
      "           4       0.69      0.77      0.73       150\n",
      "           5       0.86      0.82      0.84       175\n",
      "           6       0.96      0.99      0.98       163\n",
      "           7       0.79      0.73      0.76       183\n",
      "\n",
      "    accuracy                           0.80      1338\n",
      "   macro avg       0.80      0.80      0.80      1338\n",
      "weighted avg       0.80      0.80      0.80      1338\n",
      "\n",
      "Validation Loss: 0.6169\n",
      "Epoch 126, Batch 10, Loss: 0.8719\n",
      "Epoch 126, Batch 20, Loss: 0.9175\n",
      "Accuracy on images: 77.80%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76       165\n",
      "           1       0.83      0.79      0.81       175\n",
      "           2       0.68      0.70      0.69       165\n",
      "           3       0.71      0.77      0.74       154\n",
      "           4       0.72      0.69      0.70       174\n",
      "           5       0.82      0.79      0.81       173\n",
      "           6       0.98      0.97      0.98       169\n",
      "           7       0.73      0.75      0.74       163\n",
      "\n",
      "    accuracy                           0.78      1338\n",
      "   macro avg       0.78      0.78      0.78      1338\n",
      "weighted avg       0.78      0.78      0.78      1338\n",
      "\n",
      "Validation Loss: 0.6356\n",
      "Epoch 127, Batch 10, Loss: 0.9161\n",
      "Epoch 127, Batch 20, Loss: 0.8668\n",
      "Accuracy on images: 78.77%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.76       126\n",
      "           1       0.84      0.79      0.81       177\n",
      "           2       0.64      0.77      0.70       140\n",
      "           3       0.79      0.73      0.76       182\n",
      "           4       0.73      0.68      0.71       179\n",
      "           5       0.89      0.81      0.85       182\n",
      "           6       0.95      0.98      0.96       161\n",
      "           7       0.80      0.70      0.75       191\n",
      "\n",
      "    accuracy                           0.79      1338\n",
      "   macro avg       0.79      0.79      0.79      1338\n",
      "weighted avg       0.79      0.79      0.79      1338\n",
      "\n",
      "Validation Loss: 0.6377\n",
      "Epoch 128, Batch 10, Loss: 0.8451\n",
      "Epoch 128, Batch 20, Loss: 0.8934\n",
      "Accuracy on images: 75.19%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73       172\n",
      "           1       0.77      0.77      0.77       167\n",
      "           2       0.73      0.64      0.68       192\n",
      "           3       0.71      0.75      0.73       157\n",
      "           4       0.70      0.64      0.67       182\n",
      "           5       0.76      0.84      0.80       152\n",
      "           6       0.93      0.94      0.94       166\n",
      "           7       0.67      0.75      0.71       150\n",
      "\n",
      "    accuracy                           0.75      1338\n",
      "   macro avg       0.75      0.76      0.75      1338\n",
      "weighted avg       0.75      0.75      0.75      1338\n",
      "\n",
      "Validation Loss: 0.6848\n",
      "Epoch 129, Batch 10, Loss: 0.8802\n",
      "Epoch 129, Batch 20, Loss: 0.8909\n",
      "Accuracy on images: 80.12%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78       167\n",
      "           1       0.86      0.83      0.84       174\n",
      "           2       0.65      0.82      0.72       133\n",
      "           3       0.83      0.71      0.76       195\n",
      "           4       0.69      0.78      0.73       147\n",
      "           5       0.80      0.84      0.82       159\n",
      "           6       0.97      0.95      0.96       170\n",
      "           7       0.83      0.73      0.78       193\n",
      "\n",
      "    accuracy                           0.80      1338\n",
      "   macro avg       0.80      0.80      0.80      1338\n",
      "weighted avg       0.81      0.80      0.80      1338\n",
      "\n",
      "Validation Loss: 0.5935\n",
      "Epoch 130, Batch 10, Loss: 0.9164\n",
      "Epoch 130, Batch 20, Loss: 0.9759\n",
      "Accuracy on images: 79.52%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       166\n",
      "           1       0.84      0.80      0.82       177\n",
      "           2       0.76      0.66      0.71       193\n",
      "           3       0.77      0.77      0.77       166\n",
      "           4       0.66      0.84      0.74       131\n",
      "           5       0.83      0.84      0.83       165\n",
      "           6       0.96      0.92      0.94       175\n",
      "           7       0.73      0.75      0.74       165\n",
      "\n",
      "    accuracy                           0.80      1338\n",
      "   macro avg       0.80      0.80      0.79      1338\n",
      "weighted avg       0.80      0.80      0.80      1338\n",
      "\n",
      "Validation Loss: 0.6625\n",
      "Epoch 131, Batch 10, Loss: 0.8590\n",
      "Epoch 131, Batch 20, Loss: 0.9397\n",
      "Accuracy on images: 79.52%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76       149\n",
      "           1       0.86      0.80      0.83       179\n",
      "           2       0.75      0.70      0.72       180\n",
      "           3       0.82      0.74      0.78       185\n",
      "           4       0.62      0.79      0.69       131\n",
      "           5       0.87      0.83      0.85       176\n",
      "           6       0.96      0.96      0.96       166\n",
      "           7       0.77      0.75      0.76       172\n",
      "\n",
      "    accuracy                           0.80      1338\n",
      "   macro avg       0.80      0.80      0.79      1338\n",
      "weighted avg       0.80      0.80      0.80      1338\n",
      "\n",
      "Validation Loss: 0.6157\n",
      "Epoch 132, Batch 10, Loss: 0.8818\n",
      "Epoch 132, Batch 20, Loss: 0.9060\n",
      "Accuracy on images: 81.61%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78       145\n",
      "           1       0.87      0.85      0.86       171\n",
      "           2       0.71      0.88      0.79       136\n",
      "           3       0.78      0.78      0.78       168\n",
      "           4       0.74      0.72      0.73       172\n",
      "           5       0.84      0.84      0.84       167\n",
      "           6       0.98      0.98      0.98       168\n",
      "           7       0.87      0.69      0.77       211\n",
      "\n",
      "    accuracy                           0.82      1338\n",
      "   macro avg       0.82      0.82      0.82      1338\n",
      "weighted avg       0.82      0.82      0.82      1338\n",
      "\n",
      "Validation Loss: 0.6059\n",
      "Epoch 133, Batch 10, Loss: 0.9235\n",
      "Epoch 133, Batch 20, Loss: 0.8460\n",
      "Accuracy on images: 79.52%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.76       147\n",
      "           1       0.82      0.82      0.82       168\n",
      "           2       0.73      0.74      0.74       166\n",
      "           3       0.85      0.78      0.81       183\n",
      "           4       0.71      0.74      0.72       159\n",
      "           5       0.83      0.80      0.82       174\n",
      "           6       0.94      0.95      0.95       165\n",
      "           7       0.76      0.73      0.74       176\n",
      "\n",
      "    accuracy                           0.80      1338\n",
      "   macro avg       0.80      0.80      0.79      1338\n",
      "weighted avg       0.80      0.80      0.80      1338\n",
      "\n",
      "Validation Loss: 0.6040\n",
      "Epoch 134, Batch 10, Loss: 0.8288\n",
      "Epoch 134, Batch 20, Loss: 0.9059\n",
      "Accuracy on images: 77.43%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.78       147\n",
      "           1       0.86      0.74      0.80       194\n",
      "           2       0.76      0.67      0.71       189\n",
      "           3       0.77      0.72      0.74       180\n",
      "           4       0.60      0.77      0.67       130\n",
      "           5       0.81      0.80      0.81       169\n",
      "           6       0.93      0.97      0.95       160\n",
      "           7       0.72      0.72      0.72       169\n",
      "\n",
      "    accuracy                           0.77      1338\n",
      "   macro avg       0.77      0.78      0.77      1338\n",
      "weighted avg       0.78      0.77      0.77      1338\n",
      "\n",
      "Validation Loss: 0.6439\n",
      "Epoch 135, Batch 10, Loss: 0.8791\n",
      "Epoch 135, Batch 20, Loss: 0.8410\n",
      "Accuracy on images: 80.94%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80       159\n",
      "           1       0.78      0.90      0.84       144\n",
      "           2       0.71      0.83      0.76       144\n",
      "           3       0.84      0.75      0.79       188\n",
      "           4       0.72      0.70      0.71       173\n",
      "           5       0.89      0.76      0.82       195\n",
      "           6       0.98      0.97      0.97       168\n",
      "           7       0.77      0.78      0.78       167\n",
      "\n",
      "    accuracy                           0.81      1338\n",
      "   macro avg       0.81      0.81      0.81      1338\n",
      "weighted avg       0.81      0.81      0.81      1338\n",
      "\n",
      "Validation Loss: 0.5801\n",
      "Epoch 136, Batch 10, Loss: 0.9378\n",
      "Epoch 136, Batch 20, Loss: 0.8581\n",
      "Accuracy on images: 80.64%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79       147\n",
      "           1       0.77      0.87      0.82       147\n",
      "           2       0.77      0.81      0.79       161\n",
      "           3       0.87      0.68      0.77       212\n",
      "           4       0.68      0.74      0.71       152\n",
      "           5       0.87      0.82      0.85       176\n",
      "           6       0.98      0.95      0.97       172\n",
      "           7       0.77      0.76      0.77       171\n",
      "\n",
      "    accuracy                           0.81      1338\n",
      "   macro avg       0.81      0.81      0.81      1338\n",
      "weighted avg       0.81      0.81      0.81      1338\n",
      "\n",
      "Validation Loss: 0.6344\n",
      "Epoch 137, Batch 10, Loss: 0.8624\n",
      "Epoch 137, Batch 20, Loss: 0.8736\n",
      "Accuracy on images: 79.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.77       126\n",
      "           1       0.83      0.85      0.84       162\n",
      "           2       0.77      0.70      0.73       187\n",
      "           3       0.82      0.70      0.75       197\n",
      "           4       0.66      0.77      0.71       143\n",
      "           5       0.89      0.84      0.86       177\n",
      "           6       0.95      0.98      0.97       162\n",
      "           7       0.79      0.72      0.75       184\n",
      "\n",
      "    accuracy                           0.80      1338\n",
      "   macro avg       0.80      0.81      0.80      1338\n",
      "weighted avg       0.80      0.80      0.80      1338\n",
      "\n",
      "Validation Loss: 0.6145\n",
      "Epoch 138, Batch 10, Loss: 0.9000\n",
      "Epoch 138, Batch 20, Loss: 0.9325\n",
      "Accuracy on images: 81.32%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       170\n",
      "           1       0.77      0.91      0.83       142\n",
      "           2       0.81      0.76      0.78       179\n",
      "           3       0.79      0.74      0.76       179\n",
      "           4       0.76      0.78      0.77       162\n",
      "           5       0.81      0.87      0.84       156\n",
      "           6       0.97      0.98      0.98       165\n",
      "           7       0.79      0.71      0.75       185\n",
      "\n",
      "    accuracy                           0.81      1338\n",
      "   macro avg       0.81      0.82      0.81      1338\n",
      "weighted avg       0.81      0.81      0.81      1338\n",
      "\n",
      "Validation Loss: 0.5907\n",
      "Epoch 139, Batch 10, Loss: 0.8597\n",
      "Epoch 139, Batch 20, Loss: 0.9188\n",
      "Accuracy on images: 80.94%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80       168\n",
      "           1       0.86      0.84      0.85       171\n",
      "           2       0.78      0.78      0.78       167\n",
      "           3       0.89      0.69      0.78       215\n",
      "           4       0.67      0.79      0.72       142\n",
      "           5       0.80      0.87      0.83       154\n",
      "           6       0.97      0.96      0.96       169\n",
      "           7       0.70      0.78      0.74       152\n",
      "\n",
      "    accuracy                           0.81      1338\n",
      "   macro avg       0.81      0.81      0.81      1338\n",
      "weighted avg       0.82      0.81      0.81      1338\n",
      "\n",
      "Validation Loss: 0.5988\n",
      "Epoch 140, Batch 10, Loss: 0.8287\n",
      "Epoch 140, Batch 20, Loss: 0.9022\n",
      "Accuracy on images: 81.24%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.78       140\n",
      "           1       0.87      0.80      0.84       182\n",
      "           2       0.82      0.75      0.78       183\n",
      "           3       0.78      0.78      0.78       167\n",
      "           4       0.69      0.82      0.75       142\n",
      "           5       0.87      0.85      0.86       171\n",
      "           6       0.96      0.99      0.97       162\n",
      "           7       0.79      0.70      0.74       191\n",
      "\n",
      "    accuracy                           0.81      1338\n",
      "   macro avg       0.81      0.82      0.81      1338\n",
      "weighted avg       0.82      0.81      0.81      1338\n",
      "\n",
      "Validation Loss: 0.5782\n",
      "Epoch 141, Batch 10, Loss: 0.8808\n",
      "Epoch 141, Batch 20, Loss: 0.8359\n",
      "Accuracy on images: 79.45%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81       169\n",
      "           1       0.86      0.84      0.85       170\n",
      "           2       0.73      0.74      0.73       167\n",
      "           3       0.81      0.72      0.77       188\n",
      "           4       0.67      0.83      0.74       135\n",
      "           5       0.83      0.77      0.80       181\n",
      "           6       0.96      0.91      0.94       176\n",
      "           7       0.67      0.74      0.71       152\n",
      "\n",
      "    accuracy                           0.79      1338\n",
      "   macro avg       0.79      0.80      0.79      1338\n",
      "weighted avg       0.80      0.79      0.80      1338\n",
      "\n",
      "Validation Loss: 0.5922\n",
      "Epoch 142, Batch 10, Loss: 0.8284\n",
      "Epoch 142, Batch 20, Loss: 0.9360\n",
      "Accuracy on images: 80.49%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78       150\n",
      "           1       0.87      0.82      0.85       178\n",
      "           2       0.79      0.73      0.76       182\n",
      "           3       0.74      0.77      0.75       160\n",
      "           4       0.63      0.80      0.71       133\n",
      "           5       0.85      0.85      0.85       167\n",
      "           6       0.98      0.96      0.97       169\n",
      "           7       0.84      0.71      0.77       199\n",
      "\n",
      "    accuracy                           0.80      1338\n",
      "   macro avg       0.80      0.81      0.80      1338\n",
      "weighted avg       0.81      0.80      0.81      1338\n",
      "\n",
      "Validation Loss: 0.6031\n",
      "Epoch 143, Batch 10, Loss: 0.7831\n",
      "Epoch 143, Batch 20, Loss: 0.9223\n",
      "Accuracy on images: 80.94%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80       159\n",
      "           1       0.87      0.85      0.86       171\n",
      "           2       0.75      0.71      0.73       178\n",
      "           3       0.77      0.81      0.79       160\n",
      "           4       0.68      0.79      0.73       143\n",
      "           5       0.87      0.81      0.84       180\n",
      "           6       0.99      0.95      0.97       173\n",
      "           7       0.77      0.74      0.75       174\n",
      "\n",
      "    accuracy                           0.81      1338\n",
      "   macro avg       0.81      0.81      0.81      1338\n",
      "weighted avg       0.81      0.81      0.81      1338\n",
      "\n",
      "Validation Loss: 0.5947\n",
      "Epoch 144, Batch 10, Loss: 0.8655\n",
      "Epoch 144, Batch 20, Loss: 0.8014\n",
      "Accuracy on images: 81.91%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79       143\n",
      "           1       0.86      0.84      0.85       171\n",
      "           2       0.79      0.74      0.76       180\n",
      "           3       0.86      0.76      0.81       189\n",
      "           4       0.72      0.77      0.75       157\n",
      "           5       0.86      0.86      0.86       168\n",
      "           6       0.97      0.96      0.96       169\n",
      "           7       0.75      0.78      0.77       161\n",
      "\n",
      "    accuracy                           0.82      1338\n",
      "   macro avg       0.82      0.82      0.82      1338\n",
      "weighted avg       0.82      0.82      0.82      1338\n",
      "\n",
      "Validation Loss: 0.5504\n",
      "Epoch 145, Batch 10, Loss: 0.8478\n",
      "Epoch 145, Batch 20, Loss: 0.8822\n",
      "Accuracy on images: 81.91%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82       179\n",
      "           1       0.84      0.88      0.86       161\n",
      "           2       0.76      0.75      0.76       170\n",
      "           3       0.81      0.76      0.78       177\n",
      "           4       0.74      0.79      0.76       156\n",
      "           5       0.85      0.84      0.85       169\n",
      "           6       0.97      0.92      0.94       176\n",
      "           7       0.73      0.82      0.77       150\n",
      "\n",
      "    accuracy                           0.82      1338\n",
      "   macro avg       0.82      0.82      0.82      1338\n",
      "weighted avg       0.82      0.82      0.82      1338\n",
      "\n",
      "Validation Loss: 0.5745\n",
      "Epoch 146, Batch 10, Loss: 0.8738\n",
      "Epoch 146, Batch 20, Loss: 0.8885\n",
      "Accuracy on images: 79.52%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       172\n",
      "           1       0.87      0.79      0.83       183\n",
      "           2       0.73      0.73      0.73       168\n",
      "           3       0.75      0.80      0.78       158\n",
      "           4       0.63      0.77      0.70       138\n",
      "           5       0.82      0.84      0.83       163\n",
      "           6       0.96      0.96      0.96       168\n",
      "           7       0.80      0.72      0.76       188\n",
      "\n",
      "    accuracy                           0.80      1338\n",
      "   macro avg       0.80      0.80      0.79      1338\n",
      "weighted avg       0.80      0.80      0.80      1338\n",
      "\n",
      "Validation Loss: 0.5940\n",
      "Epoch 147, Batch 10, Loss: 0.8540\n",
      "Epoch 147, Batch 20, Loss: 0.8685\n",
      "Accuracy on images: 82.96%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81       162\n",
      "           1       0.82      0.91      0.86       151\n",
      "           2       0.74      0.85      0.79       146\n",
      "           3       0.88      0.73      0.80       202\n",
      "           4       0.77      0.75      0.76       171\n",
      "           5       0.84      0.89      0.87       158\n",
      "           6       0.97      0.97      0.97       167\n",
      "           7       0.81      0.75      0.78       181\n",
      "\n",
      "    accuracy                           0.83      1338\n",
      "   macro avg       0.83      0.83      0.83      1338\n",
      "weighted avg       0.83      0.83      0.83      1338\n",
      "\n",
      "Validation Loss: 0.5537\n",
      "Epoch 148, Batch 10, Loss: 0.7903\n",
      "Epoch 148, Batch 20, Loss: 0.8978\n",
      "Accuracy on images: 81.91%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79       145\n",
      "           1       0.83      0.85      0.84       164\n",
      "           2       0.78      0.77      0.78       170\n",
      "           3       0.83      0.81      0.82       171\n",
      "           4       0.74      0.78      0.76       157\n",
      "           5       0.87      0.81      0.84       180\n",
      "           6       0.99      0.96      0.98       171\n",
      "           7       0.79      0.73      0.76       180\n",
      "\n",
      "    accuracy                           0.82      1338\n",
      "   macro avg       0.82      0.82      0.82      1338\n",
      "weighted avg       0.82      0.82      0.82      1338\n",
      "\n",
      "Validation Loss: 0.5794\n",
      "Epoch 149, Batch 10, Loss: 0.8080\n",
      "Epoch 149, Batch 20, Loss: 0.8750\n",
      "Accuracy on images: 81.84%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.81       153\n",
      "           1       0.83      0.84      0.83       166\n",
      "           2       0.77      0.76      0.76       170\n",
      "           3       0.85      0.75      0.80       189\n",
      "           4       0.72      0.79      0.75       151\n",
      "           5       0.85      0.80      0.83       177\n",
      "           6       0.97      0.98      0.98       165\n",
      "           7       0.79      0.79      0.79       167\n",
      "\n",
      "    accuracy                           0.82      1338\n",
      "   macro avg       0.82      0.82      0.82      1338\n",
      "weighted avg       0.82      0.82      0.82      1338\n",
      "\n",
      "Validation Loss: 0.5665\n",
      "Epoch 150, Batch 10, Loss: 0.7959\n",
      "Epoch 150, Batch 20, Loss: 0.9425\n",
      "Accuracy on images: 79.60%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80       160\n",
      "           1       0.82      0.87      0.84       158\n",
      "           2       0.73      0.73      0.73       168\n",
      "           3       0.83      0.67      0.75       206\n",
      "           4       0.67      0.77      0.72       145\n",
      "           5       0.81      0.80      0.80       169\n",
      "           6       0.96      0.98      0.97       164\n",
      "           7       0.77      0.77      0.77       168\n",
      "\n",
      "    accuracy                           0.80      1338\n",
      "   macro avg       0.80      0.80      0.80      1338\n",
      "weighted avg       0.80      0.80      0.80      1338\n",
      "\n",
      "Validation Loss: 0.6187\n",
      "Epoch 151, Batch 10, Loss: 0.8669\n",
      "Epoch 151, Batch 20, Loss: 0.8467\n",
      "Accuracy on images: 82.21%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       172\n",
      "           1       0.78      0.87      0.83       150\n",
      "           2       0.73      0.75      0.74       162\n",
      "           3       0.86      0.73      0.79       195\n",
      "           4       0.76      0.77      0.77       165\n",
      "           5       0.84      0.86      0.85       164\n",
      "           6       0.98      0.98      0.98       167\n",
      "           7       0.81      0.83      0.82       163\n",
      "\n",
      "    accuracy                           0.82      1338\n",
      "   macro avg       0.82      0.82      0.82      1338\n",
      "weighted avg       0.82      0.82      0.82      1338\n",
      "\n",
      "Validation Loss: 0.5574\n",
      "Epoch 152, Batch 10, Loss: 0.7652\n",
      "Epoch 152, Batch 20, Loss: 0.8299\n",
      "Accuracy on images: 80.64%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80       148\n",
      "           1       0.88      0.84      0.86       174\n",
      "           2       0.79      0.73      0.76       180\n",
      "           3       0.76      0.77      0.76       166\n",
      "           4       0.66      0.78      0.72       143\n",
      "           5       0.83      0.85      0.84       163\n",
      "           6       0.98      0.98      0.98       166\n",
      "           7       0.80      0.68      0.73       198\n",
      "\n",
      "    accuracy                           0.81      1338\n",
      "   macro avg       0.81      0.81      0.81      1338\n",
      "weighted avg       0.81      0.81      0.81      1338\n",
      "\n",
      "Validation Loss: 0.5632\n",
      "Epoch 153, Batch 10, Loss: 0.8023\n",
      "Epoch 153, Batch 20, Loss: 0.8134\n",
      "Accuracy on images: 81.32%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79       168\n",
      "           1       0.81      0.84      0.83       161\n",
      "           2       0.83      0.73      0.77       191\n",
      "           3       0.80      0.76      0.78       174\n",
      "           4       0.66      0.79      0.72       140\n",
      "           5       0.83      0.85      0.84       163\n",
      "           6       0.96      0.93      0.95       173\n",
      "           7       0.81      0.81      0.81       168\n",
      "\n",
      "    accuracy                           0.81      1338\n",
      "   macro avg       0.81      0.81      0.81      1338\n",
      "weighted avg       0.82      0.81      0.81      1338\n",
      "\n",
      "Validation Loss: 0.5610\n",
      "Epoch 154, Batch 10, Loss: 0.8411\n",
      "Epoch 154, Batch 20, Loss: 0.8814\n",
      "Accuracy on images: 81.91%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80       163\n",
      "           1       0.81      0.89      0.85       151\n",
      "           2       0.71      0.82      0.76       147\n",
      "           3       0.83      0.74      0.79       187\n",
      "           4       0.72      0.72      0.72       168\n",
      "           5       0.92      0.84      0.88       182\n",
      "           6       0.98      0.99      0.98       165\n",
      "           7       0.79      0.76      0.78       175\n",
      "\n",
      "    accuracy                           0.82      1338\n",
      "   macro avg       0.82      0.82      0.82      1338\n",
      "weighted avg       0.82      0.82      0.82      1338\n",
      "\n",
      "Validation Loss: 0.5461\n",
      "Epoch 155, Batch 10, Loss: 0.7969\n",
      "Epoch 155, Batch 20, Loss: 0.8337\n",
      "Accuracy on images: 82.66%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82       142\n",
      "           1       0.92      0.80      0.85       192\n",
      "           2       0.83      0.73      0.78       190\n",
      "           3       0.79      0.81      0.80       162\n",
      "           4       0.74      0.80      0.77       155\n",
      "           5       0.87      0.83      0.85       174\n",
      "           6       0.97      0.96      0.97       168\n",
      "           7       0.74      0.80      0.77       155\n",
      "\n",
      "    accuracy                           0.83      1338\n",
      "   macro avg       0.83      0.83      0.83      1338\n",
      "weighted avg       0.83      0.83      0.83      1338\n",
      "\n",
      "Validation Loss: 0.5502\n",
      "Epoch 156, Batch 10, Loss: 0.7964\n",
      "Epoch 156, Batch 20, Loss: 0.8118\n",
      "Accuracy on images: 84.45%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83       147\n",
      "           1       0.84      0.90      0.87       156\n",
      "           2       0.79      0.85      0.82       155\n",
      "           3       0.86      0.77      0.81       188\n",
      "           4       0.80      0.83      0.81       161\n",
      "           5       0.89      0.81      0.85       185\n",
      "           6       0.96      0.99      0.98       161\n",
      "           7       0.85      0.77      0.80       185\n",
      "\n",
      "    accuracy                           0.84      1338\n",
      "   macro avg       0.84      0.85      0.85      1338\n",
      "weighted avg       0.85      0.84      0.84      1338\n",
      "\n",
      "Validation Loss: 0.5072\n",
      "Epoch 157, Batch 10, Loss: 0.7680\n",
      "Epoch 157, Batch 20, Loss: 0.8351\n",
      "Accuracy on images: 83.26%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       176\n",
      "           1       0.86      0.89      0.88       161\n",
      "           2       0.80      0.80      0.80       167\n",
      "           3       0.81      0.82      0.82       164\n",
      "           4       0.63      0.79      0.70       135\n",
      "           5       0.89      0.84      0.86       176\n",
      "           6       0.98      0.96      0.97       169\n",
      "           7       0.85      0.75      0.79       190\n",
      "\n",
      "    accuracy                           0.83      1338\n",
      "   macro avg       0.83      0.83      0.83      1338\n",
      "weighted avg       0.84      0.83      0.83      1338\n",
      "\n",
      "Validation Loss: 0.5493\n",
      "Epoch 158, Batch 10, Loss: 0.7877\n",
      "Epoch 158, Batch 20, Loss: 0.8099\n",
      "Accuracy on images: 84.30%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       154\n",
      "           1       0.87      0.91      0.89       160\n",
      "           2       0.82      0.83      0.83       166\n",
      "           3       0.80      0.78      0.79       172\n",
      "           4       0.75      0.78      0.77       161\n",
      "           5       0.87      0.85      0.86       172\n",
      "           6       0.98      0.96      0.97       170\n",
      "           7       0.84      0.77      0.80       183\n",
      "\n",
      "    accuracy                           0.84      1338\n",
      "   macro avg       0.84      0.84      0.84      1338\n",
      "weighted avg       0.84      0.84      0.84      1338\n",
      "\n",
      "Validation Loss: 0.4941\n",
      "Epoch 159, Batch 10, Loss: 0.7696\n",
      "Epoch 159, Batch 20, Loss: 0.6987\n",
      "Accuracy on images: 84.08%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       158\n",
      "           1       0.86      0.86      0.86       167\n",
      "           2       0.74      0.84      0.79       149\n",
      "           3       0.83      0.80      0.82       173\n",
      "           4       0.81      0.80      0.81       168\n",
      "           5       0.91      0.81      0.86       188\n",
      "           6       0.98      0.99      0.98       165\n",
      "           7       0.77      0.76      0.77       170\n",
      "\n",
      "    accuracy                           0.84      1338\n",
      "   macro avg       0.84      0.84      0.84      1338\n",
      "weighted avg       0.84      0.84      0.84      1338\n",
      "\n",
      "Validation Loss: 0.4981\n",
      "Epoch 160, Batch 10, Loss: 0.7913\n",
      "Epoch 160, Batch 20, Loss: 0.7911\n",
      "Accuracy on images: 82.88%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       158\n",
      "           1       0.82      0.90      0.86       152\n",
      "           2       0.74      0.83      0.78       151\n",
      "           3       0.86      0.78      0.82       183\n",
      "           4       0.72      0.81      0.77       149\n",
      "           5       0.91      0.74      0.82       205\n",
      "           6       0.98      0.94      0.96       173\n",
      "           7       0.80      0.81      0.81       167\n",
      "\n",
      "    accuracy                           0.83      1338\n",
      "   macro avg       0.83      0.83      0.83      1338\n",
      "weighted avg       0.83      0.83      0.83      1338\n",
      "\n",
      "Validation Loss: 0.5273\n",
      "Epoch 161, Batch 10, Loss: 0.7939\n",
      "Epoch 161, Batch 20, Loss: 0.8374\n",
      "Accuracy on images: 84.60%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83       161\n",
      "           1       0.83      0.91      0.87       152\n",
      "           2       0.82      0.80      0.81       172\n",
      "           3       0.88      0.74      0.81       198\n",
      "           4       0.80      0.77      0.78       173\n",
      "           5       0.86      0.90      0.88       160\n",
      "           6       0.96      0.98      0.97       164\n",
      "           7       0.80      0.85      0.83       158\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.85      0.85      1338\n",
      "weighted avg       0.85      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.5213\n",
      "Epoch 162, Batch 10, Loss: 0.7084\n",
      "Epoch 162, Batch 20, Loss: 0.8168\n",
      "Accuracy on images: 83.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       158\n",
      "           1       0.83      0.88      0.86       158\n",
      "           2       0.78      0.86      0.82       153\n",
      "           3       0.84      0.74      0.79       188\n",
      "           4       0.73      0.80      0.76       152\n",
      "           5       0.89      0.83      0.86       178\n",
      "           6       0.95      0.99      0.97       160\n",
      "           7       0.84      0.74      0.79       191\n",
      "\n",
      "    accuracy                           0.83      1338\n",
      "   macro avg       0.83      0.84      0.83      1338\n",
      "weighted avg       0.84      0.83      0.83      1338\n",
      "\n",
      "Validation Loss: 0.5039\n",
      "Epoch 163, Batch 10, Loss: 0.7811\n",
      "Epoch 163, Batch 20, Loss: 0.7876\n",
      "Accuracy on images: 84.23%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       160\n",
      "           1       0.89      0.85      0.87       175\n",
      "           2       0.78      0.83      0.81       157\n",
      "           3       0.85      0.80      0.83       177\n",
      "           4       0.74      0.76      0.75       162\n",
      "           5       0.88      0.85      0.86       173\n",
      "           6       0.98      0.97      0.97       168\n",
      "           7       0.82      0.83      0.82       166\n",
      "\n",
      "    accuracy                           0.84      1338\n",
      "   macro avg       0.84      0.84      0.84      1338\n",
      "weighted avg       0.84      0.84      0.84      1338\n",
      "\n",
      "Validation Loss: 0.4989\n",
      "Epoch 164, Batch 10, Loss: 0.8126\n",
      "Epoch 164, Batch 20, Loss: 0.7631\n",
      "Accuracy on images: 86.02%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       155\n",
      "           1       0.88      0.88      0.88       167\n",
      "           2       0.82      0.82      0.82       167\n",
      "           3       0.89      0.83      0.86       179\n",
      "           4       0.79      0.79      0.79       168\n",
      "           5       0.87      0.87      0.87       167\n",
      "           6       0.98      0.98      0.98       167\n",
      "           7       0.84      0.84      0.84       168\n",
      "\n",
      "    accuracy                           0.86      1338\n",
      "   macro avg       0.86      0.86      0.86      1338\n",
      "weighted avg       0.86      0.86      0.86      1338\n",
      "\n",
      "Validation Loss: 0.4882\n",
      "Epoch 165, Batch 10, Loss: 0.7929\n",
      "Epoch 165, Batch 20, Loss: 0.7826\n",
      "Accuracy on images: 83.63%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       166\n",
      "           1       0.84      0.83      0.84       170\n",
      "           2       0.77      0.85      0.81       153\n",
      "           3       0.87      0.72      0.79       201\n",
      "           4       0.68      0.86      0.76       131\n",
      "           5       0.86      0.93      0.89       153\n",
      "           6       0.99      0.98      0.98       169\n",
      "           7       0.86      0.74      0.80       195\n",
      "\n",
      "    accuracy                           0.84      1338\n",
      "   macro avg       0.84      0.84      0.84      1338\n",
      "weighted avg       0.84      0.84      0.84      1338\n",
      "\n",
      "Validation Loss: 0.5221\n",
      "Epoch 166, Batch 10, Loss: 0.7527\n",
      "Epoch 166, Batch 20, Loss: 0.8181\n",
      "Accuracy on images: 84.16%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82       151\n",
      "           1       0.87      0.87      0.87       167\n",
      "           2       0.85      0.81      0.83       176\n",
      "           3       0.81      0.81      0.81       168\n",
      "           4       0.83      0.74      0.78       186\n",
      "           5       0.81      0.88      0.85       154\n",
      "           6       0.99      0.96      0.97       172\n",
      "           7       0.79      0.80      0.80       164\n",
      "\n",
      "    accuracy                           0.84      1338\n",
      "   macro avg       0.84      0.84      0.84      1338\n",
      "weighted avg       0.84      0.84      0.84      1338\n",
      "\n",
      "Validation Loss: 0.5163\n",
      "Epoch 167, Batch 10, Loss: 0.7761\n",
      "Epoch 167, Batch 20, Loss: 0.7766\n",
      "Accuracy on images: 83.48%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       152\n",
      "           1       0.85      0.83      0.84       172\n",
      "           2       0.83      0.82      0.82       170\n",
      "           3       0.80      0.83      0.81       161\n",
      "           4       0.68      0.84      0.75       135\n",
      "           5       0.92      0.82      0.87       188\n",
      "           6       0.98      0.99      0.98       164\n",
      "           7       0.85      0.72      0.78       196\n",
      "\n",
      "    accuracy                           0.83      1338\n",
      "   macro avg       0.83      0.84      0.83      1338\n",
      "weighted avg       0.84      0.83      0.84      1338\n",
      "\n",
      "Validation Loss: 0.5007\n",
      "Epoch 168, Batch 10, Loss: 0.7770\n",
      "Epoch 168, Batch 20, Loss: 0.7879\n",
      "Accuracy on images: 81.54%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       172\n",
      "           1       0.84      0.84      0.84       166\n",
      "           2       0.70      0.85      0.77       139\n",
      "           3       0.78      0.76      0.77       172\n",
      "           4       0.72      0.79      0.75       152\n",
      "           5       0.86      0.86      0.86       167\n",
      "           6       0.97      0.96      0.97       168\n",
      "           7       0.83      0.69      0.75       202\n",
      "\n",
      "    accuracy                           0.82      1338\n",
      "   macro avg       0.82      0.82      0.82      1338\n",
      "weighted avg       0.82      0.82      0.82      1338\n",
      "\n",
      "Validation Loss: 0.5269\n",
      "Epoch 169, Batch 10, Loss: 0.8159\n",
      "Epoch 169, Batch 20, Loss: 0.7906\n",
      "Accuracy on images: 85.05%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       159\n",
      "           1       0.87      0.86      0.87       170\n",
      "           2       0.78      0.81      0.80       161\n",
      "           3       0.88      0.80      0.84       183\n",
      "           4       0.75      0.85      0.80       147\n",
      "           5       0.83      0.91      0.87       152\n",
      "           6       0.98      0.97      0.97       168\n",
      "           7       0.89      0.75      0.81       198\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.85      0.85      1338\n",
      "weighted avg       0.85      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4903\n",
      "Epoch 170, Batch 10, Loss: 0.7784\n",
      "Epoch 170, Batch 20, Loss: 0.8399\n",
      "Accuracy on images: 83.63%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86       172\n",
      "           1       0.85      0.83      0.84       172\n",
      "           2       0.87      0.76      0.81       193\n",
      "           3       0.82      0.80      0.81       171\n",
      "           4       0.65      0.84      0.73       130\n",
      "           5       0.86      0.86      0.86       167\n",
      "           6       0.97      0.97      0.97       167\n",
      "           7       0.80      0.81      0.80       166\n",
      "\n",
      "    accuracy                           0.84      1338\n",
      "   macro avg       0.84      0.84      0.84      1338\n",
      "weighted avg       0.84      0.84      0.84      1338\n",
      "\n",
      "Validation Loss: 0.5030\n",
      "Epoch 171, Batch 10, Loss: 0.8111\n",
      "Epoch 171, Batch 20, Loss: 0.7605\n",
      "Accuracy on images: 82.29%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81       184\n",
      "           1       0.86      0.87      0.87       165\n",
      "           2       0.82      0.73      0.77       189\n",
      "           3       0.78      0.81      0.80       160\n",
      "           4       0.74      0.75      0.74       166\n",
      "           5       0.82      0.89      0.85       154\n",
      "           6       0.98      0.96      0.97       169\n",
      "           7       0.73      0.81      0.77       151\n",
      "\n",
      "    accuracy                           0.82      1338\n",
      "   macro avg       0.82      0.83      0.82      1338\n",
      "weighted avg       0.82      0.82      0.82      1338\n",
      "\n",
      "Validation Loss: 0.5422\n",
      "Epoch 172, Batch 10, Loss: 0.8131\n",
      "Epoch 172, Batch 20, Loss: 0.7880\n",
      "Accuracy on images: 85.95%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84       175\n",
      "           1       0.85      0.89      0.87       160\n",
      "           2       0.85      0.83      0.84       171\n",
      "           3       0.89      0.80      0.84       184\n",
      "           4       0.76      0.80      0.78       159\n",
      "           5       0.90      0.90      0.90       166\n",
      "           6       0.98      1.00      0.99       163\n",
      "           7       0.80      0.84      0.82       160\n",
      "\n",
      "    accuracy                           0.86      1338\n",
      "   macro avg       0.86      0.86      0.86      1338\n",
      "weighted avg       0.86      0.86      0.86      1338\n",
      "\n",
      "Validation Loss: 0.4942\n",
      "Epoch 173, Batch 10, Loss: 0.8098\n",
      "Epoch 173, Batch 20, Loss: 0.7527\n",
      "Accuracy on images: 82.66%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83       147\n",
      "           1       0.84      0.88      0.86       160\n",
      "           2       0.74      0.82      0.78       153\n",
      "           3       0.83      0.80      0.81       173\n",
      "           4       0.71      0.79      0.75       150\n",
      "           5       0.87      0.82      0.85       177\n",
      "           6       0.98      1.00      0.99       163\n",
      "           7       0.86      0.67      0.76       215\n",
      "\n",
      "    accuracy                           0.83      1338\n",
      "   macro avg       0.83      0.83      0.83      1338\n",
      "weighted avg       0.83      0.83      0.83      1338\n",
      "\n",
      "Validation Loss: 0.5314\n",
      "Epoch 174, Batch 10, Loss: 0.7790\n",
      "Epoch 174, Batch 20, Loss: 0.8215\n",
      "Accuracy on images: 84.90%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       164\n",
      "           1       0.84      0.93      0.88       151\n",
      "           2       0.81      0.80      0.80       170\n",
      "           3       0.86      0.80      0.83       179\n",
      "           4       0.78      0.80      0.79       163\n",
      "           5       0.86      0.86      0.86       167\n",
      "           6       0.99      0.96      0.98       171\n",
      "           7       0.80      0.78      0.79       173\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.85      0.85      1338\n",
      "weighted avg       0.85      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4807\n",
      "Epoch 175, Batch 10, Loss: 0.8137\n",
      "Epoch 175, Batch 20, Loss: 0.7640\n",
      "Accuracy on images: 85.43%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       150\n",
      "           1       0.89      0.88      0.88       170\n",
      "           2       0.86      0.78      0.82       185\n",
      "           3       0.88      0.80      0.84       184\n",
      "           4       0.73      0.84      0.78       145\n",
      "           5       0.87      0.89      0.88       163\n",
      "           6       0.98      0.99      0.98       166\n",
      "           7       0.83      0.80      0.82       175\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.86      0.85      1338\n",
      "weighted avg       0.86      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4664\n",
      "Epoch 176, Batch 10, Loss: 0.8198\n",
      "Epoch 176, Batch 20, Loss: 0.7602\n",
      "Accuracy on images: 84.45%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85       163\n",
      "           1       0.84      0.94      0.89       150\n",
      "           2       0.73      0.83      0.78       148\n",
      "           3       0.87      0.80      0.83       182\n",
      "           4       0.77      0.78      0.77       166\n",
      "           5       0.91      0.83      0.87       184\n",
      "           6       0.96      0.96      0.96       166\n",
      "           7       0.83      0.78      0.80       179\n",
      "\n",
      "    accuracy                           0.84      1338\n",
      "   macro avg       0.84      0.85      0.84      1338\n",
      "weighted avg       0.85      0.84      0.84      1338\n",
      "\n",
      "Validation Loss: 0.4829\n",
      "Epoch 177, Batch 10, Loss: 0.8000\n",
      "Epoch 177, Batch 20, Loss: 0.7115\n",
      "Accuracy on images: 84.45%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84       141\n",
      "           1       0.80      0.92      0.86       146\n",
      "           2       0.85      0.74      0.79       192\n",
      "           3       0.87      0.80      0.83       183\n",
      "           4       0.81      0.80      0.81       169\n",
      "           5       0.86      0.86      0.86       167\n",
      "           6       0.98      0.98      0.98       166\n",
      "           7       0.81      0.78      0.80       174\n",
      "\n",
      "    accuracy                           0.84      1338\n",
      "   macro avg       0.84      0.85      0.85      1338\n",
      "weighted avg       0.85      0.84      0.84      1338\n",
      "\n",
      "Validation Loss: 0.4932\n",
      "Epoch 178, Batch 10, Loss: 0.7519\n",
      "Epoch 178, Batch 20, Loss: 0.7541\n",
      "Accuracy on images: 84.68%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       152\n",
      "           1       0.87      0.90      0.89       162\n",
      "           2       0.73      0.81      0.77       152\n",
      "           3       0.84      0.82      0.83       171\n",
      "           4       0.78      0.82      0.80       159\n",
      "           5       0.92      0.84      0.88       184\n",
      "           6       0.98      1.00      0.99       163\n",
      "           7       0.82      0.71      0.76       195\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.85      0.85      1338\n",
      "weighted avg       0.85      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4811\n",
      "Epoch 179, Batch 10, Loss: 0.7359\n",
      "Epoch 179, Batch 20, Loss: 0.8173\n",
      "Accuracy on images: 83.71%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.81       148\n",
      "           1       0.90      0.87      0.88       173\n",
      "           2       0.87      0.73      0.80       199\n",
      "           3       0.81      0.78      0.79       174\n",
      "           4       0.69      0.87      0.77       132\n",
      "           5       0.89      0.86      0.87       174\n",
      "           6       0.96      0.91      0.94       175\n",
      "           7       0.82      0.84      0.83       163\n",
      "\n",
      "    accuracy                           0.84      1338\n",
      "   macro avg       0.84      0.84      0.84      1338\n",
      "weighted avg       0.84      0.84      0.84      1338\n",
      "\n",
      "Validation Loss: 0.5111\n",
      "Epoch 180, Batch 10, Loss: 0.7870\n",
      "Epoch 180, Batch 20, Loss: 0.7379\n",
      "Accuracy on images: 85.43%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       148\n",
      "           1       0.90      0.81      0.85       186\n",
      "           2       0.80      0.88      0.84       154\n",
      "           3       0.89      0.79      0.84       187\n",
      "           4       0.79      0.84      0.81       157\n",
      "           5       0.85      0.89      0.87       160\n",
      "           6       0.97      0.96      0.96       169\n",
      "           7       0.85      0.80      0.82       177\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.86      0.85      1338\n",
      "weighted avg       0.86      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4508\n",
      "Epoch 181, Batch 10, Loss: 0.7198\n",
      "Epoch 181, Batch 20, Loss: 0.7862\n",
      "Accuracy on images: 87.14%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.89       181\n",
      "           1       0.87      0.91      0.89       161\n",
      "           2       0.81      0.82      0.81       166\n",
      "           3       0.84      0.83      0.84       168\n",
      "           4       0.79      0.84      0.81       158\n",
      "           5       0.92      0.87      0.89       175\n",
      "           6       0.96      0.99      0.98       162\n",
      "           7       0.86      0.86      0.86       167\n",
      "\n",
      "    accuracy                           0.87      1338\n",
      "   macro avg       0.87      0.87      0.87      1338\n",
      "weighted avg       0.87      0.87      0.87      1338\n",
      "\n",
      "Validation Loss: 0.4538\n",
      "Epoch 182, Batch 10, Loss: 0.7238\n",
      "Epoch 182, Batch 20, Loss: 0.8935\n",
      "Accuracy on images: 86.55%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86       140\n",
      "           1       0.91      0.88      0.90       172\n",
      "           2       0.80      0.88      0.84       153\n",
      "           3       0.89      0.80      0.84       184\n",
      "           4       0.82      0.78      0.80       176\n",
      "           5       0.89      0.86      0.88       173\n",
      "           6       0.98      0.96      0.97       170\n",
      "           7       0.84      0.83      0.83       170\n",
      "\n",
      "    accuracy                           0.87      1338\n",
      "   macro avg       0.87      0.87      0.87      1338\n",
      "weighted avg       0.87      0.87      0.87      1338\n",
      "\n",
      "Validation Loss: 0.4628\n",
      "Epoch 183, Batch 10, Loss: 0.7669\n",
      "Epoch 183, Batch 20, Loss: 0.7400\n",
      "Accuracy on images: 86.17%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83       135\n",
      "           1       0.91      0.89      0.90       170\n",
      "           2       0.81      0.86      0.83       158\n",
      "           3       0.89      0.78      0.83       189\n",
      "           4       0.78      0.80      0.79       163\n",
      "           5       0.90      0.90      0.90       168\n",
      "           6       0.99      0.98      0.98       169\n",
      "           7       0.87      0.78      0.82       186\n",
      "\n",
      "    accuracy                           0.86      1338\n",
      "   macro avg       0.86      0.87      0.86      1338\n",
      "weighted avg       0.87      0.86      0.86      1338\n",
      "\n",
      "Validation Loss: 0.4436\n",
      "Epoch 184, Batch 10, Loss: 0.6796\n",
      "Epoch 184, Batch 20, Loss: 0.7530\n",
      "Accuracy on images: 85.35%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86       139\n",
      "           1       0.84      0.93      0.89       151\n",
      "           2       0.82      0.81      0.82       170\n",
      "           3       0.91      0.76      0.83       199\n",
      "           4       0.80      0.81      0.81       165\n",
      "           5       0.91      0.82      0.86       185\n",
      "           6       0.96      0.98      0.97       165\n",
      "           7       0.79      0.80      0.80       164\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.86      0.85      1338\n",
      "weighted avg       0.86      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4643\n",
      "Epoch 185, Batch 10, Loss: 0.6882\n",
      "Epoch 185, Batch 20, Loss: 0.7693\n",
      "Accuracy on images: 84.60%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       159\n",
      "           1       0.84      0.90      0.87       156\n",
      "           2       0.82      0.80      0.81       173\n",
      "           3       0.83      0.84      0.83       166\n",
      "           4       0.75      0.85      0.80       149\n",
      "           5       0.89      0.82      0.85       180\n",
      "           6       0.98      0.97      0.98       169\n",
      "           7       0.85      0.76      0.80       186\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.85      0.85      1338\n",
      "weighted avg       0.85      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4825\n",
      "Epoch 186, Batch 10, Loss: 0.7025\n",
      "Epoch 186, Batch 20, Loss: 0.7802\n",
      "Accuracy on images: 85.87%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       166\n",
      "           1       0.89      0.87      0.88       171\n",
      "           2       0.85      0.79      0.82       181\n",
      "           3       0.85      0.84      0.84       170\n",
      "           4       0.75      0.81      0.78       155\n",
      "           5       0.88      0.89      0.89       165\n",
      "           6       0.97      0.98      0.98       165\n",
      "           7       0.82      0.84      0.83       165\n",
      "\n",
      "    accuracy                           0.86      1338\n",
      "   macro avg       0.86      0.86      0.86      1338\n",
      "weighted avg       0.86      0.86      0.86      1338\n",
      "\n",
      "Validation Loss: 0.4417\n",
      "Epoch 187, Batch 10, Loss: 0.7550\n",
      "Epoch 187, Batch 20, Loss: 0.8605\n",
      "Accuracy on images: 86.10%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       147\n",
      "           1       0.90      0.84      0.87       178\n",
      "           2       0.85      0.85      0.85       168\n",
      "           3       0.90      0.83      0.86       181\n",
      "           4       0.80      0.82      0.81       164\n",
      "           5       0.86      0.87      0.86       165\n",
      "           6       0.98      0.97      0.98       169\n",
      "           7       0.82      0.83      0.82       166\n",
      "\n",
      "    accuracy                           0.86      1338\n",
      "   macro avg       0.86      0.86      0.86      1338\n",
      "weighted avg       0.86      0.86      0.86      1338\n",
      "\n",
      "Validation Loss: 0.4626\n",
      "Epoch 188, Batch 10, Loss: 0.7868\n",
      "Epoch 188, Batch 20, Loss: 0.7142\n",
      "Accuracy on images: 86.85%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87       172\n",
      "           1       0.88      0.94      0.91       156\n",
      "           2       0.83      0.83      0.83       168\n",
      "           3       0.82      0.83      0.82       166\n",
      "           4       0.80      0.84      0.82       159\n",
      "           5       0.92      0.86      0.89       178\n",
      "           6       0.98      0.99      0.98       166\n",
      "           7       0.83      0.81      0.82       173\n",
      "\n",
      "    accuracy                           0.87      1338\n",
      "   macro avg       0.87      0.87      0.87      1338\n",
      "weighted avg       0.87      0.87      0.87      1338\n",
      "\n",
      "Validation Loss: 0.4490\n",
      "Epoch 189, Batch 10, Loss: 0.7102\n",
      "Epoch 189, Batch 20, Loss: 0.7027\n",
      "Accuracy on images: 87.59%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       151\n",
      "           1       0.86      0.89      0.88       161\n",
      "           2       0.84      0.88      0.86       160\n",
      "           3       0.93      0.81      0.86       192\n",
      "           4       0.80      0.80      0.80       167\n",
      "           5       0.92      0.90      0.91       170\n",
      "           6       0.98      0.96      0.97       169\n",
      "           7       0.85      0.85      0.85       168\n",
      "\n",
      "    accuracy                           0.88      1338\n",
      "   macro avg       0.88      0.88      0.88      1338\n",
      "weighted avg       0.88      0.88      0.88      1338\n",
      "\n",
      "Validation Loss: 0.4040\n",
      "Epoch 190, Batch 10, Loss: 0.7573\n",
      "Epoch 190, Batch 20, Loss: 0.7733\n",
      "Accuracy on images: 84.30%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87       161\n",
      "           1       0.81      0.93      0.87       146\n",
      "           2       0.86      0.76      0.81       189\n",
      "           3       0.83      0.82      0.82       168\n",
      "           4       0.79      0.73      0.76       182\n",
      "           5       0.81      0.90      0.86       151\n",
      "           6       0.95      0.97      0.96       163\n",
      "           7       0.85      0.80      0.82       178\n",
      "\n",
      "    accuracy                           0.84      1338\n",
      "   macro avg       0.84      0.85      0.84      1338\n",
      "weighted avg       0.84      0.84      0.84      1338\n",
      "\n",
      "Validation Loss: 0.4853\n",
      "Epoch 191, Batch 10, Loss: 0.8151\n",
      "Epoch 191, Batch 20, Loss: 0.7632\n",
      "Accuracy on images: 85.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85       184\n",
      "           1       0.84      0.90      0.87       156\n",
      "           2       0.82      0.86      0.84       159\n",
      "           3       0.88      0.75      0.81       196\n",
      "           4       0.71      0.83      0.77       143\n",
      "           5       0.90      0.87      0.88       173\n",
      "           6       0.99      0.95      0.97       174\n",
      "           7       0.78      0.86      0.82       153\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.85      0.85      1338\n",
      "weighted avg       0.86      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4653\n",
      "Epoch 192, Batch 10, Loss: 0.7680\n",
      "Epoch 192, Batch 20, Loss: 0.7349\n",
      "Accuracy on images: 86.25%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87       165\n",
      "           1       0.92      0.91      0.91       168\n",
      "           2       0.86      0.78      0.82       185\n",
      "           3       0.82      0.83      0.83       165\n",
      "           4       0.72      0.85      0.78       143\n",
      "           5       0.91      0.88      0.90       172\n",
      "           6       1.00      0.94      0.97       177\n",
      "           7       0.80      0.83      0.82       163\n",
      "\n",
      "    accuracy                           0.86      1338\n",
      "   macro avg       0.86      0.86      0.86      1338\n",
      "weighted avg       0.87      0.86      0.86      1338\n",
      "\n",
      "Validation Loss: 0.4365\n",
      "Epoch 193, Batch 10, Loss: 0.7515\n",
      "Epoch 193, Batch 20, Loss: 0.6990\n",
      "Accuracy on images: 86.17%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87       158\n",
      "           1       0.85      0.90      0.88       157\n",
      "           2       0.89      0.83      0.86       180\n",
      "           3       0.83      0.81      0.82       170\n",
      "           4       0.80      0.79      0.80       169\n",
      "           5       0.93      0.82      0.87       190\n",
      "           6       0.98      0.99      0.98       166\n",
      "           7       0.77      0.87      0.82       148\n",
      "\n",
      "    accuracy                           0.86      1338\n",
      "   macro avg       0.86      0.86      0.86      1338\n",
      "weighted avg       0.86      0.86      0.86      1338\n",
      "\n",
      "Validation Loss: 0.4467\n",
      "Epoch 194, Batch 10, Loss: 0.7780\n",
      "Epoch 194, Batch 20, Loss: 0.7375\n",
      "Accuracy on images: 85.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       149\n",
      "           1       0.86      0.92      0.89       157\n",
      "           2       0.74      0.88      0.81       142\n",
      "           3       0.87      0.76      0.81       192\n",
      "           4       0.77      0.87      0.82       149\n",
      "           5       0.92      0.82      0.86       187\n",
      "           6       0.93      0.99      0.96       158\n",
      "           7       0.90      0.75      0.82       204\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.86      0.85      1338\n",
      "weighted avg       0.86      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4699\n",
      "Epoch 195, Batch 10, Loss: 0.7672\n",
      "Epoch 195, Batch 20, Loss: 0.7675\n",
      "Accuracy on images: 85.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82       144\n",
      "           1       0.80      0.89      0.85       150\n",
      "           2       0.85      0.84      0.84       169\n",
      "           3       0.88      0.79      0.83       186\n",
      "           4       0.77      0.81      0.79       159\n",
      "           5       0.90      0.85      0.88       177\n",
      "           6       0.99      0.96      0.98       171\n",
      "           7       0.86      0.80      0.83       182\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.85      0.85      1338\n",
      "weighted avg       0.86      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4878\n",
      "Epoch 196, Batch 10, Loss: 0.7963\n",
      "Epoch 196, Batch 20, Loss: 0.7924\n",
      "Accuracy on images: 83.63%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       146\n",
      "           1       0.82      0.89      0.85       154\n",
      "           2       0.79      0.86      0.82       155\n",
      "           3       0.84      0.86      0.85       163\n",
      "           4       0.78      0.69      0.73       189\n",
      "           5       0.83      0.83      0.83       167\n",
      "           6       0.96      0.96      0.96       167\n",
      "           7       0.88      0.75      0.81       197\n",
      "\n",
      "    accuracy                           0.84      1338\n",
      "   macro avg       0.84      0.84      0.84      1338\n",
      "weighted avg       0.84      0.84      0.83      1338\n",
      "\n",
      "Validation Loss: 0.5051\n",
      "Epoch 197, Batch 10, Loss: 0.7775\n",
      "Epoch 197, Batch 20, Loss: 0.7540\n",
      "Accuracy on images: 87.22%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87       181\n",
      "           1       0.89      0.91      0.90       163\n",
      "           2       0.78      0.92      0.84       143\n",
      "           3       0.86      0.84      0.85       172\n",
      "           4       0.78      0.84      0.81       154\n",
      "           5       0.89      0.90      0.89       165\n",
      "           6       0.98      0.99      0.98       165\n",
      "           7       0.90      0.77      0.83       195\n",
      "\n",
      "    accuracy                           0.87      1338\n",
      "   macro avg       0.87      0.88      0.87      1338\n",
      "weighted avg       0.88      0.87      0.87      1338\n",
      "\n",
      "Validation Loss: 0.4409\n",
      "Epoch 198, Batch 10, Loss: 0.7589\n",
      "Epoch 198, Batch 20, Loss: 0.7324\n",
      "Accuracy on images: 86.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.83       138\n",
      "           1       0.91      0.84      0.88       180\n",
      "           2       0.85      0.87      0.86       163\n",
      "           3       0.88      0.86      0.87       171\n",
      "           4       0.77      0.77      0.77       167\n",
      "           5       0.93      0.84      0.88       185\n",
      "           6       0.97      0.99      0.98       164\n",
      "           7       0.86      0.85      0.85       170\n",
      "\n",
      "    accuracy                           0.86      1338\n",
      "   macro avg       0.86      0.87      0.86      1338\n",
      "weighted avg       0.87      0.86      0.86      1338\n",
      "\n",
      "Validation Loss: 0.4284\n",
      "Epoch 199, Batch 10, Loss: 0.7287\n",
      "Epoch 199, Batch 20, Loss: 0.7152\n",
      "Accuracy on images: 86.47%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       162\n",
      "           1       0.81      0.96      0.88       141\n",
      "           2       0.83      0.89      0.86       157\n",
      "           3       0.83      0.91      0.87       153\n",
      "           4       0.84      0.77      0.80       181\n",
      "           5       0.89      0.88      0.88       170\n",
      "           6       0.97      0.98      0.98       165\n",
      "           7       0.90      0.73      0.81       209\n",
      "\n",
      "    accuracy                           0.86      1338\n",
      "   macro avg       0.86      0.87      0.87      1338\n",
      "weighted avg       0.87      0.86      0.86      1338\n",
      "\n",
      "Validation Loss: 0.4281\n",
      "Epoch 200, Batch 10, Loss: 0.7415\n",
      "Epoch 200, Batch 20, Loss: 0.7595\n",
      "Accuracy on images: 85.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       150\n",
      "           1       0.88      0.92      0.90       160\n",
      "           2       0.82      0.76      0.79       180\n",
      "           3       0.89      0.73      0.80       203\n",
      "           4       0.79      0.81      0.80       162\n",
      "           5       0.83      0.89      0.86       155\n",
      "           6       0.98      0.99      0.98       164\n",
      "           7       0.82      0.84      0.83       164\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.86      0.85      1338\n",
      "weighted avg       0.85      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4662\n",
      "Epoch 201, Batch 10, Loss: 0.7662\n",
      "Epoch 201, Batch 20, Loss: 0.7539\n",
      "Accuracy on images: 85.28%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       158\n",
      "           1       0.93      0.83      0.88       187\n",
      "           2       0.83      0.82      0.82       170\n",
      "           3       0.84      0.81      0.83       172\n",
      "           4       0.71      0.91      0.79       130\n",
      "           5       0.90      0.85      0.87       176\n",
      "           6       0.95      0.98      0.96       163\n",
      "           7       0.83      0.77      0.80       182\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.86      0.85      1338\n",
      "weighted avg       0.86      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4693\n",
      "Epoch 202, Batch 10, Loss: 0.7177\n",
      "Epoch 202, Batch 20, Loss: 0.7906\n",
      "Accuracy on images: 85.28%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       155\n",
      "           1       0.91      0.87      0.89       175\n",
      "           2       0.78      0.81      0.80       161\n",
      "           3       0.84      0.80      0.82       176\n",
      "           4       0.77      0.82      0.79       157\n",
      "           5       0.92      0.83      0.87       184\n",
      "           6       0.99      0.98      0.99       168\n",
      "           7       0.80      0.83      0.82       162\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.85      0.85      1338\n",
      "weighted avg       0.86      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4444\n",
      "Epoch 203, Batch 10, Loss: 0.6855\n",
      "Epoch 203, Batch 20, Loss: 0.7279\n",
      "Accuracy on images: 87.44%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       156\n",
      "           1       0.88      0.90      0.89       163\n",
      "           2       0.85      0.84      0.84       170\n",
      "           3       0.88      0.82      0.85       179\n",
      "           4       0.81      0.81      0.81       168\n",
      "           5       0.92      0.88      0.90       174\n",
      "           6       0.99      0.98      0.98       169\n",
      "           7       0.82      0.87      0.84       159\n",
      "\n",
      "    accuracy                           0.87      1338\n",
      "   macro avg       0.87      0.88      0.87      1338\n",
      "weighted avg       0.88      0.87      0.87      1338\n",
      "\n",
      "Validation Loss: 0.4103\n",
      "Epoch 204, Batch 10, Loss: 0.6923\n",
      "Epoch 204, Batch 20, Loss: 0.6704\n",
      "Accuracy on images: 86.70%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       161\n",
      "           1       0.86      0.91      0.88       158\n",
      "           2       0.86      0.82      0.84       176\n",
      "           3       0.89      0.80      0.84       186\n",
      "           4       0.75      0.83      0.79       152\n",
      "           5       0.86      0.92      0.89       156\n",
      "           6       0.99      0.99      0.99       167\n",
      "           7       0.86      0.79      0.82       182\n",
      "\n",
      "    accuracy                           0.87      1338\n",
      "   macro avg       0.87      0.87      0.87      1338\n",
      "weighted avg       0.87      0.87      0.87      1338\n",
      "\n",
      "Validation Loss: 0.4131\n",
      "Epoch 205, Batch 10, Loss: 0.7323\n",
      "Epoch 205, Batch 20, Loss: 0.7186\n",
      "Accuracy on images: 86.92%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       158\n",
      "           1       0.87      0.89      0.88       164\n",
      "           2       0.83      0.81      0.82       173\n",
      "           3       0.88      0.86      0.87       170\n",
      "           4       0.80      0.84      0.82       160\n",
      "           5       0.95      0.85      0.90       186\n",
      "           6       0.98      0.97      0.98       169\n",
      "           7       0.81      0.86      0.83       158\n",
      "\n",
      "    accuracy                           0.87      1338\n",
      "   macro avg       0.87      0.87      0.87      1338\n",
      "weighted avg       0.87      0.87      0.87      1338\n",
      "\n",
      "Validation Loss: 0.4184\n",
      "Epoch 206, Batch 10, Loss: 0.7577\n",
      "Epoch 206, Batch 20, Loss: 0.7240\n",
      "Accuracy on images: 88.04%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       155\n",
      "           1       0.88      0.90      0.89       164\n",
      "           2       0.87      0.87      0.87       168\n",
      "           3       0.92      0.82      0.87       188\n",
      "           4       0.79      0.84      0.81       157\n",
      "           5       0.91      0.91      0.91       167\n",
      "           6       0.98      0.98      0.98       167\n",
      "           7       0.85      0.83      0.84       172\n",
      "\n",
      "    accuracy                           0.88      1338\n",
      "   macro avg       0.88      0.88      0.88      1338\n",
      "weighted avg       0.88      0.88      0.88      1338\n",
      "\n",
      "Validation Loss: 0.3973\n",
      "Epoch 207, Batch 10, Loss: 0.6728\n",
      "Epoch 207, Batch 20, Loss: 0.7606\n",
      "Accuracy on images: 85.35%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86       170\n",
      "           1       0.82      0.94      0.88       146\n",
      "           2       0.79      0.88      0.83       151\n",
      "           3       0.87      0.77      0.81       189\n",
      "           4       0.74      0.76      0.75       162\n",
      "           5       0.91      0.90      0.90       169\n",
      "           6       0.96      0.99      0.98       162\n",
      "           7       0.87      0.77      0.82       189\n",
      "\n",
      "    accuracy                           0.85      1338\n",
      "   macro avg       0.85      0.86      0.85      1338\n",
      "weighted avg       0.86      0.85      0.85      1338\n",
      "\n",
      "Validation Loss: 0.4530\n",
      "Epoch 208, Batch 10, Loss: 0.7309\n",
      "Epoch 208, Batch 20, Loss: 0.6783\n",
      "Accuracy on images: 87.29%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       152\n",
      "           1       0.87      0.91      0.89       159\n",
      "           2       0.79      0.90      0.84       147\n",
      "           3       0.87      0.83      0.85       175\n",
      "           4       0.84      0.82      0.83       172\n",
      "           5       0.93      0.83      0.88       187\n",
      "           6       0.98      0.99      0.98       164\n",
      "           7       0.88      0.81      0.84       182\n",
      "\n",
      "    accuracy                           0.87      1338\n",
      "   macro avg       0.87      0.88      0.87      1338\n",
      "weighted avg       0.88      0.87      0.87      1338\n",
      "\n",
      "Validation Loss: 0.4070\n",
      "Epoch 209, Batch 10, Loss: 0.6758\n",
      "Epoch 209, Batch 20, Loss: 0.7051\n",
      "Accuracy on images: 88.34%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       162\n",
      "           1       0.89      0.93      0.91       159\n",
      "           2       0.82      0.94      0.87       146\n",
      "           3       0.90      0.82      0.86       182\n",
      "           4       0.86      0.85      0.85       168\n",
      "           5       0.90      0.86      0.88       176\n",
      "           6       0.98      0.98      0.98       167\n",
      "           7       0.86      0.81      0.84       178\n",
      "\n",
      "    accuracy                           0.88      1338\n",
      "   macro avg       0.88      0.89      0.88      1338\n",
      "weighted avg       0.88      0.88      0.88      1338\n",
      "\n",
      "Validation Loss: 0.4100\n",
      "Early stopping\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "num_epochs = 300\n",
    "\n",
    "train_loop(model, train_loader, optimizer, criterion, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado correctamente.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.save(model.state_dict(), 'modelo_estado_88.pth')\n",
    "    print(\"Modelo guardado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(\"Error al guardar el modelo:\", e)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T18:47:33.579494800Z",
     "start_time": "2023-12-31T18:47:33.478472800Z"
    }
   },
   "id": "ebca933b926aff8f"
  },
  {
   "cell_type": "markdown",
   "id": "a91045811b60d1d4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Conclusión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c8d41a927e7b397e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
