{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Guia práctica 2 \n",
    "\n",
    "Utilizamos el dataset de kaggle : https://www.kaggle.com/datasets/andrewmvd/isic-2019/data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92ce209dc1451d6b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instalar kaggle API y descargar el dataset mediante consola, escribir en consola :"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "823221302a86a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "pip install kaggle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "352a6e4cbaf71283"
  },
  {
   "cell_type": "markdown",
   "source": [
    "kaggle datasets download -d andrewmvd/isic-2019"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f44f95899e017c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "_________________________________________"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "131ea546f8bb24db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para establecer la configuracion de API de kaggle, es decir establecer donde se descarga el kaggle.json: "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42bb379bba4c7731"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"C:/Users/elena/.kaggle\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T18:02:34.767967800Z",
     "start_time": "2023-12-14T18:02:34.751955Z"
    }
   },
   "id": "707359585bcc0795"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Configuración del dispositivo (usa GPU si está disponible)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ddf49f2f3bcc9d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93a9df02ab3fd881"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Descarga dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a004aeb8dfca4a4"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-14T18:39:51.567814900Z",
     "start_time": "2023-12-14T18:19:50.272008100Z"
    }
   },
   "outputs": [],
   "source": [
    "import kaggle\n",
    "\n",
    "dataset_name = \"andrewmvd/isic-2019\"\n",
    "kaggle.api.dataset_download_files(dataset_name, path=\"C:/Users/elena/Desktop/universidad/3º año/FSI/pythorch\", unzip=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creacion pytorch dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc700fd67090473"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T18:46:30.212652800Z",
     "start_time": "2023-12-14T18:46:30.058619500Z"
    }
   },
   "id": "4b20268a5ae6f77c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------------------------------------- Parte de la practica-----------------------------------------------------------\n",
    "\n",
    "## Definicion de una red convolucional de neuronas, modelo (CNN)\n",
    "\n",
    "Esta red neuronal tiene:\n",
    "\n",
    "3 capas convulutivas cuyo proposito es extraer características de las imagenes:\n",
    "\n",
    "- *conv1*:Toma imágenes de 3 canales (RGB) como entrada y produce 32 mapas de características.\n",
    "- *conv2*: Toma los 32 mapas de características como entrada y produce 64 mapas de características.\n",
    "- *conv3*: Toma los 64 mapas de características como entrada y produce 128 mapas de características.\n",
    "\n",
    "1 capa de Max Pooling cuyo proposito es reducir el ancho y el alto de los mapas de caracteristicas para que disminuya la carga computacional y controlar el sobreajuste.Se aplica despues de cada capa convolucional.\n",
    "\n",
    "2 capas de Dropout que se encarga de prevenir el sobreajuste al establecer aleatoriamente una fracción de las unidades de entrada en 0 durante el entrenamiento.\n",
    "- dropout25: Aplicada después de conv2 y conv3 con una tasa de abandono del 0.25.\n",
    "- dropout50: Aplicada después de la primera capa completamente conectada (fc1) con una tasa de abandono del 0.5.\n",
    "\n",
    "2 Capas Completamente Conectadas (Densas) (Linear):\n",
    "\n",
    "Propósito: Realizar la clasificación en base a las características extraídas por las capas convolucionales.\n",
    "Detalles:\n",
    "fc1: Una capa densa que aplana la salida de la última capa de agrupación en un solo vector y la reduce a 128 características.\n",
    "fc2: La capa densa final que mapea estas 128 características a 8 unidades de salida \n",
    "Método de Avance (forward):\n",
    "\n",
    "Propósito: Define la secuencia en la que los datos de entrada pasan a través de las capas.\n",
    "Detalles: Los datos de entrada pasan por cada capa en el orden definido. Después de la última capa de agrupación, los datos se aplanan y pasan a través de las capas densas.\n",
    "Tamaños de Entrada y Salida:\n",
    "\n",
    "Tamaño de Entrada: El modelo espera imágenes de entrada de tamaño 224x224 después de la transformación RandomResizedCrop.\n",
    "Tamaño de Salida: El modelo produce 10 clases (como se define en fc2).\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c503466e3077b70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Max pooling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # Dropout layers\n",
    "        self.dropout25 = nn.Dropout(0.25)\n",
    "        self.dropout50 = nn.Dropout(0.5)\n",
    "\n",
    "        # Fully connected layers\n",
    "        # ajustado para 150x150\n",
    "        self.fc1 = nn.Linear(in_features=128 * 18 * 18, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the first convolution, activation and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "\n",
    "        # Apply the second convolution, activation, max pooling and dropout layers\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout25(x)\n",
    "\n",
    "        # Apply the third convolution, activation, max pooling and dropout layers\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.dropout25(x)\n",
    "\n",
    "        # Flatten the output for the dense layer\n",
    "        x = x.view(-1, 128 *18 * 18)\n",
    "\n",
    "        # Apply the first dense layer with dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout50(x)\n",
    "\n",
    "        # Apply the second dense layer (output layer)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create the modified model\n",
    "model = CNN()\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Print the modified model summary\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e175594a56a1eeed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "42651f8d7a9b6fb9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Definir Transformaciones de Datos y Data Augmentation\n",
    "\n",
    "Se aplican varias transformaciones a las imagenes de entrenamiento:\n",
    "1. Se escala la imagen a 256x256\n",
    "2. Rotacion aleatoria hasta 180 grados\n",
    "3. Volteo horizontal aleatorio\n",
    "4. Volteo vertical aleatorio\n",
    "5. Recorte Aleatorio: Para simular el enfoque en diferentes partes de la lesión.\n",
    "6. Ajustes de Color: Cambios sutiles en el brillo y el contraste  para simular variaciones de iluminación.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63093167b111b8eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Rutas a los directorios de datos\n",
    "train_dir = 'path/to/train_data'\n",
    "valid_dir = 'path/to/valid_data'\n",
    "test_dir = 'path/to/test_data'\n",
    "\n",
    "# Carga el conjunto de datos de entrenamiento sin ninguna normalización para calcular la media y la desviación estándar\n",
    "unnormalized_transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "unnormalized_dataset = datasets.ImageFolder(root=train_dir, transform=unnormalized_transform)\n",
    "loader = DataLoader(unnormalized_dataset, batch_size=64, num_workers=0, shuffle=False)\n",
    "\n",
    "# Calcular la media y la desviación estándar\n",
    "mean_sum = torch.zeros(3)\n",
    "std_sum = torch.zeros(3)\n",
    "n_samples = 0\n",
    "\n",
    "for images, _ in loader:\n",
    "    images = images.view(images.size(0), 3, -1)\n",
    "    mean, std = torch.std_mean(images, dim=[0, 2])\n",
    "    mean_sum += mean * images.size(0)\n",
    "    std_sum += std * images.size(0)\n",
    "    n_samples += images.size(0)\n",
    "\n",
    "mean = mean_sum / n_samples\n",
    "std = std_sum / n_samples\n",
    "\n",
    "# Transformaciones para el conjunto de entrenamiento\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),             \n",
    "    transforms.RandomRotation(180),            \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# Transformaciones para el conjunto de validación y test (sin data augmentation)\n",
    "test_valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# Parte de nelson (modificar aqui)\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
    "valid_dataset = datasets.ImageFolder(root=valid_dir, transform=test_valid_transforms)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_valid_transforms)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc64fe40e7c3a368"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuración de DataSetLOaders\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9633e01124f11a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Crea los DataLoaders para cada conjunto de datos\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4be80253311242e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Early Stopping "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bf6c42b8ccee4c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.01)\n",
    "\n",
    "# dentro del bucle de entrenamiento\n",
    "for epoch in range(num_epochs):\n",
    "    # Entrenamiento ...\n",
    "    # Validación ...\n",
    "    \n",
    "    val_loss = # Calcula la pérdida de validación\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86fa48715ce51bce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "74a884ae17dfa08b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
