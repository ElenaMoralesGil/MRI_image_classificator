{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9bd7ea",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "Este cuaderno se centra en el procesamiento y análisis de un conjunto de datos de melanoma. Incluye pasos para la carga de datos, preprocesamiento, entrenamiento del modelo y evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c1c27ce5733df518",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:08.147914900Z",
     "start_time": "2023-12-29T18:51:07.931866100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo configurado para usar: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Establecer el dispositivo a GPU si CUDA está disponible, de lo contrario a CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo configurado para usar: {device}\")\n",
    "\n",
    "# Mover el modelo a la GPU\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:08.538308400Z",
     "start_time": "2023-12-29T18:51:07.946870200Z"
    }
   },
   "id": "faa796bd77e24327"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f0fee2fdda7496c2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:08.540308500Z",
     "start_time": "2023-12-29T18:51:08.009883600Z"
    }
   },
   "outputs": [],
   "source": [
    "# consts\n",
    "cats = [\"MEL\",\"NV\",\"BCC\",\"AK\",\"BKL\",\"DF\",\"VASC\",\"SCC\",\"UNK\"]\n",
    "\n",
    "train_percent = .7\n",
    "val_percent = .2\n",
    "test_percent = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1da1cf",
   "metadata": {},
   "source": [
    "## Configuración\n",
    "Las siguientes celdas importan las librerías necesarias y definen constantes utilizadas a lo largo del cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92b3a9a4ed897fc6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:08.541308700Z",
     "start_time": "2023-12-29T18:51:08.089901600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de elementos 25331\n",
      "> Head de los datos del csv\n",
      "          image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK\n",
      "0  ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "1  ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "2  ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "3  ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "4  ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "csv = pd.read_csv(\"./dataset/ISIC_2019_Training_GroundTruth.csv\")\n",
    "\n",
    "print(\"> Cantidad de elementos\", csv.count(axis=1).size )\n",
    "print(\"> Head de los datos del csv\")\n",
    "print(csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e9ab4ebbcb46709f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:08.542309100Z",
     "start_time": "2023-12-29T18:51:08.249937700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Categorias\n",
      "['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']\n"
     ]
    }
   ],
   "source": [
    "header = list(csv.columns)\n",
    "header.remove(\"image\")\n",
    "\n",
    "print(\"> Categorias\")\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c481c8f1366be394",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:08.654343300Z",
     "start_time": "2023-12-29T18:51:08.328192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de filas 25331\n",
      "> Head de los datos en el formato que usa pytorch\n",
      "            img  cat\n",
      "0  ISIC_0000000    1\n",
      "1  ISIC_0000001    1\n",
      "2  ISIC_0000002    0\n",
      "3  ISIC_0000003    1\n",
      "4  ISIC_0000004    0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.DataFrame({\"img\":[], \"cat\": []}, dtype=int)\n",
    "rows_list = []\n",
    "for entry in csv.values:\n",
    "    new_row = {\"img\": entry[0], \"cat\": np.where(entry==1.0)[0][0]-1}\n",
    "    rows_list.append(new_row)\n",
    "\n",
    "data = pd.DataFrame(rows_list)\n",
    "\n",
    "\n",
    "print(\"> Cantidad de filas\", csv.count(axis=1).size)\n",
    "print(\"> Head de los datos en el formato que usa pytorch\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a992e0280a0b1ed3"
  },
  {
   "cell_type": "markdown",
   "id": "b9ee863b",
   "metadata": {},
   "source": [
    "## Carga de Datos y Exploración Inicial\n",
    "El conjunto de datos se carga desde un archivo CSV, y se realiza una exploración inicial para entender su estructura y contenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bc0e11a6b211336",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:08.654343300Z",
     "start_time": "2023-12-29T18:51:08.614324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de imagenes de cada tipo:\n",
      "[ 4522 12875  3323   867  2624   239   253   628     0]\n"
     ]
    }
   ],
   "source": [
    "counter = np.zeros(len(cats), dtype=int)\n",
    "\n",
    "for elm in data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> Cantidad de imagenes de cada tipo:\")\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6950c4077b1fa49c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:08.757369400Z",
     "start_time": "2023-12-29T18:51:08.629328900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad mínima de imagenes de un tipo:\n",
      "239\n"
     ]
    }
   ],
   "source": [
    "# counter = list(filter(lambda elm: elm > 0, counter))\n",
    "# min_cat_size = min(counter)\n",
    "\n",
    "min_cat_size = data.cat.value_counts().min()\n",
    "\n",
    "print(\"> Cantidad mínima de imagenes de un tipo:\")\n",
    "print(min_cat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3fe701173aed9a00",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:08.871427Z",
     "start_time": "2023-12-29T18:51:08.742363200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de elemntos: 1912\n",
      "> Datos equilibrados\n",
      "            img  cat\n",
      "0  ISIC_0055930    0\n",
      "1  ISIC_0054226    0\n",
      "2  ISIC_0063692    0\n",
      "3  ISIC_0063945    0\n",
      "4  ISIC_0065697    0\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(data.groupby(\"cat\").apply(lambda cat: cat.sample(min_cat_size)).reset_index(drop=True))\n",
    "\n",
    "print(\"> Cantidad de elemntos:\", data.count(axis=1).size )\n",
    "print(\"> Datos equilibrados\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e68a69ccb1858902",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:08.897833Z",
     "start_time": "2023-12-29T18:51:08.806411500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> cantidad de elementos 1912\n",
      "> datos barajados\n",
      "               img  cat\n",
      "585   ISIC_0025299    2\n",
      "125   ISIC_0056271    0\n",
      "1367  ISIC_0054918    5\n",
      "1630  ISIC_0025707    6\n",
      "1285  ISIC_0071002    5\n"
     ]
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "\n",
    "print(\"> cantidad de elementos\", data.count(axis=1).size)\n",
    "print(\"> datos barajados\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c3d97",
   "metadata": {},
   "source": [
    "## Preprocesamiento y Análisis de Datos\n",
    "Estas celdas manejan el preprocesamiento de datos, incluyendo la limpieza, equilibrio y preparación para el aprendizaje automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "470557ffc7667896",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:08.970853800Z",
     "start_time": "2023-12-29T18:51:08.885429800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cantidad de imagenes de cada tipo:\n",
      "[239 239 239 239 239 239 239 239   0]\n"
     ]
    }
   ],
   "source": [
    "counter = np.zeros(len(cats), dtype=int)\n",
    "\n",
    "for elm in data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> Cantidad de imagenes de cada tipo:\")\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4f03ba0196f184d7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:09.093881500Z",
     "start_time": "2023-12-29T18:51:08.964852600Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"./dataset/balanced_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b9f77abbcb7df943",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:09.522042500Z",
     "start_time": "2023-12-29T18:51:09.060874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train 1338\n",
      "                           img  cat\n",
      "1174              ISIC_0056654    4\n",
      "366   ISIC_0015981_downsampled    1\n",
      "448               ISIC_0054357    1\n",
      "862               ISIC_0063250    3\n",
      "519               ISIC_0070656    2\n",
      "\n",
      "> val 382\n",
      "                           img  cat\n",
      "405               ISIC_0029190    1\n",
      "990               ISIC_0026538    4\n",
      "930               ISIC_0069120    3\n",
      "1012              ISIC_0033635    4\n",
      "419   ISIC_0012484_downsampled    1\n",
      "\n",
      "> test 192\n",
      "                           img  cat\n",
      "1174              ISIC_0056654    4\n",
      "366   ISIC_0015981_downsampled    1\n",
      "448               ISIC_0054357    1\n",
      "862               ISIC_0063250    3\n",
      "519               ISIC_0070656    2\n"
     ]
    }
   ],
   "source": [
    "train_data, tmp = train_test_split(data, train_size=train_percent, stratify=data['cat'], shuffle=True)\n",
    "val_data, test_data = train_test_split(tmp, test_size=test_percent/(test_percent+val_percent), stratify=tmp['cat'], shuffle=True)\n",
    "\n",
    "\n",
    "print(\"> train\", train_data.count(axis=1).size)\n",
    "print(test_data.head())\n",
    "print()\n",
    "\n",
    "print(\"> val\", val_data.count(axis=1).size)\n",
    "print(val_data.head())\n",
    "print()\n",
    "\n",
    "print(\"> test\", test_data.count(axis=1).size)\n",
    "print(test_data.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1a496339fdf9a0c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:09.522042500Z",
     "start_time": "2023-12-29T18:51:09.271985700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train 1338 0.6997907949790795\n",
      "[167 167 167 168 167 167 167 168   0] (0.12481315396113603)\n",
      "\n",
      "> val 382 0.1997907949790795\n",
      "[48 48 48 47 48 48 48 47  0] (0.1256544502617801)\n",
      "\n",
      "> test 192 0.100418410041841\n",
      "[24 24 24 24 24 24 24 24  0] (0.125)\n"
     ]
    }
   ],
   "source": [
    "counter = np.zeros(len(cats), dtype=int)\n",
    "for elm in train_data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> train\", train_data.count(axis=1).size, train_data.count(axis=1).size/data.count(axis=1).size)\n",
    "print(counter, f\"({counter[0]/train_data.count(axis=1).size})\")\n",
    "print()\n",
    "\n",
    "counter = np.zeros(len(cats), dtype=int)\n",
    "for elm in val_data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> val\", val_data.count(axis=1).size, val_data.count(axis=1).size/data.count(axis=1).size)\n",
    "print(counter, f\"({counter[0]/val_data.count(axis=1).size})\")\n",
    "print()\n",
    "\n",
    "counter = np.zeros(len(cats), dtype=int)\n",
    "for elm in test_data.values:\n",
    "    counter[int(elm[1])]+=1\n",
    "\n",
    "print(\"> test\", test_data.count(axis=1).size, test_data.count(axis=1).size/data.count(axis=1).size)\n",
    "print(counter, f\"({counter[0]/test_data.count(axis=1).size})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a3837",
   "metadata": {},
   "source": [
    "## División de Datos para el Entrenamiento del Modelo\n",
    "El conjunto de datos se divide en conjuntos de entrenamiento, validación y prueba para prepararse para el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2797ef73cf3048b3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:09.522042500Z",
     "start_time": "2023-12-29T18:51:09.412017400Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(\"dataset/train_data.csv\", index=False)\n",
    "val_data.to_csv(\"dataset/val_data.csv\", index=False)\n",
    "test_data.to_csv(\"dataset/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# creacion de un dataset personalizado"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bda1f2617a941319"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "image_dir = \"C:/Users/elena/Desktop/universidad/3º año/FSI/pythorch/ISIC_2019_Training_Input/ISIC_2019_Training_Input\"\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.dataframe.iloc[idx]['img'] + \".jpg\")\n",
    "        image = Image.open(img_name)\n",
    "        label = self.dataframe.iloc[idx]['cat']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:51:09.752093400Z",
     "start_time": "2023-12-29T18:51:09.492035Z"
    }
   },
   "id": "595ecc46888c8a24"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "89ed4be3007db7d5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:52:03.567653Z",
     "start_time": "2023-12-29T18:51:09.624065400Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from PIL import Image\n",
    "import os\n",
    "# Carga el conjunto de datos de entrenamiento sin ninguna normalización para calcular la media y la desviación estándar\n",
    "unnormalized_transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "unnormalized_dataset = CustomDataset(data, image_dir, transform=unnormalized_transform)\n",
    "loader = DataLoader(unnormalized_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Calcular la media y la desviación estándar\n",
    "mean_sum = torch.zeros(3)\n",
    "std_sum = torch.zeros(3)\n",
    "n_samples = 0\n",
    "\n",
    "for images, _ in loader:\n",
    "    images = images.view(images.size(0), images.size(1), -1)\n",
    "    mean = images.mean(dim=2)\n",
    "    std = images.std(dim=2)\n",
    "    mean_sum += mean.sum(dim=0)\n",
    "    std_sum += std.sum(dim=0)\n",
    "    n_samples += images.size(0) * images.size(2)\n",
    "\n",
    "\n",
    "mean = mean_sum / n_samples\n",
    "std = std_sum / n_samples\n",
    "\n",
    "# Transformaciones para el conjunto de entrenamiento\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),             \n",
    "    transforms.RandomRotation(180),            \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# Transformaciones para el conjunto de validación y test (sin data augmentation)\n",
    "test_valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_data,image_dir, transform=train_transform)\n",
    "val_dataset = CustomDataset(val_data,image_dir, transform=test_valid_transforms)\n",
    "test_dataset = CustomDataset(test_data, image_dir,transform=test_valid_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.iloc[idx]['img']\n",
    "        label = self.dataframe.iloc[idx]['cat']\n",
    "        \n",
    "        # Aquí debes ajustar el path de acuerdo a la ubicación de tus imágenes\n",
    "        image = Image.open(f'ruta/a/tus/imagenes/{img_name}.jpg')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:52:03.585656300Z",
     "start_time": "2023-12-29T18:52:03.564652100Z"
    }
   },
   "id": "1f3b4ef27f02fec4"
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# consts\n",
    "CRITERION = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:52:04.402927300Z",
     "start_time": "2023-12-29T18:52:03.578655400Z"
    }
   },
   "id": "d709d2fda39f8c40"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Red Neuronal simple "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4882cf26b9bf3ba4"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "CNN(\n  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (dropout25): Dropout(p=0.25, inplace=False)\n  (dropout50): Dropout(p=0.5, inplace=False)\n  (fc1): Linear(in_features=41472, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=8, bias=True)\n)"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Capas convolucionales\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Max pooling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # Capa Dropout \n",
    "        self.dropout25 = nn.Dropout(0.25)\n",
    "        self.dropout50 = nn.Dropout(0.5)\n",
    "\n",
    "        # Capas Fully connected \n",
    "        # ajustado para 150x150\n",
    "        self.fc1 = nn.Linear(in_features=128 * 18 * 18, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=8)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "\n",
    "\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout25(x)\n",
    "\n",
    "   \n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.dropout25(x)\n",
    "\n",
    "       \n",
    "        x = x.view(-1, 128 *18 * 18)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout50(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN()\n",
    "model.eval()  \n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:52:04.640869200Z",
     "start_time": "2023-12-29T18:52:04.406927800Z"
    }
   },
   "id": "20d82c43bc377723"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparación del Modelo\n",
    "Esta sección prepara el modelo de red neuronal usando PyTorch, incluyendo la definición de la arquitectura del modelo y los cargadores de datos."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd27f414"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "92805274b9e977ff",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:52:04.876110300Z",
     "start_time": "2023-12-29T18:52:04.641869200Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history)\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5454f2",
   "metadata": {},
   "source": [
    "## Funciones de Entrenamiento y Evaluación\n",
    "Aquí se definen las funciones para entrenar el modelo y evaluar su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ce16dbb8f44ec2b9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:52:05.019888400Z",
     "start_time": "2023-12-29T18:52:04.878110500Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(model, train_loader, optimizer, criterion, num_epoch, device, history = []):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        running_loss = 0\n",
    "        for i, (imgs, cats) in enumerate(train_loader, 1):\n",
    "            \n",
    "            imgs, cats = imgs.to(device), cats.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, cats)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if not i % 10:\n",
    "                print(f\"Epoch {epoch+1}, Batch {i}, Loss: {running_loss/10:.4f}\")\n",
    "                history.append(running_loss/10)\n",
    "                running_loss = 0.0\n",
    "        val_loss = eval(model, train_loader, device)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "        early_stopping(val_loss)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f699366dbf8a106e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:52:05.191509300Z",
     "start_time": "2023-12-29T18:52:05.019888400Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval(model, test_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    pred = []\n",
    "    real = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, cats in test_loader:\n",
    "            imgs, cats = imgs.to(device), cats.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            pred.extend(predicted.tolist())\n",
    "            real.extend(cats.tolist())\n",
    "\n",
    "            total += cats.size(0)\n",
    "            correct += (predicted == cats).sum().item()\n",
    "\n",
    "    print(f'Accuracy on test images: {100 * correct / total:.2f}%')\n",
    "    print(metrics.classification_report(pred, real, target_names=dataset.classes))\n",
    "    \n",
    "    #return pred, real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec68d3e4",
   "metadata": {},
   "source": [
    "## Utilidades Adicionales\n",
    "Funciones de utilidad adicionales, como la detención temprana, se definen en esta sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a3dcf6a2c89b7ef8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T18:52:05.350858900Z",
     "start_time": "2023-12-29T18:52:05.194502900Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f27f34",
   "metadata": {},
   "source": [
    "## Conclusión\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
